

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Generative Adversarial Networks &#8212; Applied Machine Learning in Python</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="_static/myfile.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'MachineLearning_GAN';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Time Series Analysis and Modeling" href="MachineLearning_time_series.html" />
    <link rel="prev" title="Autoencoder" href="MachineLearning_autoencoder.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/AppliedMachineLearning.jpg" class="logo__image only-light" alt="Applied Machine Learning in Python - Home"/>
    <script>document.write(`<img src="_static/AppliedMachineLearning.jpg" class="logo__image only-dark" alt="Applied Machine Learning in Python - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_concepts.html">Machine Learning Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_training_tuning.html">Training and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_workflow_construction.html">Workflow Construction and Coding</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_probability.html">Probability Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_plotting_data_models.html">Loading and Plotting Data and Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_univariate_analysis.html">Univariate Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_multivariate_analysis.html">Multivariate Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_feature_transformations.html">Feature Transformations</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_feature_ranking.html">Feature Ranking</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_feature_imputation.html">Feature Imputation</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_clustering.html">Cluster Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_density-based_clustering.html">Density-based Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_spectral_clustering.html">Spectral Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_PCA.html">Principal Components Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_multidimensional_scaling.html">Multidimensional Scaling</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_random_projection.html">Random Projection</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_predictive.html">Prediction with scikit-learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_linear_regression.html">Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_ridge_regression.html">Ridge Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_LASSO_regression.html">LASSO Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_Bayesian_linear_regression.html">Bayesian Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_naive_Bayes.html">Naive Bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_polynomial_regression.html">Polynomial Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_knearest_neighbours.html">k-Nearest Neighbours</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_decision_tree.html">Decision Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_ensemble_trees.html">Bagging Tree and Random Forest</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_gradient_boosting.html">Gradient Boosting</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_support_vector_machines.html">Support Vector Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_ANN.html">Artificial Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_CNN.html">Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_autoencoder.html">Autoencoder Neural Networks</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Generative Adversarial Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_time_series.html">Time Series Analysis and Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_python.html">Python Code Snippets</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_datasets.html">Synthetic Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="conclusions.html">Conclusions</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/GeostatsPyDemos_Book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/GeostatsPyDemos_Book/issues/new?title=Issue%20on%20page%20%2FMachineLearning_GAN.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/MachineLearning_GAN.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Generative Adversarial Networks</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation">Motivation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Generative Adversarial Networks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#indirect-adversarial-learning">Indirect, Adversarial Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#import-required-packages">Import Required Packages</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#declare-functions">Declare Functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#set-the-working-directory">Set the Working Directory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-the-generative-adversarial-network">Visualize the Generative Adversarial Network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generator-forward-pass">Generator Forward Pass</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discriminator-forward-pass">Discriminator Forward Pass</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discriminator-loss">Discriminator Loss</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discriminator-loss-derivative">Discriminator Loss Derivative</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discriminator-back-propagation">Discriminator Back Propagation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generator-loss-derivative-and-back-propagation-through-the-discriminator">Generator Loss Derivative and Back Propagation Through the Discriminator</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#backpropagation-through-generator-to-weights-and-bias">Backpropagation Through Generator to Weights and Bias</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-gan-training-workflow">Simple GAN Training Workflow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-real-images-and-trained-generator-fake-images">Visualize Real Images and Trained Generator Fake Images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-real-images-and-generator-fake-images-over-training-epochs">Visualize Real Images and Generator Fake Images Over Training Epochs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comments">Comments</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#about-the-author">About the Author</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#want-to-work-together">Want to Work Together?</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <figure style="text-align: center;">
  <img src="_static/intro/title_page.png" style="display: block; margin: 0 auto; width: 100%;">
</figure>
<section id="generative-adversarial-networks">
<h1>Generative Adversarial Networks<a class="headerlink" href="#generative-adversarial-networks" title="Permalink to this heading">#</a></h1>
<p>Michael J. Pyrcz, Professor, The University of Texas at Austin</p>
<p><a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></p>
<p>Chapter of e-book “Applied Machine Learning in Python: a Hands-on Guide with Code”.</p>
<div class="remove-from-content-only admonition">
<p class="admonition-title">Cite this e-Book as:</p>
<p>Pyrcz, M.J., 2024, <em>Applied Machine Learning in Python: A Hands-on Guide with Code</em> [e-book]. Zenodo. doi:10.5281/zenodo.15169138 <a class="reference external" href="https://doi.org/10.5281/zenodo.15169138"><img alt="DOI" src="https://zenodo.org/badge/863274676.svg" /></a></p>
</div>
<p>The workflows in this book and more are available here:</p>
<div class="remove-from-content-only admonition">
<p class="admonition-title">Cite the MachineLearningDemos GitHub Repository as:</p>
<p>Pyrcz, M.J., 2024, <em>MachineLearningDemos: Python Machine Learning Demonstration Workflows Repository</em> (0.0.3) [Software]. Zenodo. DOI: 10.5281/zenodo.13835312. GitHub repository: <a class="github reference external" href="https://github.com/GeostatsGuy/MachineLearningDemos">GeostatsGuy/MachineLearningDemos</a> <a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.13835312"><img alt="DOI" src="https://zenodo.org/badge/862519860.svg" /></a></p>
</div>
<p>By Michael J. Pyrcz <br />
© Copyright 2024.</p>
<p>This chapter is a tutorial for / demonstration of <strong>Generative Adversarial Networks</strong>.</p>
<p><strong>YouTube Lecture</strong>: check out my lectures on:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://youtu.be/A9PiCMY_6nM?si=NxWSU_5RgQ4w55EL">Artificial Neural Networks</a></p></li>
<li><p><a class="reference external" href="https://youtu.be/za2my_XDoOs?si=LeHU6p2_fc9dX4Yt">Convolutional Neural Networks</a></p></li>
</ul>
<p>These lectures are all part of my <a class="reference external" href="https://youtube.com/playlist?list=PLG19vXLQHvSC2ZKFIkgVpI9fCjkN38kwf&amp;si=XonjO2wHdXffMpeI">Machine Learning Course</a> on YouTube with linked well-documented Python workflows and interactive dashboards. My goal is to share accessible, actionable, and repeatable educational content. If you want to know about my motivation, check out <a class="reference external" href="https://michaelpyrcz.com/my-story">Michael’s Story</a>.</p>
<section id="motivation">
<h2>Motivation<a class="headerlink" href="#motivation" title="Permalink to this heading">#</a></h2>
<p>What if we put together machines? Working in a competitive, adversarial manner?</p>
<ul class="simple">
<li><p>Could we make a more powerful model that learns its own loss function!</p></li>
<li><p>Could we make images that don’t collapse to exact reproduction of the images in the training set?</p></li>
</ul>
<p>Generative neural networks are very powerful, nature inspired computing deep learning method to make fake, but realistic, images by application of convolutional neural networks, an analogy of visual cortex that extend the ability of our artificial neural networks to better work with images.</p>
<p>Nature inspired computing is looking to nature for inspiration to develop novel problem-solving methods,</p>
<ul class="simple">
<li><p><strong>artificial neural networks</strong> are inspired by biological neural networks</p></li>
<li><p><strong>nodes</strong> in our model are artificial neurons, simple processors</p></li>
<li><p><strong>connections</strong> between nodes are artificial synapses</p></li>
<li><p><strong>perceptive fields</strong> regularization to improve generalization and efficiency</p></li>
</ul>
<p>intelligence emerges from many connected simple processors. For the remainder of this chapter, I will used the terms nodes and connections to describe our convolutional neural network.</p>
</section>
<section id="id1">
<h2>Generative Adversarial Networks<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<p>If we start with a convolutional neural network and we flip it, i.e., reverse the order of the operations,</p>
<ul class="simple">
<li><p>we have a machine that maps from a 1D vector of values, to an image, i.e., we can generate fake images</p></li>
<li><p>to accomplish this instead of convolution, we have transpose convolution for each feature map</p></li>
<li><p>we also perform non-linear activation at each feature map to prevent network collapse</p></li>
</ul>
<figure style="text-align: center;">
  <img src="_static/GAN/flipcnn.png" style="display: block; margin: 0 auto; width: 80%;">
  <figcaption style="text-align: center;"> A convolutional neural network flipped and convolution replaced with transpose convolution to go from a 1D random latent vector to a random image.
</figcaption>
</figure>
<p>But how do we train this flipped convolutional neural network to make good images?</p>
<ul class="simple">
<li><p>we could take training images and score the difference between our generated fake images, for example, with a pixel-wise squared error (L2 norm)</p></li>
<li><p>but if we did this, our machine would only learn how to make this image or a limited set of training images and that would not be useful</p></li>
</ul>
<p>We want to make a diverse set of image realizations, that look and behave correctly. This is the simulation paradigm at the heart of geostatistics</p>
<ul class="simple">
<li><p>to learn more about the simulation paradigm from geostatistics, see my <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/GeostatsPy_simulation.html">Simulation Chapter</a> from my free, online e-book, <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book">Applied Geostatistics in Python</a>.</p></li>
</ul>
<p>Instead of a loss function we take a classification convolutional neural network to map from the image to a probability of a real image. We have 2 neural networks in our GAN,</p>
<ul class="simple">
<li><p><strong>generator</strong> - flipped convolutional neural network that makes random fake images</p></li>
<li><p><strong>discriminator</strong> - classification convolutional neural netwrok that calculates the probability that an image is real</p></li>
</ul>
<figure style="text-align: center;">
  <img src="_static/GAN/ganschematic.png" style="display: block; margin: 0 auto; width: 100%;">
  <figcaption style="text-align: center;"> A convolutional neural network flipped and convolution replaced with transpose convolution to go from a 1D random latent vector to a random image.
</figcaption>
</figure>
</section>
<section id="indirect-adversarial-learning">
<h2>Indirect, Adversarial Learning<a class="headerlink" href="#indirect-adversarial-learning" title="Permalink to this heading">#</a></h2>
<p>How do we train these two coupled networks? We call each network an agent and we train them competively, e.g., they compete while learning!</p>
<ul class="simple">
<li><p>agent 1, Generator, is not trained to minimize an loss function with respect to training data (training image), no MSE!</p></li>
<li><p>instead the agent 1, Generator, is trained to fool agent 2, Discriminator</p></li>
<li><p>agent 2, Discriminator, is learning at the same time to tell the difference between the real training images and the fakes from agent 1, generator</p></li>
</ul>
<p>Each agent has their own competitive goals,</p>
<ul class="simple">
<li><p>Generator – make fakes that Discriminator classifies as real</p></li>
<li><p>Discriminator – correctly classify fake and real images</p></li>
</ul>
<p>Note, the generator never sees the real images, but by learning to fool the discriminator learns to make images like the real training images.</p>
<p>The GAN loss function is stated as,</p>
<div class="math notranslate nohighlight">
\[
\min_{\theta_G} \, \max_{\theta_D} \;
\mathbb{E}_{\mathbf{y} \sim p_{\text{data}}} \left[ \log D_{\theta_D}(\mathbf{y}) \right]
+
\mathbb{E}_{\mathbf{x} \sim p_{\mathbf{x}}} \left[ \log \left( 1 - D_{\theta_D}(G_{\theta_G}(\mathbf{x})) \right) \right]
\]</div>
<p>where,</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\theta_D\)</span> - parameters (weights, biases) of the <strong>discriminator</strong></p></li>
<li><p><span class="math notranslate nohighlight">\(\theta_G\)</span> - parameters of the <strong>generator</strong></p></li>
<li><p><span class="math notranslate nohighlight">\(D_{\theta_D}(\cdot)\)</span> - discriminator output, given the discriminator parameters <span class="math notranslate nohighlight">\(\theta_D\)</span> (probability input is real)</p></li>
<li><p><span class="math notranslate nohighlight">\(G_{\theta_G}(\mathbf{x})\)</span> - output of the  Generator output given latent input <span class="math notranslate nohighlight">\(\mathbf{x}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{y} \sim p_{\text{data}}\)</span> - training images from the <strong>real image set</strong></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{x} \sim p_{\mathbf{x}}\)</span> - latent input sampled from known prior (e.g. uniform or normal)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbb{E}[\cdot]\)</span> - expectation over data (i.e., average over all samples)</p></li>
<li><p><span class="math notranslate nohighlight">\(\log D(\cdot)\)</span> - log-likelihood that the discriminator assigns input as real</p></li>
<li><p><span class="math notranslate nohighlight">\(\log(1 - D(G(\cdot)))\)</span> - log-likelihood that discriminator assigns fake to generator’s output</p></li>
</ul>
<p>The discriminator wants to <strong>maximize</strong>,</p>
<div class="math notranslate nohighlight">
\[
\log D(\mathbf{y}) + \log(1 - D(G(\mathbf{x})))
\]</div>
<ul class="simple">
<li><p>correctly predicts <strong>real</strong> data as real</p></li>
<li><p>correctly predicts <strong>generated</strong> data as fake</p></li>
</ul>
<p>The generator want to <strong>minimize</strong>,</p>
<div class="math notranslate nohighlight">
\[
\log(1 - D(G(\mathbf{x})))
\]</div>
<ul class="simple">
<li><p>tries to <strong>fool the discriminator</strong></p></li>
<li><p>makes fake samples look real</p></li>
</ul>
<p>To assist with understanding the GAN loss function, consider these end members,</p>
<ol class="arabic simple">
<li><p>Perfect Discriminator - if the discriminator is perfect,</p></li>
</ol>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(D(\mathbf{y}) = 1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(D(G(\mathbf{x})) = 0\)</span></p></li>
</ul>
<p><span class="math notranslate nohighlight">\(\quad\)</span> then the discriminator loss is,</p>
<div class="math notranslate nohighlight">
\[
\log(1) + \log(1 - 0) = 0 + \log(1) = 0
\]</div>
<ul class="simple">
<li><p>generator receives <strong>no gradient</strong></p></li>
<li><p>training <strong>stalls</strong> due to vanishing gradients</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Perfect Generator - if the generator is perfect,</p></li>
</ol>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(G(\mathbf{x}) \sim p_{\text{data}}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(D(\cdot) = 0.5\)</span></p></li>
</ul>
<p><span class="math notranslate nohighlight">\(\quad\)</span> then the loss is,</p>
<div class="math notranslate nohighlight">
\[
\log(0.5) + \log(1 - 0.5) = \log(0.5) + \log(0.5) = -\log 4
\]</div>
<ul class="simple">
<li><p>discriminator is <strong>maximally confused</strong></p></li>
<li><p>this is the <strong>Nash equilibrium</strong></p></li>
</ul>
</section>
<section id="import-required-packages">
<h2>Import Required Packages<a class="headerlink" href="#import-required-packages" title="Permalink to this heading">#</a></h2>
<p>We will also need some standard packages. These should have been installed with Anaconda 3.</p>
<ul class="simple">
<li><p>recall our goal is to build a convolutional neural network by-hand with only basic math and array operations, so we only need NumPy along with matplotlib for plotting.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline                                         
<span class="n">suppress_warnings</span> <span class="o">=</span> <span class="kc">True</span>                                      <span class="c1"># toggle to supress warnings</span>
<span class="kn">import</span> <span class="nn">os</span>                                                     <span class="c1"># set working directory</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>                                            <span class="c1"># arrays and matrix math</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>                               <span class="c1"># for plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib.patches</span> <span class="k">as</span> <span class="nn">patches</span>
<span class="kn">import</span> <span class="nn">copy</span>                                                   <span class="c1"># deep copy dictionaries</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span>                                         <span class="c1"># default color bar, no bias and friendly for color vision defeciency</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;axes&#39;</span><span class="p">,</span> <span class="n">axisbelow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                                <span class="c1"># grid behind plotting elements</span>
<span class="k">if</span> <span class="n">suppress_warnings</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>  
    <span class="kn">import</span> <span class="nn">warnings</span>                                           <span class="c1"># supress any warnings for this demonstration</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span> 
<span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span>                                                     <span class="c1"># random number seed for workflow repeatability</span>
</pre></div>
</div>
</div>
</div>
<p>If you get a package import error, you may have to first install some of these packages. This can usually be accomplished by opening up a command window on Windows and then typing ‘python -m pip install [package-name]’. More assistance is available with the respective package docs.</p>
</section>
<section id="declare-functions">
<h2>Declare Functions<a class="headerlink" href="#declare-functions" title="Permalink to this heading">#</a></h2>
<p>Here’s the functions to make, train and visualize our generative adversarial network, including the steps,</p>
<ul class="simple">
<li><p>make a simple set of synthetic data</p></li>
<li><p>initialize the weights in our generator and discriminator</p></li>
<li><p>apply our generator and discrimintor</p></li>
<li><p>calculate the error derivative and update the generator and discriminator weights and biases</p></li>
</ul>
<p>Here’s a list of the functions,</p>
<ol class="arabic simple">
<li><p><strong>generate_real_data</strong> -  synthetic data generator</p></li>
<li><p><strong>initialize_generator_weights</strong> - assign small random weights and bias for generator</p></li>
<li><p><strong>initialize_discriminator_weights</strong> - assign small random weights and bias for discriminator</p></li>
<li><p><strong>generator_forward</strong> - calculate a set of fake data with the generator given a set of latent values and the current weights and biases</p></li>
<li><p><strong>discriminator_forward</strong> - calculate the probability of a real image over a set of images and return a 1D ndarray of probabilities</p></li>
<li><p><strong>sigmoid</strong> - activation function to apply in the generator and discriminator</p></li>
<li><p><strong>generator_gradients</strong> - compute generator gradients averaged over the batch</p></li>
<li><p><strong>discriminator_gradients</strong> - compute generator gradients averaged over the batch</p></li>
</ol>
<p>Here are the functions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_real_data</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">slope_range</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7</span><span class="p">),</span> <span class="n">residual_std</span><span class="o">=</span><span class="mf">0.02</span><span class="p">):</span> <span class="c1"># make a synthetic training image set</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate real 3-node images with decreasing linear trend plus noise.</span>
<span class="sd">    Standardize each to have mean 0.5.</span>
<span class="sd">    Returns shape (batch_size, 3)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">slopes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">slope_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">slope_range</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">base</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>  <span class="c1"># node positions for linear trend</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">trend</span> <span class="o">=</span> <span class="n">slopes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">base</span>
        <span class="n">residual</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">residual_std</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="n">trend</span> <span class="o">+</span> <span class="n">residual</span>
        <span class="n">sample</span> <span class="o">+=</span> <span class="mf">0.5</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>  <span class="c1"># standardize to mean 0.5</span>
        <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample</span>
    <span class="k">return</span> <span class="n">data</span>

<span class="k">def</span> <span class="nf">initialize_generator_weights</span><span class="p">():</span>                           <span class="c1"># initialize the generator weights and return as a dictionary</span>
    <span class="c1"># Small random weights and bias for generator</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;lambda_12&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="s1">&#39;lambda_13&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="s1">&#39;lambda_14&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="mf">0.0</span>
    <span class="p">}</span>

<span class="k">def</span> <span class="nf">generator_forward</span><span class="p">(</span><span class="n">L1_latent</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>                    <span class="c1"># given latent vector and generator weights return a set of fake images</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    L1_latent: ndarray shape (batch_size,)</span>
<span class="sd">    weights: dict with keys &#39;lambda_1_2&#39;, &#39;lambda_1_3&#39;, &#39;lambda_1_4&#39;, &#39;b&#39;</span>
<span class="sd">    Returns output ndarray shape (batch_size, 3)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">O2</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="s1">&#39;lambda_12&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">L1_latent</span> <span class="o">+</span> <span class="n">weights</span><span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">]</span>
    <span class="n">O3</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="s1">&#39;lambda_13&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">L1_latent</span> <span class="o">+</span> <span class="n">weights</span><span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">]</span>
    <span class="n">O4</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="s1">&#39;lambda_14&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">L1_latent</span> <span class="o">+</span> <span class="n">weights</span><span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">O2</span><span class="p">,</span> <span class="n">O3</span><span class="p">,</span> <span class="n">O4</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>  <span class="c1"># shape (batch_size, 3)</span>

<span class="k">def</span> <span class="nf">initialize_discriminator_weights</span><span class="p">():</span>                       <span class="c1"># initialize the discriminator weights and return as a dictionary               </span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;lambda_58&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="s1">&#39;lambda_68&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="s1">&#39;lambda_78&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="s1">&#39;c&#39;</span><span class="p">:</span> <span class="mf">0.0</span>
    <span class="p">}</span>

<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>                                               <span class="c1"># sigmoid activation function</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">discriminator_forward</span><span class="p">(</span><span class="n">I5</span><span class="p">,</span> <span class="n">I6</span><span class="p">,</span> <span class="n">I7</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>               <span class="c1"># given a set of images return the discriminator probability of real image</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Inputs: I5, I6, I7 shape (batch_size,)</span>
<span class="sd">    weights: dict with keys &#39;lambda_58&#39;, &#39;lambda_68&#39;, &#39;lambda_78&#39;, &#39;c&#39;</span>
<span class="sd">    Returns probability ndarray shape (batch_size,)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;lambda_58&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">I5</span> <span class="o">+</span> 
         <span class="n">weights</span><span class="p">[</span><span class="s1">&#39;lambda_68&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">I6</span> <span class="o">+</span> 
         <span class="n">weights</span><span class="p">[</span><span class="s1">&#39;lambda_78&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">I7</span> <span class="o">+</span> 
         <span class="n">weights</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">z</span>

<span class="k">def</span> <span class="nf">discriminator_gradients</span><span class="p">(</span><span class="n">I5</span><span class="p">,</span> <span class="n">I6</span><span class="p">,</span> <span class="n">I7</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>     <span class="c1"># given set of images, true labels, and discriminator weights return the gradients</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute discriminator gradients averaged over batch.</span>
<span class="sd">    y_true: labels (1 for real, 0 for fake), shape (batch_size,)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">y_pred</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">discriminator_forward</span><span class="p">(</span><span class="n">I5</span><span class="p">,</span> <span class="n">I6</span><span class="p">,</span> <span class="n">I7</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="n">dz</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">)</span>  <span class="c1"># shape (batch_size,)</span>
    
    <span class="n">grad_lambda_58</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dz</span> <span class="o">*</span> <span class="n">I5</span><span class="p">)</span>
    <span class="n">grad_lambda_68</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dz</span> <span class="o">*</span> <span class="n">I6</span><span class="p">)</span>
    <span class="n">grad_lambda_78</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dz</span> <span class="o">*</span> <span class="n">I7</span><span class="p">)</span>
    <span class="n">grad_c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dz</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;lambda_58&#39;</span><span class="p">:</span> <span class="n">grad_lambda_58</span><span class="p">,</span>
        <span class="s1">&#39;lambda_68&#39;</span><span class="p">:</span> <span class="n">grad_lambda_68</span><span class="p">,</span>
        <span class="s1">&#39;lambda_78&#39;</span><span class="p">:</span> <span class="n">grad_lambda_78</span><span class="p">,</span>
        <span class="s1">&#39;c&#39;</span><span class="p">:</span> <span class="n">grad_c</span>
    <span class="p">}</span>

<span class="k">def</span> <span class="nf">generator_gradients</span><span class="p">(</span><span class="n">L1_latent</span><span class="p">,</span> <span class="n">weights_g</span><span class="p">,</span> <span class="n">weights_d</span><span class="p">):</span>     <span class="c1"># given latent vector, generator and discriminator weights return the gradients</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute gradients of generator weights using discriminator feedback.</span>
<span class="sd">    L1_latent: shape (batch_size,)</span>
<span class="sd">    weights_g: generator weights dict</span>
<span class="sd">    weights_d: discriminator weights dict</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">L1_latent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="c1"># Generator outputs</span>
    <span class="n">O</span> <span class="o">=</span> <span class="n">generator_forward</span><span class="p">(</span><span class="n">L1_latent</span><span class="p">,</span> <span class="n">weights_g</span><span class="p">)</span>  <span class="c1"># shape (batch_size, 3)</span>
    <span class="n">I5</span><span class="p">,</span> <span class="n">I6</span><span class="p">,</span> <span class="n">I7</span> <span class="o">=</span> <span class="n">O</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">O</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">O</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span>
    
    <span class="c1"># Discriminator forward pass</span>
    <span class="n">y_pred</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">discriminator_forward</span><span class="p">(</span><span class="n">I5</span><span class="p">,</span> <span class="n">I6</span><span class="p">,</span> <span class="n">I7</span><span class="p">,</span> <span class="n">weights_d</span><span class="p">)</span>
    
    <span class="c1"># Gradient of loss w.r.t discriminator logit for generator loss (label=1)</span>
    <span class="n">dz</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># shape (batch_size,)</span>
    
    <span class="c1"># Gradients w.r.t generator outputs</span>
    <span class="n">dO2</span> <span class="o">=</span> <span class="n">dz</span> <span class="o">*</span> <span class="n">weights_d</span><span class="p">[</span><span class="s1">&#39;lambda_58&#39;</span><span class="p">]</span>
    <span class="n">dO3</span> <span class="o">=</span> <span class="n">dz</span> <span class="o">*</span> <span class="n">weights_d</span><span class="p">[</span><span class="s1">&#39;lambda_68&#39;</span><span class="p">]</span>
    <span class="n">dO4</span> <span class="o">=</span> <span class="n">dz</span> <span class="o">*</span> <span class="n">weights_d</span><span class="p">[</span><span class="s1">&#39;lambda_78&#39;</span><span class="p">]</span>
    
    <span class="c1"># Gradients w.r.t generator weights and bias</span>
    <span class="n">grad_lambda_12</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dO2</span> <span class="o">*</span> <span class="n">L1_latent</span><span class="p">)</span>
    <span class="n">grad_lambda_13</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dO3</span> <span class="o">*</span> <span class="n">L1_latent</span><span class="p">)</span>
    <span class="n">grad_lambda_14</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dO4</span> <span class="o">*</span> <span class="n">L1_latent</span><span class="p">)</span>
    <span class="n">grad_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dO2</span> <span class="o">+</span> <span class="n">dO3</span> <span class="o">+</span> <span class="n">dO4</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;lambda_12&#39;</span><span class="p">:</span> <span class="n">grad_lambda_12</span><span class="p">,</span>
        <span class="s1">&#39;lambda_13&#39;</span><span class="p">:</span> <span class="n">grad_lambda_13</span><span class="p">,</span>
        <span class="s1">&#39;lambda_14&#39;</span><span class="p">:</span> <span class="n">grad_lambda_14</span><span class="p">,</span>
        <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="n">grad_b</span>
    <span class="p">}</span>

<span class="k">def</span> <span class="nf">fancybox</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">xy</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">text_color</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span> <span class="c1"># a dashed fancy box for the GAN plot</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Draws a dashed, rounded rectangle on a given axes.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - ax: The matplotlib axes to draw on</span>
<span class="sd">    - xy: (x, y) tuple for bottom-left corner of the box</span>
<span class="sd">    - width: Width of the box</span>
<span class="sd">    - height: Height of the box</span>
<span class="sd">    - label: Optional label text to display centered above the box</span>
<span class="sd">    - edgecolor: Border color of the box</span>
<span class="sd">    - text_color: Color of the label text (defaults to edgecolor)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">text_color</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">text_color</span> <span class="o">=</span> <span class="n">edgecolor</span>

    <span class="c1"># Draw box</span>
    <span class="n">box</span> <span class="o">=</span> <span class="n">patches</span><span class="o">.</span><span class="n">FancyBboxPatch</span><span class="p">(</span>
        <span class="n">xy</span><span class="p">,</span>
        <span class="n">width</span><span class="p">,</span>
        <span class="n">height</span><span class="p">,</span>
        <span class="n">boxstyle</span><span class="o">=</span><span class="s2">&quot;round,pad=0.02&quot;</span><span class="p">,</span>
        <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">edgecolor</span><span class="o">=</span><span class="n">edgecolor</span><span class="p">,</span>
        <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
        <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">box</span><span class="p">)</span>

    <span class="c1"># Add label text above the box</span>
    <span class="n">x_center</span> <span class="o">=</span> <span class="n">xy</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">width</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="n">y_top</span> <span class="o">=</span> <span class="n">xy</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">height</span> <span class="o">+</span> <span class="mf">0.02</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x_center</span><span class="p">,</span> <span class="n">y_top</span> <span class="o">+</span> <span class="mf">0.02</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">text_color</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="set-the-working-directory">
<h2>Set the Working Directory<a class="headerlink" href="#set-the-working-directory" title="Permalink to this heading">#</a></h2>
<p>I always like to do this so I don’t lose files and to simplify subsequent read and writes (avoid including the full address each time).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#os.chdir(&quot;c:/PGE383&quot;)                                        # set the working directory</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualize-the-generative-adversarial-network">
<h2>Visualize the Generative Adversarial Network<a class="headerlink" href="#visualize-the-generative-adversarial-network" title="Permalink to this heading">#</a></h2>
<p>We are implementing a minimal Generative Adversarial Network (GAN) with:</p>
<ul class="simple">
<li><p><strong>Generator</strong> that produces 3-node outputs (like tiny 1D images) from a single latent input</p></li>
<li><p><strong>Discriminator</strong> that evaluates these outputs to distinguish between <strong>real</strong> and <strong>fake</strong> samples.</p></li>
</ul>
<p>Now let’s define the part of the <strong>Generator</strong>,</p>
<ul class="simple">
<li><p><strong>Latent Node</strong> - <span class="math notranslate nohighlight">\(L_1\)</span>, a single random value with uniform distribution, <span class="math notranslate nohighlight">\(U[0.4,1.0]\)</span>. Note we do stay away from 0.0 or negative values as these would remove the slope or flip the slope of the fakes.</p></li>
<li><p><strong>Generator Weights</strong> - <span class="math notranslate nohighlight">\(\lambda_{1,2}\)</span>, <span class="math notranslate nohighlight">\(\lambda_{1,3}\)</span> and <span class="math notranslate nohighlight">\(\lambda_{1,4}\)</span> for the connections from latent to each of the output nodes. This is the simplest possible tranpose convolution, kernel size is 3, output nodes is 3 and latent is 1, so the kernel does not translate. I did this to greatly simplify the book keeping, but the concepts could be extended to a more realistic convolution / tranpose convolution problem.</p></li>
<li><p><strong>Generator Bias</strong> - <span class="math notranslate nohighlight">\(b\)</span>, a single, constant bias over the output layer (output image), the nodes, <span class="math notranslate nohighlight">\(O_2\)</span>, <span class="math notranslate nohighlight">\(O_3\)</span>, and <span class="math notranslate nohighlight">\(O_4\)</span></p></li>
<li><p><strong>Generator Output Nodes</strong> - <span class="math notranslate nohighlight">\(O_2\)</span>, <span class="math notranslate nohighlight">\(O_3\)</span>, and <span class="math notranslate nohighlight">\(O_4\)</span>, the single and last feature map in our very simple generator, a 1D image with 3 nodes or pixels</p></li>
</ul>
<p>and the parts of the paired <strong>Discrimintor</strong>,</p>
<ul class="simple">
<li><p><strong>Discriminator Input Nodes</strong> - <span class="math notranslate nohighlight">\(I_5\)</span>, <span class="math notranslate nohighlight">\(I_6\)</span>, and <span class="math notranslate nohighlight">\(I_7\)</span>, that receive the real images or the fake images from the generator output nodes, <span class="math notranslate nohighlight">\(O_2\)</span>, <span class="math notranslate nohighlight">\(O_3\)</span>, <span class="math notranslate nohighlight">\(O_4\)</span></p></li>
<li><p><strong>Discriminator Weights</strong> - <span class="math notranslate nohighlight">\(\lambda_{5,8}\)</span>, <span class="math notranslate nohighlight">\(\lambda_{6,8}\)</span>, and <span class="math notranslate nohighlight">\(\lambda_{7,8}\)</span> for the connections from input nodes (input image) to the output (descision) node, <span class="math notranslate nohighlight">\(D_8\)</span>
$$</p></li>
<li><p><strong>Discriminator Bias</strong> - <span class="math notranslate nohighlight">\(c\)</span>, bias applied at the output (descision) node, <span class="math notranslate nohighlight">\(D_8\)</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;darksalmon&#39;</span><span class="p">,</span><span class="s1">&#39;deepskyblue&#39;</span><span class="p">,</span><span class="s1">&#39;gold&#39;</span><span class="p">]</span>                  <span class="c1"># line colors for latent to fake to probability flow</span>
<span class="n">colors_real</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;orangered&#39;</span><span class="p">,</span><span class="s1">&#39;dodgerblue&#39;</span><span class="p">,</span><span class="s1">&#39;goldenrod&#39;</span><span class="p">]</span>          <span class="c1"># line colors for real image to probability flow</span>

<span class="k">def</span> <span class="nf">draw_gan_architecture_full</span><span class="p">():</span>                             <span class="c1"># function to draw the GAN demonstrated in this workflow</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$L_1$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="c1"># generator latent node</span>
            <span class="n">bbox</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s2">&quot;circle&quot;</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">))</span>

    <span class="n">gen_outputs</span> <span class="o">=</span> <span class="p">[</span>                                           <span class="c1"># generator output nodes</span>
        <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$O_2$&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$\lambda_{1,2}$&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$O_3$&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$\lambda_{1,3}$&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$O_4$&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$\lambda_{1,4}$&quot;</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gen_outputs</span><span class="p">):</span>  
        <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
                <span class="n">bbox</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s2">&quot;circle&quot;</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
                    <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mf">0.05</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
                    <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">arrowstyle</span><span class="o">=</span><span class="s2">&quot;-&gt;&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">((</span><span class="n">x</span> <span class="o">+</span> <span class="mf">0.11</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">)</span>

    <span class="n">disc_inputs</span> <span class="o">=</span> <span class="p">[</span>                                           <span class="c1"># discriminator input nodes</span>
        <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$I_5$&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$\lambda_{5,8}$&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$I_6$&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$\lambda_{6,8}$&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$I_7$&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$\lambda_{7,8}$&quot;</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">disc_inputs</span><span class="p">):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
                <span class="n">bbox</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s2">&quot;circle&quot;</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
                    <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mf">0.05</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mf">0.35</span><span class="p">,</span> <span class="n">gen_outputs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]),</span>
                    <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">arrowstyle</span><span class="o">=</span><span class="s2">&quot;-&gt;&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$D_8$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="c1"># discriminator decision node</span>
            <span class="n">bbox</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s2">&quot;circle&quot;</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">disc_inputs</span><span class="p">):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
                    <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.65</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mf">0.05</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span>
                    <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">arrowstyle</span><span class="o">=</span><span class="s2">&quot;-&gt;&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">((</span><span class="n">x</span> <span class="o">+</span> <span class="mf">0.7</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">)</span>

    <span class="n">real_inputs</span> <span class="o">=</span> <span class="p">[</span>                                           <span class="c1"># real data path below generator</span>
        <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$I_5^</span><span class="si">{real}</span><span class="s2">$&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$I_6^</span><span class="si">{real}</span><span class="s2">$&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$I_7^</span><span class="si">{real}</span><span class="s2">$&quot;</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">real_inputs</span><span class="p">):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
                <span class="n">bbox</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s2">&quot;circle&quot;</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">))</span>
        <span class="c1"># Arrow to discriminator inputs</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
                    <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">disc_inputs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mf">0.05</span><span class="p">,</span> <span class="n">disc_inputs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]),</span> 
                    <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mf">0.05</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span>
                    <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">arrowstyle</span><span class="o">=</span><span class="s2">&quot;-&gt;&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors_real</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">))</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.57</span><span class="p">,</span> <span class="s2">&quot;Latent&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>    <span class="c1"># part labels</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.57</span><span class="p">,</span> <span class="s2">&quot;Classification&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.265</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.18</span><span class="p">,</span> <span class="s2">&quot;Real Images&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span><span class="n">rotation</span><span class="o">=</span><span class="mf">90.0</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.265</span><span class="p">,</span> <span class="mf">0.38</span><span class="p">,</span> <span class="s2">&quot;Fake Images&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span><span class="n">rotation</span><span class="o">=</span><span class="mf">90.0</span><span class="p">)</span>

    <span class="n">fancybox</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.07</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">),</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Generator&quot;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">)</span>
    <span class="n">fancybox</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.48</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">),</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.29</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Discriminator&quot;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.68</span><span class="p">,</span><span class="mf">0.4</span><span class="p">,</span><span class="s1">&#39;c&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>           <span class="c1"># draw the biases</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.695</span><span class="p">,</span> <span class="mf">0.47</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mf">0.685</span><span class="p">,</span> <span class="mf">0.42</span><span class="p">),</span><span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">arrowstyle</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.08</span><span class="p">,</span><span class="mf">0.4</span><span class="p">,</span><span class="s1">&#39;b&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.095</span><span class="p">,</span> <span class="mf">0.472</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mf">0.085</span><span class="p">,</span> <span class="mf">0.42</span><span class="p">),</span><span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">arrowstyle</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">draw_gan_architecture_full</span><span class="p">()</span>                                  <span class="c1"># draw the GAN         </span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b9cda33562135d931de4cba645356ec67988f21d0d19a0230f142961a6b7402e.png" src="_images/b9cda33562135d931de4cba645356ec67988f21d0d19a0230f142961a6b7402e.png" />
</div>
</div>
<p>Now let’s walk-through all the parts of our example GAN and show all the math.</p>
</section>
<section id="generator-forward-pass">
<h2>Generator Forward Pass<a class="headerlink" href="#generator-forward-pass" title="Permalink to this heading">#</a></h2>
<p>First, let’s walk through the generator to go from a latent value to a fake image. The generator takes a latent input,</p>
<div class="math notranslate nohighlight">
\[
z \sim \mathcal{U}(0.4, 1)
\]</div>
<p>Our simple generator has only one layer (L1), with only 3 outputs, <span class="math notranslate nohighlight">\(O_2\)</span>, <span class="math notranslate nohighlight">\(O_3\)</span>, and <span class="math notranslate nohighlight">\(O_4\)</span>, representing the fake image.</p>
<ul class="simple">
<li><p>Our transpose convolution kernel has a size of 3, so we don’t see it translate, resulting in simplified book keeping!</p></li>
<li><p>The kernel weights are <span class="math notranslate nohighlight">\(\lambda_{1,2}\)</span>, <span class="math notranslate nohighlight">\(\lambda_{1,3}\)</span>, and <span class="math notranslate nohighlight">\(\lambda_{1,4}\)</span></p></li>
<li><p>We apply the sigmoid activation in each of the output nodes</p></li>
</ul>
<p>Each output is computed by applying a linear transformation followed by a <strong>sigmoid</strong> activation, <span class="math notranslate nohighlight">\(\sigma\)</span>,</p>
<div class="math notranslate nohighlight">
\[
O_2 = \sigma(\lambda_{1,2} \cdot z + b)
\]</div>
<div class="math notranslate nohighlight">
\[
O_3 = \sigma(\lambda_{1,3} \cdot z + b)
\]</div>
<div class="math notranslate nohighlight">
\[
O_4 = \sigma(\lambda_{1,4} \cdot z + b)
\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\lambda_{1,j}\)</span> are the transpose convolution kernel weights</p></li>
<li><p><span class="math notranslate nohighlight">\(b\)</span> is the shared bias, single bias term for the output layer</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma(x) = \dfrac{1}{1 + e^{-x}}\)</span> is the sigmoid activation function</p></li>
</ul>
<p>We can also write the generator forward pass in matrix notation as,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
O_2 \\
O_3 \\
O_4
\end{bmatrix}
=
\sigma\left(
\begin{bmatrix}
\lambda_{1,2} \\
\lambda_{1,3} \\
\lambda_{1,4}
\end{bmatrix}
z + 
\begin{bmatrix}
b \\
b \\
b
\end{bmatrix}
\right)
\end{split}\]</div>
<p>where the sigmoid activation is applied element-wise.</p>
</section>
<section id="discriminator-forward-pass">
<h2>Discriminator Forward Pass<a class="headerlink" href="#discriminator-forward-pass" title="Permalink to this heading">#</a></h2>
<p>Now let’s walk-through the discriminator, going from an image, real or fake, to a probability of real. The discriminator receives the image, over 3 input nodes, <span class="math notranslate nohighlight">\(I_5\)</span>, <span class="math notranslate nohighlight">\(I_6\)</span>, and <span class="math notranslate nohighlight">\(I_7\)</span>. In the case of a fake image,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
I_5 \\
I_6 \\
I_7
\end{bmatrix}
=
\begin{bmatrix}
O_2 \\
O_3 \\
O_4
\end{bmatrix}
\end{split}\]</div>
<p>and in the case of a real image,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
I_5 \\
I_6 \\
I_7
\end{bmatrix}
=
\begin{bmatrix}
I_5^{real} \\
I_6^{real} \\
I_7^{real}
\end{bmatrix}
\end{split}\]</div>
<p>Since we have only 1 layer and the convolution kernel is 3 with an input of 3 once again there is no translation!</p>
<ul class="simple">
<li><p>we just take input image, <span class="math notranslate nohighlight">\(I_5\)</span>, <span class="math notranslate nohighlight">\(I_6\)</span>, and <span class="math notranslate nohighlight">\(I_7\)</span>, and apply the convolutional kernel weights, <span class="math notranslate nohighlight">\(\lambda_{5,8}\)</span>, <span class="math notranslate nohighlight">\(\lambda_{6,8}\)</span>, and <span class="math notranslate nohighlight">\(\lambda_{7,8}\)</span>, and add the bias term, <span class="math notranslate nohighlight">\(c\)</span>,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
D_8 = \sigma\left(
\lambda_{5,8} \cdot I_5 +
\lambda_{6,8} \cdot I_6 +
\lambda_{7,8} \cdot I_7 + c
\right)
\]</div>
<p>where,</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\lambda_{i,8}\)</span> are the convolutional kernel weights to go from input image to next feature map, only 1 value, our output probability</p></li>
<li><p><span class="math notranslate nohighlight">\(c\)</span> is the bias term</p></li>
</ul>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\sigma(x) = \dfrac{1}{1 + e^{-x}}\)</span> is the sigmoid activation function</p></li>
</ul>
<p><span class="math notranslate nohighlight">\(D_8 \in [0, 1]\)</span> represents the probability assigned by the discriminator that the input is <strong>real</strong> (i.e. not a fake from the generator).</p>
<p>We can also write the discriminator forward pass in matrix notation as,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
D_8 = \sigma\left(
\begin{bmatrix}
\lambda_{5,8} &amp; \lambda_{6,8} &amp; \lambda_{7,8}
\end{bmatrix}
\cdot
\begin{bmatrix}
I_5 \\
I_6 \\
I_7
\end{bmatrix}
+ c
\right)
\end{split}\]</div>
<p>where,</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\lambda_{5,8}, \lambda_{6,8}, \lambda_{7,8}\)</span> are scalar weights</p></li>
<li><p><span class="math notranslate nohighlight">\(I_5, I_6, I_7\)</span> are the input values (i.e., outputs of the generator, <span class="math notranslate nohighlight">\(O_2, O_3, O_4\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(c\)</span> is the bias term</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma(x) = \dfrac{1}{1 + e^{-x}}\)</span> is the sigmoid function</p></li>
</ul>
</section>
<section id="discriminator-loss">
<h2>Discriminator Loss<a class="headerlink" href="#discriminator-loss" title="Permalink to this heading">#</a></h2>
<p>Binary cross-entropy is a loss function used for binary classification tasks where the output is a probability between 0 and 1, and the target label is either 0 or 1.</p>
<ul class="simple">
<li><p><strong>Prediction</strong> (model output) - <span class="math notranslate nohighlight">\(\hat{y} \in (0, 1)\)</span>, the output of <span class="math notranslate nohighlight">\(D_8\)</span>, the discriminator’s classification, probability that the image is real</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\hat{y} = D_8
\]</div>
<ul class="simple">
<li><p><strong>True label</strong> (ground truth) - <span class="math notranslate nohighlight">\(y \in \{0, 1\}\)</span>, 0 if the image is from the generator, fake, and 1 if the image is from the real training data</p></li>
</ul>
<p>Now we can define the <strong>binary cross-entropy loss</strong> as,</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}_{\text{BCE}}(y, \hat{y}) = - \left[ y \cdot \log(\hat{y}) + (1 - y) \cdot \log(1 - \hat{y}) \right]
\]</div>
<p>now we can further specify,</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\log(\hat{y})\)</span> is the log-likelihood of the positive prediction</p></li>
<li><p><span class="math notranslate nohighlight">\(log(1 - \hat{y})\)</span> is the log-likelihood of the negative prediction</p></li>
</ul>
<p>how does binary cross-entropy behave?</p>
<ul class="simple">
<li><p>if <span class="math notranslate nohighlight">\(y = 1\)</span> (real image), then:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathcal{L} = -\log(\hat{y}) \quad \text{(we want } \hat{y} \to 1)
\]</div>
<ul class="simple">
<li><p>if <span class="math notranslate nohighlight">\(y = 0\)</span> (fake image from the generator), then:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathcal{L} = -\log(1 - \hat{y}) \quad \text{(we want } \hat{y} \to 0)
\]</div>
<p>We can summarize as,</p>
<ul class="simple">
<li><p>the loss is <strong>low</strong> when the model’s prediction ( \hat{y} ) is <strong>close to the true label</strong>, low probability of real for a fake image and high probability of real for a real image</p></li>
<li><p>the loss becomes <strong>very large</strong> if the model is <strong>confident and wrong</strong>, due to the logarithm, i.e., very low probability or real for a real image and very high probability of real for a fake image</p></li>
<li><p>the sigmoid activation ensures that the output, <span class="math notranslate nohighlight">\(\hat{y}\)</span> is a valid probability</p></li>
</ul>
</section>
<section id="discriminator-loss-derivative">
<h2>Discriminator Loss Derivative<a class="headerlink" href="#discriminator-loss-derivative" title="Permalink to this heading">#</a></h2>
<p>To perform backpropagation we need to calculate the loss derivative. Let’s do this for the input of the activation function as our output node, <span class="math notranslate nohighlight">\(D_8\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}}{dz}
\]</div>
<ul class="simple">
<li><p>define <span class="math notranslate nohighlight">\(z\)</span> as the input for the sigmoid activation as output node, <span class="math notranslate nohighlight">\(D_8\)</span>.</p></li>
<li><p>as you see we do this because it results in a very simple, efficient result.</p></li>
<li><p>recall, the sigmoid function,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\hat{y} = \sigma(z) = \frac{1}{1 + e^{-z}}
\]</div>
<p>We will use the chain rule, so we only need to solve the parts,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}}{dz} = \frac{d\mathcal{L}}{d\hat{y}} \cdot \frac{d\hat{y}}{dz}
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\frac{d\mathcal{L}}{d\hat{y}}\)</span> - partial derivative of binary cross-entropy loss given the discriminator output <span class="math notranslate nohighlight">\(\hat{y}\)</span> (<span class="math notranslate nohighlight">\(D_8\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(\frac{d\hat{y}}{dz}\)</span> - partial derivative of the discriminator output <span class="math notranslate nohighlight">\(\hat{y}\)</span> (<span class="math notranslate nohighlight">\(D_8\)</span>) given the sigmoid activation input</p></li>
</ul>
<p>Now we can solve the first part, partial derivative of loss with respect to the discriminator output, <span class="math notranslate nohighlight">\(\hat{y}\)</span></p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}}{d\hat{y}} = -\left( \frac{y}{\hat{y}} - \frac{1 - y}{1 - \hat{y}} \right)
\]</div>
<p>now we can solve the second part, the partial derivative of the discriminator output <span class="math notranslate nohighlight">\(\hat{y}\)</span> (<span class="math notranslate nohighlight">\(D_8\)</span>) given the sigmoid activation input, it is just the sigmoid derivative,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\hat{y}}{dz} = \hat{y}(1 - \hat{y})
\]</div>
<p>and we can combine these by the chain rule as,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}}{dz} = -\left( \frac{y}{\hat{y}} - \frac{1 - y}{1 - \hat{y}} \right) \cdot \hat{y}(1 - \hat{y})
\]</div>
<p>We are almost there, we only need to simplify the result, first we distribute, <span class="math notranslate nohighlight">\(\hat{y}(1 - \hat{y})\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}}{dz} = -\left[ y(1 - \hat{y}) - (1 - y)\hat{y} \right]
\]</div>
<p>and then simplify it further,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}}{dz} = -\left[ y - y\hat{y} - \hat{y} + y\hat{y} \right]
= -\left[ y - \hat{y} \right]
= \hat{y} - y
\]</div>
<p>I said this would get simple! Our partial derivative of our loss with respect to the input to the output node sigmoid activation function, <span class="math notranslate nohighlight">\(z\)</span>, is,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}}{dz} = \hat{y} - y
\]</div>
<p>This result shows the gradient is just the <strong>error</strong> — the difference between predicted and true values.</p>
<p>Now we can make this simple interpretation,</p>
<ul class="simple">
<li><p>if <span class="math notranslate nohighlight">\(\hat{y} &gt; y\)</span>, the model overestimates <span class="math notranslate nohighlight">\(\rightarrow\)</span> gradient is positive <span class="math notranslate nohighlight">\(\rightarrow\)</span> lower prediction by moving in the negative gradient</p></li>
<li><p>if <span class="math notranslate nohighlight">\(\hat{y} &lt; y\)</span>, the model underestimates <span class="math notranslate nohighlight">\(\rightarrow\)</span> gradient is negative <span class="math notranslate nohighlight">\(\rightarrow\)</span> increase prediction by moving in the negative gradient</p></li>
</ul>
<p>I know that a title this section “Discriminator Loss Derivative”, but excuse me for performing just a little bit of backpropagation (to before sigmoid activation).</p>
<ul class="simple">
<li><p>next we carry on with back propagation to the discriminator weights and biases</p></li>
</ul>
</section>
<section id="discriminator-back-propagation">
<h2>Discriminator Back Propagation<a class="headerlink" href="#discriminator-back-propagation" title="Permalink to this heading">#</a></h2>
<p>For compact notation, let’s use matrix notation and define the input to the <span class="math notranslate nohighlight">\(D_8\)</span> activation, <span class="math notranslate nohighlight">\(z\)</span>, as,</p>
<div class="math notranslate nohighlight">
\[
z = \mathbf{w}^\top \mathbf{x} + c \quad \Rightarrow \quad \frac{dz}{d\mathbf{w}} = \mathbf{x}
\]</div>
<p>Now we can extend our use of the chain rule to,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}}{d\mathbf{w}} = \frac{d\mathcal{L}}{dz} \cdot \frac{dz}{d\mathbf{w}} = (\hat{y} - y) \cdot \mathbf{x}
\]</div>
<p>So for each of our discriminator weights, <span class="math notranslate nohighlight">\(\lambda_{5,8}\)</span>, <span class="math notranslate nohighlight">\(\lambda_{6,8}\)</span>, and <span class="math notranslate nohighlight">\(\lambda_{7,8}\)</span> we have,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}}{d\lambda_{5,8}} = (\hat{y} - y) \cdot I_5
\]</div>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}}{d\lambda_{6,8}} = (\hat{y} - y) \cdot I_6
\]</div>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}}{d\lambda_{7,8}} = (\hat{y} - y) \cdot I_7
\]</div>
<p>and for the bias, <span class="math notranslate nohighlight">\(c\)</span>, we calculate the next component for the chain rule as,</p>
<div class="math notranslate nohighlight">
\[
\frac{dz}{dc} = 1
\]</div>
<p>so we have,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}}{dc} = \frac{d\mathcal{L}}{dz} \cdot \frac{dz}{dc} = (\hat{y} - y) \cdot 1 = \hat{y} - y
\]</div>
<p>The backpropagation for our very simple discriminator is quite simple, we can summarize for the weights,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}}{d\mathbf{w}} = (\hat{y} - y) \cdot \mathbf{x}
\]</div>
<p>and for the bias,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}}{dc} = \hat{y} - y
\]</div>
<p>Let’s write these out for all of our discriminators parameters,
$<span class="math notranslate nohighlight">\(
\begin{aligned}
\frac{d\mathcal{L}}{d\lambda_{5,8}} &amp;= (\hat{y} - y) \cdot I_5 \\
\frac{d\mathcal{L}}{d\lambda_{6,8}} &amp;= (\hat{y} - y) \cdot I_6 \\
\frac{d\mathcal{L}}{d\lambda_{7,8}} &amp;= (\hat{y} - y) \cdot I_7 \\
\frac{d\mathcal{L}}{dc} &amp;= \hat{y} - y
\end{aligned}
\)</span>$</p>
</section>
<section id="generator-loss-derivative-and-back-propagation-through-the-discriminator">
<h2>Generator Loss Derivative and Back Propagation Through the Discriminator<a class="headerlink" href="#generator-loss-derivative-and-back-propagation-through-the-discriminator" title="Permalink to this heading">#</a></h2>
<p>Recall that the goal of the generator is to make fake images the discriminator assigns as a high probability of a real image, i.e., to fool the discriminator</p>
<ul class="simple">
<li><p>the generator produces a fake image,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ 
\tilde{\mathbf{x}} = G(z) 
\]</div>
<p><span class="math notranslate nohighlight">\(\quad\)</span> where ( z ) is a latent vector (e.g., sampled from Uniform[0.4, 1]).</p>
<ul class="simple">
<li><p>the discriminator evaluates this fake sample and returns:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\hat{y} = D(\tilde{\mathbf{x}}) \in (0, 1)
\]</div>
<p>Now we can calculate the binary cross-entropy for the generator as,</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}_G = -\log(\hat{y})
\]</div>
<p>where,</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\hat{y} = D(G(z))\)</span>, the discriminator’s evaluation of the generator’s fake image, <span class="math notranslate nohighlight">\(z\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{y}\)</span> is the probability assigned by the discriminator to the fake being real</p></li>
</ul>
<p>This is equivalent to cross-entropy with <strong>target label ( y = 1 )</strong></p>
<p>Let’s show how to back propagate through the entire discriminator with the chain rule.</p>
<ul class="simple">
<li><p>we want the generator loss gradient with respect generator output,</p></li>
</ul>
<p>Given <span class="math notranslate nohighlight">\(\tilde{\mathbf{x}} = G(z)\)</span>, our fake image, we want the partial derivative of the loss given our fake image,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}}
\]</div>
<p>and by the chain rule,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} = \frac{d\mathcal{L}_G}{d\hat{y}} \cdot \frac{d\hat{y}}{d\tilde{\mathbf{x}}}
\]</div>
<p>This is how the discriminator’s belief <span class="math notranslate nohighlight">\(\hat{y}\)</span>​ about “fakeness” changes with changes in <span class="math notranslate nohighlight">\(\tilde{\mathbf{x}}\)</span> the fake image.</p>
<p>Now we are ready to back propagate the generator loss through the discriminator, let’s start with our generator loss (from above),</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}_G = -\log(\hat{y})
\]</div>
<p>and when we perform the partial derivative,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}_G}{d\hat{y}} = -\frac{1}{\hat{y}}
\]</div>
<p>Now, recall the discriminator’s forward pass is,</p>
<div class="math notranslate nohighlight">
\[
\hat{y} = \sigma(\mathbf{w}^\top \tilde{\mathbf{x}} + c)
\]</div>
<p>so we can calculate the partial derivative of the discriminator’s output with respect to the generator’s fake image as,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\hat{y}}{d\tilde{\mathbf{x}}} = \hat{y}(1 - \hat{y}) \cdot \mathbf{w}
\]</div>
<p>now we combine these with the chain rule as,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}}
= \left( -\frac{1}{\hat{y}} \right) \cdot \left( \hat{y}(1 - \hat{y}) \cdot \mathbf{w} \right)
= -(1 - \hat{y}) \cdot \mathbf{w}
\]</div>
<p>The gradient of the generator’s loss with respect to the output image <span class="math notranslate nohighlight">\(\tilde{\mathbf{x}}\)</span> is,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} = -(1 - \hat{y}) \cdot \mathbf{w}
\]</div>
<p>We can add some interpretations of this result,</p>
<ul class="simple">
<li><p>when <span class="math notranslate nohighlight">\(\hat{y}\)</span> is close to 0 <span class="math notranslate nohighlight">\(\rightarrow\)</span> discriminator easily spots fake <span class="math notranslate nohighlight">\(\rightarrow\)</span> large gradient <span class="math notranslate nohighlight">\(\rightarrow\)</span> generator updates more.</p></li>
<li><p>when <span class="math notranslate nohighlight">\(\hat{y}\)</span> is close to 1 <span class="math notranslate nohighlight">\(\rightarrow\)</span> generator is fooling the discriminator <span class="math notranslate nohighlight">\(\rightarrow\)</span> gradient is small.</p></li>
</ul>
<p>This guides the generator to tweak its output to increase <span class="math notranslate nohighlight">\(\hat{y}\)</span> — i.e., fool the discriminator.</p>
<p>To further clarify, for our example let’s compute how the discriminator’s output <span class="math notranslate nohighlight">\(\hat{y}\)</span> changes with respect to the generator outputs <span class="math notranslate nohighlight">\(O_5, O_6, O_7\)</span>, instead of the <span class="math notranslate nohighlight">\(w\)</span> vector notation used above.</p>
<ul class="simple">
<li><p>if we apply the chain rule we get,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\frac{d\hat{y}}{dO_i} = \frac{d\hat{y}}{dz} \cdot \frac{dz}{dO_i}
\]</div>
<p><span class="math notranslate nohighlight">\(\quad\)</span> for each of the components we have,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\hat{y}}{dz} = \hat{y}(1 - \hat{y})
\]</div>
<div class="math notranslate nohighlight">
\[
\frac{dz}{dO_5} = \lambda_{5,8}
\]</div>
<div class="math notranslate nohighlight">
\[
\frac{dz}{dO_6} = \lambda_{6,8}
\]</div>
<div class="math notranslate nohighlight">
\[
\frac{dz}{dO_7} = \lambda_{7,8}
\]</div>
<p><span class="math notranslate nohighlight">\(\quad\)</span> substituting in the chain rule we have,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\hat{y}}{dO_5} = \hat{y}(1 - \hat{y}) \cdot \lambda_{5,8}
\]</div>
<div class="math notranslate nohighlight">
\[
\frac{d\hat{y}}{dO_6} = \hat{y}(1 - \hat{y}) \cdot \lambda_{6,8}
\]</div>
<div class="math notranslate nohighlight">
\[
\frac{d\hat{y}}{dO_7} = \hat{y}(1 - \hat{y}) \cdot \lambda_{7,8}
\]</div>
</section>
<section id="backpropagation-through-generator-to-weights-and-bias">
<h2>Backpropagation Through Generator to Weights and Bias<a class="headerlink" href="#backpropagation-through-generator-to-weights-and-bias" title="Permalink to this heading">#</a></h2>
<p>We now propagate through the generators sigmoid activation in each of the output nodes,</p>
<div class="math notranslate nohighlight">
\[
\frac{dO_i}{dz_i} = O_i (1 - O_i)
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(O_i = \sigma(z_i)\)</span>, where <span class="math notranslate nohighlight">\(z_i\)</span> is the input for the output nodes, pre-activation, and <span class="math notranslate nohighlight">\(O_i\)</span> is output for the output nodes, post-activation</p></li>
</ul>
<p>We Apply chain rule,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}_G}{dz_i} = \frac{d\mathcal{L}_G}{dO_i} \cdot \frac{dO_i}{dz_i}
= \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1 - O_i)
\]</div>
<p>Recall,</p>
<div class="math notranslate nohighlight">
\[
z_i = \lambda_{1,i} \cdot L_1 + b
\]</div>
<p>so we can calculate the generator’s weights partial derivatives as,</p>
<div class="math notranslate nohighlight">
\[
\frac{dz_i}{d\lambda_{1,i}} = L_1
\]</div>
<p>and the generator’s bias partial derivative as,</p>
<div class="math notranslate nohighlight">
\[
\frac{dz_i}{db} = 1
\]</div>
<p>Now we can put this all together with the chain rule, the partial derivatives of the generator loss with respect to the generator weights are,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}_G}{d\lambda_{1,i}} =
\frac{d\mathcal{L}_G}{dz_i} \cdot \frac{dz_i}{d\lambda_{1,i}} =
\left( \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1 - O_i) \right) \cdot L_1
\]</div>
<p>and the partial derivative of the generator loss with respect to the generator bias is,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}_G}{db} =
\sum_{i=5}^7 \frac{d\mathcal{L}_G}{dz_i} \cdot \frac{dz_i}{db} =
\sum_{i=5}^7 \left( \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1 - O_i) \right)
\]</div>
<p>For clarity, let’s write this out for each of our generator’s weights,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}_G}{d\lambda_{1,2}} =
-(1 - \hat{y}) \cdot \lambda_{5,8} \cdot O_5 (1 - O_5) \cdot L_1
\]</div>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}_G}{d\lambda_{1,3}} =
-(1 - \hat{y}) \cdot \lambda_{6,8} \cdot O_6 (1 - O_6) \cdot L_1
\]</div>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}_G}{d\lambda_{1,4}} =
-(1 - \hat{y}) \cdot \lambda_{7,8} \cdot O_7 (1 - O_7) \cdot L_1
\]</div>
<p>and for our generator’s bias,</p>
<div class="math notranslate nohighlight">
\[
\frac{d\mathcal{L}_G}{db} =
-(1 - \hat{y}) \cdot \left[
\lambda_{5,8} \cdot O_5(1 - O_5)
+ \lambda_{6,8} \cdot O_6(1 - O_6)
+ \lambda_{7,8} \cdot O_7(1 - O_7)
\right]
\]</div>
<p>Let’s make some interpretations,</p>
<ul class="simple">
<li><p>the generator’s weights and bias gradients scale with how much the discriminator is fooled (<span class="math notranslate nohighlight">\(1 - \hat{y}\)</span>)</p></li>
<li><p>the generator learns to tweak <span class="math notranslate nohighlight">\(\lambda_{1,i}\)</span> and <span class="math notranslate nohighlight">\(b\)</span> to push the fake images, <span class="math notranslate nohighlight">\(O_5\)</span>, <span class="math notranslate nohighlight">\(O_6\)</span> and <span class="math notranslate nohighlight">\(O_7\)</span> in directions that increase <span class="math notranslate nohighlight">\(\hat{y}\)</span></p></li>
<li><p>this flow of error gives the generator a signal to <strong>fool the discriminator more effectively</strong> without ever seeing a real image!</p></li>
</ul>
</section>
<section id="simple-gan-training-workflow">
<h2>Simple GAN Training Workflow<a class="headerlink" href="#simple-gan-training-workflow" title="Permalink to this heading">#</a></h2>
<p>We start with initialization of the generator and discriminator weights and bias and setting the training hyperparameters.</p>
<ol class="arabic simple">
<li><p>Generate the Synthethic, “Real Images” for training</p></li>
</ol>
<ul class="simple">
<li><p>sample <span class="math notranslate nohighlight">\(N\)</span> real 3-node, 1D images <span class="math notranslate nohighlight">\(\mathbf{I} = \{(I_{5,i}, I_{6,i}, I_{7,i})\}_{i=1}^N\)</span></p></li>
<li><p>use the synthetic training data function:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\text{Real images} \sim \text{linear decreasing trend} + \text{noise}
\]</div>
<ol class="arabic simple" start="2">
<li><p><strong>Initialize generator weights and bias</strong> - the weights,</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\{\lambda_{1,2}, \lambda_{1,3}, \lambda_{1,4}, b\} \leftarrow \text{small random values}
\]</div>
<p><span class="math notranslate nohighlight">\(\quad\)</span> and the bias,</p>
<div class="math notranslate nohighlight">
\[
b \leftarrow 0.0
\]</div>
<ol class="arabic simple" start="3">
<li><p><strong>Initialize discriminator weights and bias</strong> - the weights,</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\{\lambda_{5,8}, \lambda_{6,8}, \lambda_{7,8}, c\} \leftarrow \text{small random values}
\]</div>
<p><span class="math notranslate nohighlight">\(\quad\)</span> and the bias,</p>
<div class="math notranslate nohighlight">
\[
c \leftarrow 0.0
\]</div>
<ol class="arabic simple" start="4">
<li><p><strong>Set model training hyperparameters</strong> - this includes,</p></li>
</ol>
<ul class="simple">
<li><p>Learning Rates - for the generator, <span class="math notranslate nohighlight">\(\eta_G\)</span>, and discriminator, <span class="math notranslate nohighlight">\(\eta_D\)</span></p></li>
<li><p>Batch Size - in this example we are assuming batch size equal to the number of real images</p></li>
<li><p>Epochs - number of training iterations</p></li>
</ul>
<ol class="arabic simple" start="5">
<li><p><strong>Train the discriminator</strong></p></li>
</ol>
<ul class="simple">
<li><p>combine real and fake inputs into a batch of size <span class="math notranslate nohighlight">\(2N\)</span> and inlcude labels <span class="math notranslate nohighlight">\(y_i = 1\)</span> for real, <span class="math notranslate nohighlight">\(y_i = 0\)</span> for fake</p></li>
<li><p>compute discriminator outputs <span class="math notranslate nohighlight">\(\hat{y}_i = D(I_{5,i}, I_{6,i}, I_{7,i})\)</span></p></li>
<li><p>calculate discriminator loss and gradients using:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\frac{\partial \mathcal{L}}{\partial \lambda_{j,8}}, \quad \frac{\partial \mathcal{L}}{\partial c}
\]</div>
<ul class="simple">
<li><p>update discriminator weights and bias:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\lambda_{j,8} \leftarrow \lambda_{j,8} - \eta_D \times \frac{\partial \mathcal{L}}{\partial \lambda_{j,8}}, \quad
  c \leftarrow c - \eta_D \times \frac{\partial \mathcal{L}}{\partial c}
\]</div>
<ol class="arabic simple" start="5">
<li><p><strong>Train the generator</strong></p></li>
</ol>
<ul class="simple">
<li><p>Compute generator output fake images and pass to the discriminator to evaluate the outputs on these fakes, <span class="math notranslate nohighlight">\(D_8\)</span> same as <span class="math notranslate nohighlight">\(y\)</span></p></li>
<li><p>Calculate generator loss gradients using,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\frac{\partial \mathcal{L}_G}{\partial \lambda_{1,j}}, \quad \frac{\partial \mathcal{L}_G}{\partial b}
\]</div>
<ul class="simple">
<li><p>Update generator weights and bias,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\lambda_{1,j} \leftarrow \lambda_{1,j} - \eta_G \times \frac{\partial \mathcal{L}_G}{\partial \lambda_{1,j}}, \quad
  b \leftarrow b - \eta_G \times \frac{\partial \mathcal{L}_G}{\partial b}
\]</div>
<ol class="arabic simple" start="6">
<li><p><strong>Repeat Until Convergence</strong> - or stop criteria is met, such as maximum number of training epochs, return to step 5.</p></li>
</ol>
<p>Here a summary of the training loop,</p>
<ol class="arabic simple">
<li><p>Generate real data batch</p></li>
<li><p>Generate fake data batch</p></li>
<li><p>Update discriminator to better distinguish real/fake</p></li>
<li><p>Update generator to fool discriminator</p></li>
<li><p>Repeat</p></li>
</ol>
<p>This adversarial training loop lets the generator learn to create data mimicking the real distribution, and the discriminator improve in spotting fakes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_gan</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span><span class="n">lr_g</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span><span class="n">lr_d</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span> <span class="c1"># function for training the GAN</span>
    <span class="n">weights_epoch_list</span> <span class="o">=</span> <span class="p">[];</span> <span class="n">weights_g_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Initialize weights</span>
    <span class="n">weights_g</span> <span class="o">=</span> <span class="n">initialize_generator_weights</span><span class="p">()</span>
    <span class="n">weights_d</span> <span class="o">=</span> <span class="n">initialize_discriminator_weights</span><span class="p">()</span>
    
    <span class="c1"># Tracking losses</span>
    <span class="n">generator_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">discriminator_losses</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">real_images</span> <span class="o">=</span> <span class="n">generate_real_data</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> <span class="c1"># one set of images</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="c1"># Step 1: Generate real data</span>

        <span class="n">I5_real</span><span class="p">,</span> <span class="n">I6_real</span><span class="p">,</span> <span class="n">I7_real</span> <span class="o">=</span> <span class="n">real_images</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">real_images</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">real_images</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">y_real</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

        <span class="c1"># Step 2: Generate fake data</span>
        <span class="n">L1_fake</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">fake_images</span> <span class="o">=</span> <span class="n">generator_forward</span><span class="p">(</span><span class="n">L1_fake</span><span class="p">,</span> <span class="n">weights_g</span><span class="p">)</span>
        <span class="n">I5_fake</span><span class="p">,</span> <span class="n">I6_fake</span><span class="p">,</span> <span class="n">I7_fake</span> <span class="o">=</span> <span class="n">fake_images</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">fake_images</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">fake_images</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">y_fake</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

        <span class="c1"># Combine for discriminator training</span>
        <span class="n">I5_combined</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">I5_real</span><span class="p">,</span> <span class="n">I5_fake</span><span class="p">])</span>
        <span class="n">I6_combined</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">I6_real</span><span class="p">,</span> <span class="n">I6_fake</span><span class="p">])</span>
        <span class="n">I7_combined</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">I7_real</span><span class="p">,</span> <span class="n">I7_fake</span><span class="p">])</span>
        <span class="n">y_combined</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">y_real</span><span class="p">,</span> <span class="n">y_fake</span><span class="p">])</span>

        <span class="c1"># Step 3: Train discriminator</span>
        <span class="n">grads_d</span> <span class="o">=</span> <span class="n">discriminator_gradients</span><span class="p">(</span><span class="n">I5_combined</span><span class="p">,</span> <span class="n">I6_combined</span><span class="p">,</span> <span class="n">I7_combined</span><span class="p">,</span> <span class="n">y_combined</span><span class="p">,</span> <span class="n">weights_d</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">weights_d</span><span class="p">:</span>
            <span class="n">weights_d</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">-=</span> <span class="n">lr_d</span> <span class="o">*</span> <span class="n">grads_d</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

        <span class="c1"># Step 4: Train generator</span>
        <span class="n">L1_gen</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">grads_g</span> <span class="o">=</span> <span class="n">generator_gradients</span><span class="p">(</span><span class="n">L1_gen</span><span class="p">,</span> <span class="n">weights_g</span><span class="p">,</span> <span class="n">weights_d</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">weights_g</span><span class="p">:</span>
            <span class="n">weights_g</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">-=</span> <span class="n">lr_g</span> <span class="o">*</span> <span class="n">grads_g</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="c1"># if epoch in [1000,2500,5000]: # save the weights to visualize model improvement over epochs</span>
            <span class="c1"># weights_g_list.append(weights_g)</span>
        
        <span class="c1"># Step 5: Calculate and store losses</span>
        <span class="n">y_pred_real</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">discriminator_forward</span><span class="p">(</span><span class="n">I5_real</span><span class="p">,</span> <span class="n">I6_real</span><span class="p">,</span> <span class="n">I7_real</span><span class="p">,</span> <span class="n">weights_d</span><span class="p">)</span>
        <span class="n">y_pred_fake</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">discriminator_forward</span><span class="p">(</span><span class="n">I5_fake</span><span class="p">,</span> <span class="n">I6_fake</span><span class="p">,</span> <span class="n">I7_fake</span><span class="p">,</span> <span class="n">weights_d</span><span class="p">)</span>
        <span class="n">loss_d_real</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_pred_real</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">))</span>
        <span class="n">loss_d_fake</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y_pred_fake</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">))</span>
        <span class="n">loss_d</span> <span class="o">=</span> <span class="n">loss_d_real</span> <span class="o">+</span> <span class="n">loss_d_fake</span>
        <span class="n">discriminator_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_d</span><span class="p">)</span>

        <span class="n">y_pred_gen</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">discriminator_forward</span><span class="p">(</span><span class="o">*</span><span class="n">generator_forward</span><span class="p">(</span><span class="n">L1_gen</span><span class="p">,</span> <span class="n">weights_g</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">weights_d</span><span class="p">)</span>
        <span class="n">loss_g</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_pred_gen</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">))</span>
        <span class="n">generator_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_g</span><span class="p">)</span>

        <span class="c1"># Print progress</span>
        <span class="k">if</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">epoch</span> <span class="o">==</span> <span class="n">epochs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">weights_epoch_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
            <span class="n">weights_g_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">weights_g</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">: D_loss = </span><span class="si">{</span><span class="n">loss_d</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, G_loss = </span><span class="si">{</span><span class="n">loss_g</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># # Final output</span>
    <span class="c1"># print(&quot;\nTraining complete.\nFinal Generator Weights:&quot;)</span>
    <span class="c1"># for k, v in weights_g.items():</span>
    <span class="c1">#     print(f&quot;  {k}: {v:.4f}&quot;)</span>
    
    <span class="c1"># print(&quot;\nFinal Discriminator Weights:&quot;)</span>
    <span class="c1"># for k, v in weights_d.items():</span>
    <span class="c1">#     print(f&quot;  {k}: {v:.4f}&quot;)</span>

    <span class="k">return</span> <span class="n">weights_g</span><span class="p">,</span> <span class="n">weights_d</span><span class="p">,</span> <span class="n">generator_losses</span><span class="p">,</span> <span class="n">discriminator_losses</span><span class="p">,</span> <span class="n">real_images</span><span class="p">,</span> <span class="n">weights_g_list</span><span class="p">,</span> <span class="n">weights_epoch_list</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">final_weights_g</span><span class="p">,</span> <span class="n">final_weights_d</span><span class="p">,</span> <span class="n">loss_g</span><span class="p">,</span> <span class="n">loss_d</span><span class="p">,</span> <span class="n">real_images</span><span class="p">,</span> <span class="n">weights_g_list</span><span class="p">,</span> <span class="n">weights_epoch_list</span> <span class="o">=</span> <span class="n">train_gan</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">lr_g</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">lr_d</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">loss_g</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Generator&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">loss_d</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Discriminator&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">epochs</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">2.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 0: D_loss = 1.3181, G_loss = 0.6909
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1000: D_loss = 1.2445, G_loss = 0.6723
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2000: D_loss = 1.2650, G_loss = 0.6292
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3000: D_loss = 1.2955, G_loss = 0.6195
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4000: D_loss = 1.2948, G_loss = 0.6584
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5000: D_loss = 1.3010, G_loss = 0.6991
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6000: D_loss = 1.3335, G_loss = 0.6973
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7000: D_loss = 1.4199, G_loss = 0.6486
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8000: D_loss = 1.4667, G_loss = 0.5782
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9000: D_loss = 1.5111, G_loss = 0.5936
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9999: D_loss = 1.4460, G_loss = 0.6302
</pre></div>
</div>
<img alt="_images/20883611b90b0f953f930771b5a8bd601f413b3124ae6e2b6ff6a3b77b778aa2.png" src="_images/20883611b90b0f953f930771b5a8bd601f413b3124ae6e2b6ff6a3b77b778aa2.png" />
</div>
</div>
</section>
<section id="visualize-real-images-and-trained-generator-fake-images">
<h2>Visualize Real Images and Trained Generator Fake Images<a class="headerlink" href="#visualize-real-images-and-trained-generator-fake-images" title="Permalink to this heading">#</a></h2>
<p>Let’s check a set of fake images from our trained generator against the real images.</p>
<ul class="simple">
<li><p>recall the generator never saw these images, the discriminator saw the real and fake images and told the generator how good or bad were the generator’s fake images.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">L1_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span> 
<span class="n">trained_fake</span> <span class="o">=</span> <span class="n">generator_forward</span><span class="p">(</span><span class="n">L1_test</span><span class="p">,</span> <span class="n">weights_g_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">untrained_fake</span> <span class="o">=</span> <span class="n">generator_forward</span><span class="p">(</span><span class="n">L1_test</span><span class="p">,</span> <span class="n">weights_g_list</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">batch_size</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">real_images</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">real_images</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Real Images&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Node&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">batch_size</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trained_fake</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">trained_fake</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Trained Generator Fake Images&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Node&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/23aaf1fce6eb82054c0d400153aec8c52ee7bcfacab67cf4abc33aa9e946f388.png" src="_images/23aaf1fce6eb82054c0d400153aec8c52ee7bcfacab67cf4abc33aa9e946f388.png" />
</div>
</div>
</section>
<section id="visualize-real-images-and-generator-fake-images-over-training-epochs">
<h2>Visualize Real Images and Generator Fake Images Over Training Epochs<a class="headerlink" href="#visualize-real-images-and-generator-fake-images-over-training-epochs" title="Permalink to this heading">#</a></h2>
<p>It is interesting to see how our generator’s fake images evolve over the training epochs.</p>
<ul class="simple">
<li><p>as first the fake images are random due to the random initialization of the generator’s weights and bias</p></li>
<li><p>as the training proceeds the generator learns to improve the fake images.</p></li>
</ul>
<p>I include the real images at the end for comparison.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">weights_g</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">weights_g_list</span><span class="p">):</span>
    <span class="n">fake</span> <span class="o">=</span> <span class="n">generator_forward</span><span class="p">(</span><span class="n">L1_test</span><span class="p">,</span> <span class="n">weights_g_list</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fake</span><span class="p">[</span><span class="n">j</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">fake</span><span class="p">[</span><span class="n">j</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Fake Images: Training Epoch &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">weights_epoch_list</span><span class="p">[</span><span class="n">i</span><span class="p">]));</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Node&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">12</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">batch_size</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">real_images</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">real_images</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Real Images&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Node&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">3.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ca71df0d300fff9ff2c2772bec3d93d556f4435bfcb9f00cefcc71d54aff50e5.png" src="_images/ca71df0d300fff9ff2c2772bec3d93d556f4435bfcb9f00cefcc71d54aff50e5.png" />
</div>
</div>
</section>
<section id="comments">
<h2>Comments<a class="headerlink" href="#comments" title="Permalink to this heading">#</a></h2>
<p>This was a basic treatment of generative adversarial networks. Much more could be done and discussed, I have many more resources. Check out my <a class="reference external" href="https://michaelpyrcz.com/my-resources">shared resource inventory</a> and the YouTube lecture links at the start of this chapter with resource links in the videos’ descriptions.</p>
<p>I hope this is helpful,</p>
<p><em>Michael</em></p>
</section>
<section id="about-the-author">
<h2>About the Author<a class="headerlink" href="#about-the-author" title="Permalink to this heading">#</a></h2>
<figure style="text-align: center;">
  <img src="_static/intro/michael_pyrcz_officeshot_jacket.jpg" style="display: block; margin: 0 auto; width: 70%;">
  <figcaption style="text-align: center;"> Professor Michael Pyrcz in his office on the 40 acres, campus of The University of Texas at Austin.
</figcaption>
</figure>
<p>Michael Pyrcz is a professor in the <a class="reference external" href="https://cockrell.utexas.edu/faculty-directory/alphabetical/p">Cockrell School of Engineering</a>, and the <a class="reference external" href="https://www.jsg.utexas.edu/researcher/michael_pyrcz/">Jackson School of Geosciences</a>, at <a class="reference external" href="https://www.utexas.edu/">The University of Texas at Austin</a>, where he researches and teaches subsurface, spatial data analytics, geostatistics, and machine learning. Michael is also,</p>
<ul class="simple">
<li><p>the principal investigator of the <a class="reference external" href="https://fri.cns.utexas.edu/energy-analytics">Energy Analytics</a> freshmen research initiative and a core faculty in the Machine Learn Laboratory in the College of Natural Sciences, The University of Texas at Austin</p></li>
<li><p>an associate editor for <a class="reference external" href="https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board">Computers and Geosciences</a>, and a board member for <a class="reference external" href="https://link.springer.com/journal/11004/editorial-board">Mathematical Geosciences</a>, the International Association for Mathematical Geosciences.</p></li>
</ul>
<p>Michael has written over 70 <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en">peer-reviewed publications</a>, a <a class="reference external" href="https://pypi.org/project/geostatspy/">Python package</a> for spatial data analytics, co-authored a textbook on spatial data analytics, <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistical Reservoir Modeling</a> and author of two recently released e-books, <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostatistics in Python: a Hands-on Guide with GeostatsPy</a> and <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html">Applied Machine Learning in Python: a Hands-on Guide with Code</a>.</p>
<p>All of Michael’s university lectures are available on his <a class="reference external" href="https://www.youtube.com/&#64;GeostatsGuyLectures">YouTube Channel</a> with links to 100s of Python interactive dashboards and well-documented workflows in over 40 repositories on his <a class="reference external" href="https://github.com/GeostatsGuy">GitHub account</a>, to support any interested students and working professionals with evergreen content. To find out more about Michael’s work and shared educational resources visit his <span class="xref myst">Website</span>.</p>
</section>
<section id="want-to-work-together">
<h2>Want to Work Together?<a class="headerlink" href="#want-to-work-together" title="Permalink to this heading">#</a></h2>
<p>I hope this content is helpful to those that want to learn more about subsurface modeling, data analytics and machine learning. Students and working professionals are welcome to participate.</p>
<ul class="simple">
<li><p>Want to invite me to visit your company for training, mentoring, project review, workflow design and / or consulting? I’d be happy to drop by and work with you!</p></li>
<li><p>Interested in partnering, supporting my graduate student research or my Subsurface Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)? My research combines data analytics, stochastic modeling and machine learning theory with practice to develop novel methods and workflows to add value. We are solving challenging subsurface problems!</p></li>
<li><p>I can be reached at <a class="reference external" href="mailto:mpyrcz&#37;&#52;&#48;austin&#46;utexas&#46;edu">mpyrcz<span>&#64;</span>austin<span>&#46;</span>utexas<span>&#46;</span>edu</a>.</p></li>
</ul>
<p>I’m always happy to discuss,</p>
<p><em>Michael</em></p>
<p>Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The Jackson School of Geosciences, The University of Texas at Austin</p>
<p>More Resources Available at: <a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="MachineLearning_autoencoder.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Autoencoder</p>
      </div>
    </a>
    <a class="right-next"
       href="MachineLearning_time_series.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Time Series Analysis and Modeling</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation">Motivation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Generative Adversarial Networks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#indirect-adversarial-learning">Indirect, Adversarial Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#import-required-packages">Import Required Packages</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#declare-functions">Declare Functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#set-the-working-directory">Set the Working Directory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-the-generative-adversarial-network">Visualize the Generative Adversarial Network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generator-forward-pass">Generator Forward Pass</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discriminator-forward-pass">Discriminator Forward Pass</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discriminator-loss">Discriminator Loss</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discriminator-loss-derivative">Discriminator Loss Derivative</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discriminator-back-propagation">Discriminator Back Propagation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generator-loss-derivative-and-back-propagation-through-the-discriminator">Generator Loss Derivative and Back Propagation Through the Discriminator</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#backpropagation-through-generator-to-weights-and-bias">Backpropagation Through Generator to Weights and Bias</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-gan-training-workflow">Simple GAN Training Workflow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-real-images-and-trained-generator-fake-images">Visualize Real Images and Trained Generator Fake Images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-real-images-and-generator-fake-images-over-training-epochs">Visualize Real Images and Generator Fake Images Over Training Epochs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comments">Comments</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#about-the-author">About the Author</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#want-to-work-together">Want to Work Together?</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Michael J. Pyrcz
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024 CC BY-NC-ND 4.0.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>