

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>k-nearest Neighbours &#8212; Applied Machine Learning in Python</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/myfile.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'MachineLearning_knearest_neighbours';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Decision Tree" href="MachineLearning_decision_tree.html" />
    <link rel="prev" title="Polynomial Regression" href="MachineLearning_polynomial_regression.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/AppliedMachineLearning.jpg" class="logo__image only-light" alt="Applied Machine Learning in Python - Home"/>
    <script>document.write(`<img src="_static/AppliedMachineLearning.jpg" class="logo__image only-dark" alt="Applied Machine Learning in Python - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_concepts.html">Machine Learning Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_training_tuning.html">Training and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_workflow_construction.html">Workflow Construction and Coding</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_probability.html">Probability Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_plotting_data_models.html">Loading and Plotting Data and Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_univariate_analysis.html">Univariate Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_multivariate_analysis.html">Multivariate Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_feature_transformations.html">Feature Transformations</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_feature_ranking.html">Feature Ranking</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_feature_imputation.html">Feature Imputation</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_clustering.html">Cluster Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_density-based_clustering.html">Density-based Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_spectral_clustering.html">Spectral Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_PCA.html">Principal Components Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_multidimensional_scaling.html">Multidimensional Scaling</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_random_projection.html">Random Projection</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_linear_regression.html">Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_ridge_regression.html">Ridge Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_LASSO_regression.html">LASSO Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_Bayesian_linear_regression.html">Bayesian Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_naive_Bayes.html">Naive Bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_polynomial_regression.html">Polynomial Regression</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">k-Nearest Neighbours</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_decision_tree.html">Decision Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_ensemble_trees.html">Bagging Tree and Random Forest</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_gradient_boosting.html">Gradient Boosting</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_support_vector_machines.html">Support Vector Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_time_series.html">Time Series Analysis and Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="conclusions.html">Conclusions</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/GeostatsPyDemos_Book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/GeostatsPyDemos_Book/issues/new?title=Issue%20on%20page%20%2FMachineLearning_knearest_neighbours.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/MachineLearning_knearest_neighbours.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>k-nearest Neighbours</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivations-for-k-nearest-neighbours-regression">Motivations for k-nearest Neighbours Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convolution">Convolution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#k-nearest-neighbours-hyperparameters">k-nearest Neighbours Hyperparameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-the-required-libraries">Load the Required Libraries</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#declare-functions">Declare Functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#set-the-working-directory">Set the Working Directory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-tabular-data">Loading Tabular Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-add-random-noise-to-the-response-feature">Optional: Add Random Noise to the Response Feature</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-the-dataframe">Visualize the DataFrame</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-statistics-for-tabular-data">Summary Statistics for Tabular Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculate-the-correlation-matrix-and-correlation-with-response-ranking">Calculate the Correlation Matrix and Correlation with Response Ranking</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#working-with-only-two-predictor-features">Working with Only Two Predictor Features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#standardizing-predictor-features">Standardizing Predictor Features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-ranges">Feature Ranges</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-and-test-split">Train and Test Split</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#instantiate-fit-and-predict-with-k-nearest-neighbour">Instantiate, Fit and Predict with k-nearest Neighbour</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-tuning-for-k-nearest-neighbours">Hyperparameter Tuning for k-Nearest Neighbours</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tuning-the-hyperparameters">Tuning the Hyperparameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#k-fold-cross-validation">k-fold Cross Validation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#predictor-feature-standardization">Predictor Feature Standardization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#k-nearest-neighbour-regression-in-scikit-learn-with-pipelines">k Nearest Neighbour Regression in scikit-learn with Pipelines</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-learning-modeling-pipelines-basics">Machine Learning Modeling Pipelines Basics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#k-nearest-neighbours-with-pipelines">k-Nearest Neighbours with Pipelines</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#check-the-tuned-hyperparameters">Check the Tuned Hyperparameters</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comments">Comments</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#about-the-author">About the Author</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#want-to-work-together">Want to Work Together?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#more-resources-available-at-twitter-github-website-googlescholar-book-youtube-applied-geostats-in-python-e-book-linkedin">More Resources Available at: Twitter | GitHub | Website | GoogleScholar | Book | YouTube  | Applied Geostats in Python e-book | LinkedIn</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <figure style="text-align: center;">
  <img src="_static/intro/title_page.png" style="display: block; margin: 0 auto; width: 100%;">
</figure>
<section id="k-nearest-neighbours">
<h1>k-nearest Neighbours<a class="headerlink" href="#k-nearest-neighbours" title="Permalink to this heading">#</a></h1>
<p>Michael J. Pyrcz, Professor, The University of Texas at Austin</p>
<p><a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></p>
<p>Chapter of e-book “Applied Machine Learning in Python: a Hands-on Guide with Code”.</p>
<div class="remove-from-content-only admonition">
<p class="admonition-title">Cite this e-Book as:</p>
<p>Pyrcz, M. J., 2024, Applied Machine Learning in Python: A Hands-on Guide with Code. GitHub repository. Zenodo. DOI: 10.5281/zenodo.15169138 <a class="reference external" href="https://doi.org/10.5281/zenodo.15169138"><img alt="DOI" src="https://zenodo.org/badge/863274676.svg" /></a></p>
</div>
<p>The workflows in this book and more are available here:</p>
<div class="remove-from-content-only admonition">
<p class="admonition-title">Cite the MachineLearningDemos GitHub Repository as:</p>
<p>Pyrcz, M.J., 2024, MachineLearningDemos: Python Machine Learning Demonstration Workflows Repository (0.0.1). Zenodo. DOI: 10.5281/zenodo.13835312  <a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.13835312"><img alt="DOI" src="https://zenodo.org/badge/862519860.svg" /></a></p>
</div>
<p>By Michael J. Pyrcz <br />
© Copyright 2024.</p>
<p>This chapter is a tutorial for / demonstration of <strong>k-nearest Neighbours</strong>.</p>
<p><strong>YouTube Lecture</strong>: check out my lectures on:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://youtu.be/zOUM_AnI1DQ?si=wzWdJ35qJ9n8O6Bl">Introduction to Machine Learning</a></p></li>
<li><p><a class="reference external" href="https://youtu.be/lzmeChSYvv8?si=nfcvGtkIAQ7rFkjo">k-nearest Neighbours Regression</a></p></li>
</ul>
<p>These lectures are all part of my <a class="reference external" href="https://youtube.com/playlist?list=PLG19vXLQHvSC2ZKFIkgVpI9fCjkN38kwf&amp;si=XonjO2wHdXffMpeI">Machine Learning Course</a> on YouTube with linked well-documented Python workflows and interactive dashboards. My goal is to share accessible, actionable, and repeatable educational content. If you want to know about my motivation, check out <a class="reference external" href="https://michaelpyrcz.com/my-story">Michael’s Story</a>.</p>
<section id="motivations-for-k-nearest-neighbours-regression">
<h2>Motivations for k-nearest Neighbours Regression<a class="headerlink" href="#motivations-for-k-nearest-neighbours-regression" title="Permalink to this heading">#</a></h2>
<p>There are many good reasons to cover k-nearest neighbours regression. In addition to being a simple, interpretable and flexible predictive machine learning model, it also demonstrates important concepts,</p>
<ul class="simple">
<li><p><strong>non-parametric predictive model</strong> - that learns the form of the relationships from the data, i.e., no prior assumption about the form of the relationship</p></li>
<li><p><strong>instance-based, lazy learning</strong> - model training is postponed until prediction is required, no precalculation of the model. i.e., prediction requires access to the data</p></li>
<li><p><strong>hyperparameter tuning</strong> - with a understandable hyperparameters that control model fit</p></li>
<li><p><strong>very flexible, versatile predictive model</strong> - performs well in many situations</p></li>
</ul>
</section>
<section id="convolution">
<h2>Convolution<a class="headerlink" href="#convolution" title="Permalink to this heading">#</a></h2>
<p>In fact, k-nearest neighbours is analogous to spatial estimation through weighted averaging within a local neighbourhood.</p>
<figure style="text-align: center;">
  <img src="_static/knearest/spatial_interpolation.png" style="display: block; margin: 0 auto; width: 50%;">
  <figcaption style="text-align: center;">Prediction modeling a spatial interpolation in predictor feature space.</figcaption>
</figure>
<p>The k-nearest neighbours approach is similar to a convolution approach for spatial interpolation. Convolution is the integral product of two functions, after one is reversed and shifted by <span class="math notranslate nohighlight">\(\Delta\)</span>.</p>
<ul class="simple">
<li><p>one interpretation is smoothing a function with weighting function, <span class="math notranslate nohighlight">\(𝑓(\Delta)\)</span>, is applied to calculate the weighted average of function, <span class="math notranslate nohighlight">\(𝑔(x)\)</span>,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ 
(f * g)(x) = \int_{-\infty}^{\infty} f(\Delta) g(x - \Delta) \, d\Delta 
\]</div>
<p>this easily extends into multidimensional</p>
<div class="math notranslate nohighlight">
\[
(f * g)(x, y, z) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f(\Delta_x, \Delta_y, \Delta_z) g(x - \Delta_x, y - \Delta_y, z - \Delta_z) \, d\Delta_x \, d\Delta_y \, d\Delta_z
\]</div>
<p>The choice of which function is shifted before integration does not change the result, the convolution operator has commutativity,</p>
<div class="math notranslate nohighlight">
\[ 
(f * g)(x) = \int_{-\infty}^{\infty} f(\Delta) g(x - \Delta) \, d\Delta 
\]</div>
<div class="math notranslate nohighlight">
\[
(f * g)(x) = \int_{-\infty}^{\infty} f(x - \Delta) g(\Delta) \, d\Delta 
\]</div>
<ul class="simple">
<li><p>if either function is reflected then convolution is equivalent to cross-correlation, measure of similarity between 2 signals as a function of displacement.</p></li>
</ul>
<p>To demonstrate convolution with an exhaustive <span class="math notranslate nohighlight">\(g(x)\)</span> and sparsely sampled <span class="math notranslate nohighlight">\(g(x)\)</span> I built out an <a class="reference external" href="https://github.com/GeostatsGuy/DataScienceInteractivePython/blob/main/Interactive_Convolution_kNearest.ipynb">interactive Python convolution dashboard</a>,</p>
<figure style="text-align: center;">
  <img src="_static/knearest/interactive_convolution.png" style="display: block; margin: 0 auto; width: 100%;">
  <figcaption style="text-align: center;">Interactive Python dashboard to demonstrate convolution.</figcaption>
</figure>
<p>While it is useful to review and discuss convolution, k-nearest neighbours departs from convolution with the specification of <span class="math notranslate nohighlight">\(k\)</span> nearest neighbours to include in the weighted average,</p>
<ul class="simple">
<li><p>specifying <span class="math notranslate nohighlight">\(k\)</span> results in a locally adaptive window size, the local neighbourhood extends far enough to find <span class="math notranslate nohighlight">\(k\)</span> training data</p></li>
</ul>
<figure style="text-align: center;">
  <img src="_static/knearest/adaptive_window.png" style="display: block; margin: 0 auto; width: 70%;">
  <figcaption style="text-align: center;">For a given $k$ number of nearest neighbours data are collected from farther away in sparse data regions of the predictor feature space.</figcaption>
</figure>
</section>
<section id="k-nearest-neighbours-hyperparameters">
<h2>k-nearest Neighbours Hyperparameters<a class="headerlink" href="#k-nearest-neighbours-hyperparameters" title="Permalink to this heading">#</a></h2>
<p>Now let’s discuss the k-nearest neighbours hyperparameters.</p>
<ol class="arabic simple">
<li><p><strong>k number of nearest data</strong> - to utilize for prediction</p></li>
<li><p><strong>data weighting</strong> - for example uniform weighting (use local training data average), inverse distance weighting</p></li>
</ol>
<p>Note, for the case of inverse distance weighting, the method is analogous to inverse distance weighted interpolation with a maximum number of local data constraint commonly applied for spatial interpolation. Inverse distance is available in GeostatsPy for spatial mapping.</p>
<ol class="arabic simple" start="3">
<li><p><strong>Distance Metric</strong> - training data within the predictor feature space are ranked by distance, closest to farthest, a variety of distance metrics may be applied, including:</p></li>
</ol>
<ul class="simple">
<li><p>Euclidian distance</p></li>
</ul>
<p>\begin{equation}<br />
d_i = \sqrt{\sum_{\alpha = 1}^{m} \left(x_{\alpha,i} - x_{\alpha,0}\right)^2}
\end{equation}</p>
<ul class="simple">
<li><p>Minkowski Distance - a generalized form of distance with well-known Manhattan and Euclidean distances are special cases,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
d_{(i,i')} = \left( \sum_{j=1}^{m} \left( x_{(j,i)} - x_{(j,i')} \right)^p \right)^{\frac{1}{p}}
\]</div>
<ul class="simple">
<li><p>when <span class="math notranslate nohighlight">\(p=2\)</span>, this becomes the Euclidean distance</p></li>
<li><p>when <span class="math notranslate nohighlight">\(p=1\)</span> it becomes the Manhattan distance</p></li>
</ul>
</section>
<section id="load-the-required-libraries">
<h2>Load the Required Libraries<a class="headerlink" href="#load-the-required-libraries" title="Permalink to this heading">#</a></h2>
<p>We will also need some standard packages. These should have been installed with Anaconda 3.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline                                         
<span class="n">suppress_warnings</span> <span class="o">=</span> <span class="kc">True</span>
<span class="kn">import</span> <span class="nn">os</span>                                                     <span class="c1"># to set current working directory </span>
<span class="kn">import</span> <span class="nn">math</span>                                                   <span class="c1"># square root operator</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>                                            <span class="c1"># arrays and matrix math</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>                                      <span class="c1"># statistical methods</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>                                           <span class="c1"># DataFrames</span>
<span class="kn">import</span> <span class="nn">pandas.plotting</span> <span class="k">as</span> <span class="nn">pd_plot</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>                               <span class="c1"># for plotting</span>
<span class="kn">from</span> <span class="nn">matplotlib.ticker</span> <span class="kn">import</span> <span class="p">(</span><span class="n">MultipleLocator</span><span class="p">,</span><span class="n">AutoMinorLocator</span><span class="p">,</span><span class="n">FuncFormatter</span><span class="p">)</span> <span class="c1"># control of axes ticks</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>                  <span class="c1"># custom color maps</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>                                         <span class="c1"># for matrix scatter plots</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>                                   <span class="c1"># measures to check our models</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>              <span class="c1"># standardize the features</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>             <span class="c1"># for nearest k neighbours</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>                                   <span class="c1"># measures to check our models</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="p">(</span><span class="n">cross_val_score</span><span class="p">,</span><span class="n">train_test_split</span><span class="p">,</span><span class="n">GridSearchCV</span><span class="p">,</span><span class="n">KFold</span><span class="p">)</span> <span class="c1"># model tuning</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="p">(</span><span class="n">Pipeline</span><span class="p">,</span><span class="n">make_pipeline</span><span class="p">)</span>         <span class="c1"># machine learning modeling pipeline</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>                     <span class="c1"># custom displays</span>
<span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span>                                         <span class="c1"># default color bar, no bias and friendly for color vision defeciency</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;axes&#39;</span><span class="p">,</span> <span class="n">axisbelow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                                <span class="c1"># grid behind plotting elements</span>
<span class="k">if</span> <span class="n">suppress_warnings</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>  
    <span class="kn">import</span> <span class="nn">warnings</span>                                           <span class="c1"># suppress any warnings for this demonstration</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span> 
<span class="n">seed</span> <span class="o">=</span> <span class="mi">13</span>                                                     <span class="c1"># random number seed for workflow repeatability</span>
</pre></div>
</div>
</div>
</div>
<p>If you get a package import error, you may have to first install some of these packages. This can usually be accomplished by opening up a command window on Windows and then typing ‘python -m pip install [package-name]’. More assistance is available with the respective package docs.</p>
</section>
<section id="declare-functions">
<h2>Declare Functions<a class="headerlink" href="#declare-functions" title="Permalink to this heading">#</a></h2>
<p>Let’s define a couple of functions to streamline plotting correlation matrices, visualization of a decision tree regression model, and the addition specified percentiles and major and minor gridlines to our plots.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">comma_format</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pos</span><span class="p">):</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="si">:</span><span class="s1">,</span><span class="si">}</span><span class="s1">&#39;</span>

<span class="k">def</span> <span class="nf">feature_rank_plot</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">metric</span><span class="p">,</span><span class="n">mmin</span><span class="p">,</span><span class="n">mmax</span><span class="p">,</span><span class="n">nominal</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">ylabel</span><span class="p">,</span><span class="n">mask</span><span class="p">):</span> <span class="c1"># feature ranking plot</span>
    <span class="n">mpred</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">);</span> <span class="n">mask_low</span> <span class="o">=</span> <span class="n">nominal</span><span class="o">-</span><span class="n">mask</span><span class="o">*</span><span class="p">(</span><span class="n">nominal</span><span class="o">-</span><span class="n">mmin</span><span class="p">);</span> <span class="n">mask_high</span> <span class="o">=</span> <span class="n">nominal</span><span class="o">+</span><span class="n">mask</span><span class="o">*</span><span class="p">(</span><span class="n">mmax</span><span class="o">-</span><span class="n">nominal</span><span class="p">);</span> <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">metric</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">metric</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">1.5</span><span class="p">],[</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">],</span><span class="s1">&#39;r--&#39;</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mpred</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">mpred</span><span class="p">),</span><span class="n">metric</span><span class="p">,</span><span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">metric</span> <span class="o">&lt;</span> <span class="n">nominal</span><span class="p">),</span><span class="n">interpolate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;dodgerblue&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mpred</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">mpred</span><span class="p">),</span><span class="n">metric</span><span class="p">,</span><span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">metric</span> <span class="o">&gt;</span> <span class="n">nominal</span><span class="p">),</span><span class="n">interpolate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightcoral&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mpred</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">mpred</span><span class="p">,</span><span class="n">mask_low</span><span class="p">),</span><span class="n">metric</span><span class="p">,</span><span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">metric</span> <span class="o">&lt;</span> <span class="n">mask_low</span><span class="p">),</span><span class="n">interpolate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mpred</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">mpred</span><span class="p">,</span><span class="n">mask_high</span><span class="p">),</span><span class="n">metric</span><span class="p">,</span><span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">metric</span> <span class="o">&gt;</span> <span class="n">mask_high</span><span class="p">),</span><span class="n">interpolate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>  
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predictor Features&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">mmin</span><span class="p">,</span><span class="n">mmax</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">1.5</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">();</span>
    <span class="k">return</span>

<span class="k">def</span> <span class="nf">plot_corr</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">limits</span><span class="p">,</span><span class="n">mask</span><span class="p">):</span>                 <span class="c1"># plots a graphical correlation matrix </span>
    <span class="n">my_colormap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">&#39;RdBu_r&#39;</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>          
    <span class="n">newcolors</span> <span class="o">=</span> <span class="n">my_colormap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>
    <span class="n">white</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">white_low</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">128</span> <span class="o">-</span> <span class="n">mask</span><span class="o">*</span><span class="mi">128</span><span class="p">);</span> <span class="n">white_high</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">128</span><span class="o">+</span><span class="n">mask</span><span class="o">*</span><span class="mi">128</span><span class="p">)</span>
    <span class="n">newcolors</span><span class="p">[</span><span class="n">white_low</span><span class="p">:</span><span class="n">white_high</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">white</span>                <span class="c1"># mask all correlations less than abs(0.8)</span>
    <span class="n">newcmp</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">(</span><span class="n">newcolors</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="n">fignum</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">vmin</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">*</span><span class="n">limits</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="n">limits</span><span class="p">,</span><span class="n">cmap</span> <span class="o">=</span> <span class="n">newcmp</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">);</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_label_position</span><span class="p">(</span><span class="s1">&#39;bottom&#39;</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">tick_bottom</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">&#39;vertical&#39;</span><span class="p">)</span>
    <span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">m</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],[</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">])</span>
    
<span class="k">def</span> <span class="nf">visualize_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">xfeature</span><span class="p">,</span><span class="n">x_min</span><span class="p">,</span><span class="n">x_max</span><span class="p">,</span><span class="n">yfeature</span><span class="p">,</span><span class="n">y_min</span><span class="p">,</span><span class="n">y_max</span><span class="p">,</span><span class="n">response</span><span class="p">,</span><span class="n">z_min</span><span class="p">,</span><span class="n">z_max</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">axes_commas</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span> <span class="c1"># plots the data points and the decision tree prediction </span>
    <span class="n">n_classes</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">cmap_temp</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span>
    <span class="n">xplot_step</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_max</span><span class="o">-</span><span class="n">x_min</span><span class="p">)</span><span class="o">/</span><span class="mi">100</span><span class="p">;</span> <span class="n">yplot_step</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_max</span><span class="o">-</span><span class="n">y_min</span><span class="p">)</span><span class="o">/</span><span class="mi">100</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">xplot_step</span><span class="p">),</span>
                     <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">yplot_step</span><span class="p">))</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">cs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap_temp</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="n">z_min</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">z_max</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">z_min</span><span class="p">,</span> <span class="n">z_max</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>

    <span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xfeature</span><span class="p">,</span><span class="n">yfeature</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">response</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap_temp</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">z_min</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">z_max</span><span class="p">,</span> 
                     <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xfeature</span><span class="p">,</span><span class="n">yfeature</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap_temp</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">z_min</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">z_max</span><span class="p">,</span> 
                     <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">xfeature</span><span class="o">.</span><span class="n">name</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">yfeature</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
    <span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">&#39;vertical&#39;</span><span class="p">);</span> <span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">270</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">axes_commas</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">Z</span>
    
<span class="k">def</span> <span class="nf">visualize_tuned_model</span><span class="p">(</span><span class="n">k_tuned</span><span class="p">,</span><span class="n">k_mat</span><span class="p">,</span><span class="n">score_mat</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">k_mat</span><span class="p">,</span><span class="n">score_mat</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> 
                <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">k_tuned</span><span class="p">,</span><span class="n">k_tuned</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">10000000</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)),</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;tuned&#39;</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;k-fold Cross Validation Error (MSE) vs. k Nearest Neighbours&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Nearest Neighbours&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Mean Square Error&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">k_min</span><span class="p">,</span><span class="n">k_max</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">score_mat</span><span class="p">))</span>
    
<span class="k">def</span> <span class="nf">check_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">xtrain</span><span class="p">,</span><span class="n">ytrain</span><span class="p">,</span><span class="n">xtest</span><span class="p">,</span><span class="n">ytest</span><span class="p">,</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">rtrain</span><span class="p">,</span><span class="n">rtest</span><span class="p">,</span><span class="n">title</span><span class="p">):</span> <span class="c1"># plots the estimated vs. the actual  </span>
    <span class="n">predict_train</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xtrain</span><span class="p">,</span><span class="n">ytrain</span><span class="p">])</span>
    <span class="n">predict_test</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xtest</span><span class="p">,</span><span class="n">ytest</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">rtrain</span><span class="p">,</span><span class="n">predict_train</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">rtest</span><span class="p">,</span><span class="n">predict_test</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Test&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Actual Production (MCFPD)&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Estimated Production (MCFPD)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span><span class="n">head_length</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span><span class="n">head_width</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
    <span class="n">MSE_train</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">rtrain</span><span class="p">,</span><span class="n">predict_train</span><span class="p">)</span>
    <span class="n">Var_Explained_train</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">explained_variance_score</span><span class="p">(</span><span class="n">rtrain</span><span class="p">,</span><span class="n">predict_train</span><span class="p">)</span>
    <span class="n">cor_train</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">rtrain</span><span class="p">,</span><span class="n">predict_train</span><span class="p">))</span>
    <span class="n">MSE_test</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">rtest</span><span class="p">,</span><span class="n">predict_test</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;Train MSE: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">MSE_train</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="si">:</span><span class="s1">,</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">),[</span><span class="mf">0.05</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)</span><span class="o">+</span><span class="n">ymin</span><span class="p">,</span><span class="mf">0.95</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)</span><span class="o">+</span><span class="n">ymin</span><span class="p">])</span> 
    <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;Test MSE:  &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">MSE_test</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="si">:</span><span class="s1">,</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">),[</span><span class="mf">0.05</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)</span><span class="o">+</span><span class="n">ymin</span><span class="p">,</span><span class="mf">0.90</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)</span><span class="o">+</span><span class="n">ymin</span><span class="p">])</span>
    <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
    <span class="c1"># print(&#39;Mean Squared Error on Training = &#39;, round(MSE_test,2),&#39;, Variance Explained =&#39;, round(Var_Explained,2),&#39;Cor =&#39;, round(cor,2))</span>

<span class="k">def</span> <span class="nf">weighted_percentile</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">perc</span><span class="p">):</span>                 <span class="c1"># calculate weighted percentile (iambr on StackOverflow @ https://stackoverflow.com/questions/21844024/weighted-percentile-using-numpy/32216049) </span>
    <span class="n">ix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> 
    <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> 
    <span class="n">cdf</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> 
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">interp</span><span class="p">(</span><span class="n">perc</span><span class="p">,</span> <span class="n">cdf</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">histogram_bounds</span><span class="p">(</span><span class="n">values</span><span class="p">,</span><span class="n">weights</span><span class="p">,</span><span class="n">color</span><span class="p">):</span>                   <span class="c1"># add uncertainty bounds to a histogram          </span>
    <span class="n">p10</span> <span class="o">=</span> <span class="n">weighted_percentile</span><span class="p">(</span><span class="n">values</span><span class="p">,</span><span class="n">weights</span><span class="p">,</span><span class="mf">0.1</span><span class="p">);</span> <span class="n">avg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">values</span><span class="p">,</span><span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">);</span> <span class="n">p90</span> <span class="o">=</span> <span class="n">weighted_percentile</span><span class="p">(</span><span class="n">values</span><span class="p">,</span><span class="n">weights</span><span class="p">,</span><span class="mf">0.9</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">p10</span><span class="p">,</span><span class="n">p10</span><span class="p">],[</span><span class="mf">0.0</span><span class="p">,</span><span class="mi">45</span><span class="p">],</span><span class="n">color</span> <span class="o">=</span> <span class="n">color</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">avg</span><span class="p">,</span><span class="n">avg</span><span class="p">],[</span><span class="mf">0.0</span><span class="p">,</span><span class="mi">45</span><span class="p">],</span><span class="n">color</span> <span class="o">=</span> <span class="n">color</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">p90</span><span class="p">,</span><span class="n">p90</span><span class="p">],[</span><span class="mf">0.0</span><span class="p">,</span><span class="mi">45</span><span class="p">],</span><span class="n">color</span> <span class="o">=</span> <span class="n">color</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">add_grid</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="c1"># add y grids</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="mi">7</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">());</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">())</span> <span class="c1"># turn on minor ticks </span>

<span class="k">def</span> <span class="nf">display_sidebyside</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>                                <span class="c1"># display DataFrames side-by-side (ChatGPT 4.0 generated Spet, 2024)</span>
    <span class="n">html_str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
        <span class="n">html_str</span> <span class="o">+=</span> <span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span><span class="o">.</span><span class="n">to_html</span><span class="p">()</span>  <span class="c1"># Using .head() for the first few rows</span>
    <span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;&lt;div style=&quot;display: flex;&quot;&gt;</span><span class="si">{</span><span class="n">html_str</span><span class="si">}</span><span class="s1">&lt;/div&gt;&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="set-the-working-directory">
<h2>Set the Working Directory<a class="headerlink" href="#set-the-working-directory" title="Permalink to this heading">#</a></h2>
<p>I always like to do this so I don’t lose files and to simplify subsequent read and writes (avoid including the full address each time).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#os.chdir(&quot;c:/PGE383&quot;)                                        # set the working directory</span>
</pre></div>
</div>
</div>
</div>
<p>You will have to update the part in quotes with your own working directory and the format is different on a Mac (e.g. “~/PGE”).</p>
</section>
<section id="loading-tabular-data">
<h2>Loading Tabular Data<a class="headerlink" href="#loading-tabular-data" title="Permalink to this heading">#</a></h2>
<p>Here’s the command to load our comma delimited data file in to a Pandas’ DataFrame object.</p>
<p>Let’s load the provided multivariate, spatial dataset ‘unconv_MV.csv’. This dataset has variables from 1,000 unconventional wells including:</p>
<ul class="simple">
<li><p>well average porosity</p></li>
<li><p>log transform of permeability (to linearize the relationships with other variables)</p></li>
<li><p>acoustic impedance (kg/m^3 x m/s x 10^6)</p></li>
<li><p>brittleness ratio (%)</p></li>
<li><p>total organic carbon (%)</p></li>
<li><p>vitrinite reflectance (%)</p></li>
<li><p>initial production 90 day average (MCFPD).</p></li>
</ul>
<p>Note, the dataset is synthetic.</p>
<p>We load it with the pandas ‘read_csv’ function into a DataFrame we called ‘my_data’ and then preview it to make sure it loaded correctly.</p>
</section>
<section id="optional-add-random-noise-to-the-response-feature">
<h2>Optional: Add Random Noise to the Response Feature<a class="headerlink" href="#optional-add-random-noise-to-the-response-feature" title="Permalink to this heading">#</a></h2>
<p>We can do this to observe the impact of data noise on overfit and hyperparameter tuning.</p>
<ul class="simple">
<li><p>This is for experiential learning, of course we wouldn’t add random noise to our data</p></li>
<li><p>We set the random number seed for reproducibility</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_load</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv&#39;</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz&#39;s GitHub  </span>
<span class="n">df_load</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:</span><span class="mi">8</span><span class="p">]</span>                                 <span class="c1"># copy all rows and columns 1 through 8, note 0 column is removed</span>

<span class="n">response</span> <span class="o">=</span> <span class="s1">&#39;Prod&#39;</span>                                             <span class="c1"># specify the response feature</span>
<span class="n">add_noise</span> <span class="o">=</span> <span class="kc">True</span>                                              <span class="c1"># set True to add noise to response feature to demonstrate overfit</span>
<span class="n">noise_stdev</span> <span class="o">=</span> <span class="mi">500</span>                                             <span class="c1"># amount of noise to add to response feature to demonstrate overfit</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span>                                   <span class="c1"># set the random number seed</span>
<span class="k">if</span> <span class="n">add_noise</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">df_load</span><span class="p">[</span><span class="n">response</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_load</span><span class="p">[</span><span class="n">response</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">noise_stdev</span><span class="p">,</span><span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_load</span><span class="p">))</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="n">response</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;columns&#39;</span><span class="p">)</span>                         <span class="c1"># make predictor and response DataFrames</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">response</span><span class="p">]</span>

<span class="n">features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="p">[</span><span class="n">y</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>               <span class="c1"># store the names of the features</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">resp</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>

<span class="n">Xmin</span> <span class="o">=</span> <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.9</span><span class="p">];</span> <span class="n">Xmax</span> <span class="o">=</span> <span class="p">[</span><span class="mf">24.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">5.0</span><span class="p">,</span><span class="mf">85.0</span><span class="p">,</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">2.9</span><span class="p">]</span> <span class="c1"># set the minumum and maximum values for plotting</span>
<span class="n">ymin</span> <span class="o">=</span> <span class="mf">1000.0</span><span class="p">;</span> <span class="n">ymax</span> <span class="o">=</span> <span class="mf">9000.0</span>

<span class="n">predlabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Porosity (%)&#39;</span><span class="p">,</span><span class="s1">&#39;Permeability (mD)&#39;</span><span class="p">,</span><span class="s1">&#39;Acoustic Impedance (kg/m2s*10^6)&#39;</span><span class="p">,</span><span class="s1">&#39;Brittleness Ratio (%)&#39;</span><span class="p">,</span> <span class="c1"># set the names for plotting</span>
             <span class="s1">&#39;Total Organic Carbon (%)&#39;</span><span class="p">,</span><span class="s1">&#39;Vitrinite Reflectance (%)&#39;</span><span class="p">]</span>
<span class="n">resplabel</span> <span class="o">=</span> <span class="s1">&#39;Normalized Initial Production (MCFPD)&#39;</span>

<span class="n">predtitle</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Porosity&#39;</span><span class="p">,</span><span class="s1">&#39;Permeability&#39;</span><span class="p">,</span><span class="s1">&#39;Acoustic Impedance&#39;</span><span class="p">,</span><span class="s1">&#39;Brittleness Ratio&#39;</span><span class="p">,</span> <span class="c1"># set the units for plotting</span>
             <span class="s1">&#39;Total Organic Carbon&#39;</span><span class="p">,</span><span class="s1">&#39;Vitrinite Reflectance&#39;</span><span class="p">]</span>
<span class="n">resptitle</span> <span class="o">=</span> <span class="s1">&#39;Initial Production&#39;</span>

<span class="n">featurelabel</span> <span class="o">=</span> <span class="n">predlabel</span> <span class="o">+</span> <span class="p">[</span><span class="n">resplabel</span><span class="p">]</span>                        <span class="c1"># make feature labels and titles for concise code</span>
<span class="n">featuretitle</span> <span class="o">=</span> <span class="n">predtitle</span> <span class="o">+</span> <span class="p">[</span><span class="n">resptitle</span><span class="p">]</span>

<span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">mpred</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                                  <span class="c1"># make one DataFrame with both X and y (remove all other features)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualize-the-dataframe">
<h2>Visualize the DataFrame<a class="headerlink" href="#visualize-the-dataframe" title="Permalink to this heading">#</a></h2>
<p>Visualizing the DataFrame is useful first check of the data.</p>
<ul class="simple">
<li><p>many things can go wrong, e.g., we loaded the wrong data, all the features did not load, etc.</p></li>
</ul>
<p>We can preview by utilizing the ‘head’ DataFrame member function (with a nice and clean format, see below).</p>
<ul class="simple">
<li><p>add parameter ‘n=13’ to see the first 13 rows of the dataset.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
      <th>Prod</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
      <td>1339.165488</td>
    </tr>
    <tr>
      <th>1</th>
      <td>12.38</td>
      <td>3.53</td>
      <td>3.22</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
      <td>3383.979252</td>
    </tr>
    <tr>
      <th>2</th>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
      <td>2509.686720</td>
    </tr>
    <tr>
      <th>3</th>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
      <td>5514.421023</td>
    </tr>
    <tr>
      <th>4</th>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
      <td>3532.020478</td>
    </tr>
    <tr>
      <th>5</th>
      <td>14.53</td>
      <td>4.81</td>
      <td>2.69</td>
      <td>53.60</td>
      <td>0.94</td>
      <td>1.67</td>
      <td>4283.543382</td>
    </tr>
    <tr>
      <th>6</th>
      <td>13.49</td>
      <td>3.60</td>
      <td>2.93</td>
      <td>63.71</td>
      <td>0.80</td>
      <td>1.85</td>
      <td>3627.906723</td>
    </tr>
    <tr>
      <th>7</th>
      <td>11.58</td>
      <td>3.03</td>
      <td>3.25</td>
      <td>53.00</td>
      <td>0.69</td>
      <td>1.93</td>
      <td>3101.539533</td>
    </tr>
    <tr>
      <th>8</th>
      <td>12.52</td>
      <td>2.72</td>
      <td>2.43</td>
      <td>65.77</td>
      <td>0.95</td>
      <td>1.98</td>
      <td>3213.391047</td>
    </tr>
    <tr>
      <th>9</th>
      <td>13.25</td>
      <td>3.94</td>
      <td>3.71</td>
      <td>66.20</td>
      <td>1.14</td>
      <td>2.65</td>
      <td>2200.204701</td>
    </tr>
    <tr>
      <th>10</th>
      <td>15.04</td>
      <td>4.39</td>
      <td>2.22</td>
      <td>61.11</td>
      <td>1.08</td>
      <td>1.77</td>
      <td>3433.752662</td>
    </tr>
    <tr>
      <th>11</th>
      <td>16.19</td>
      <td>6.30</td>
      <td>2.29</td>
      <td>49.10</td>
      <td>1.53</td>
      <td>1.86</td>
      <td>4465.007131</td>
    </tr>
    <tr>
      <th>12</th>
      <td>16.82</td>
      <td>5.42</td>
      <td>2.80</td>
      <td>66.65</td>
      <td>1.17</td>
      <td>1.98</td>
      <td>4373.060709</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="summary-statistics-for-tabular-data">
<h2>Summary Statistics for Tabular Data<a class="headerlink" href="#summary-statistics-for-tabular-data" title="Permalink to this heading">#</a></h2>
<p>There are a lot of efficient methods to calculate summary statistics from tabular data in DataFrames. The describe command provides count, mean, minimum, maximum in a nice data table.</p>
<ul class="simple">
<li><p>we have some negative TOC values! Let’s check the distribution.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>                                     <span class="c1"># calculate summary statistics for the data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Por</th>
      <td>200.0</td>
      <td>14.991150</td>
      <td>2.971176</td>
      <td>6.550000</td>
      <td>12.912500</td>
      <td>15.070000</td>
      <td>17.40250</td>
      <td>23.550000</td>
    </tr>
    <tr>
      <th>Perm</th>
      <td>200.0</td>
      <td>4.330750</td>
      <td>1.731014</td>
      <td>1.130000</td>
      <td>3.122500</td>
      <td>4.035000</td>
      <td>5.28750</td>
      <td>9.870000</td>
    </tr>
    <tr>
      <th>AI</th>
      <td>200.0</td>
      <td>2.968850</td>
      <td>0.566885</td>
      <td>1.280000</td>
      <td>2.547500</td>
      <td>2.955000</td>
      <td>3.34500</td>
      <td>4.630000</td>
    </tr>
    <tr>
      <th>Brittle</th>
      <td>200.0</td>
      <td>48.161950</td>
      <td>14.129455</td>
      <td>10.940000</td>
      <td>37.755000</td>
      <td>49.510000</td>
      <td>58.26250</td>
      <td>84.330000</td>
    </tr>
    <tr>
      <th>TOC</th>
      <td>200.0</td>
      <td>0.990450</td>
      <td>0.481588</td>
      <td>-0.190000</td>
      <td>0.617500</td>
      <td>1.030000</td>
      <td>1.35000</td>
      <td>2.180000</td>
    </tr>
    <tr>
      <th>VR</th>
      <td>200.0</td>
      <td>1.964300</td>
      <td>0.300827</td>
      <td>0.930000</td>
      <td>1.770000</td>
      <td>1.960000</td>
      <td>2.14250</td>
      <td>2.870000</td>
    </tr>
    <tr>
      <th>Prod</th>
      <td>200.0</td>
      <td>3842.630027</td>
      <td>1594.301295</td>
      <td>803.640483</td>
      <td>2551.414599</td>
      <td>3626.229052</td>
      <td>4739.73408</td>
      <td>9021.792491</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>There are just a couple slightly negative values, let’s just truncate them at zero. We   can use this command below to set all TOC values in the DataFrame that are less than 0.0 as 0.0, otherwise we keep the original TOC value.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">_get_numeric_data</span><span class="p">()</span>                                  <span class="c1"># get the numerical values</span>
<span class="n">num</span><span class="p">[</span><span class="n">num</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>                                              <span class="c1"># truncate negative values to 0.0</span>
<span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>                                     <span class="c1"># calculate summary statistics for the data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Por</th>
      <td>200.0</td>
      <td>14.991150</td>
      <td>2.971176</td>
      <td>6.550000</td>
      <td>12.912500</td>
      <td>15.070000</td>
      <td>17.40250</td>
      <td>23.550000</td>
    </tr>
    <tr>
      <th>Perm</th>
      <td>200.0</td>
      <td>4.330750</td>
      <td>1.731014</td>
      <td>1.130000</td>
      <td>3.122500</td>
      <td>4.035000</td>
      <td>5.28750</td>
      <td>9.870000</td>
    </tr>
    <tr>
      <th>AI</th>
      <td>200.0</td>
      <td>2.968850</td>
      <td>0.566885</td>
      <td>1.280000</td>
      <td>2.547500</td>
      <td>2.955000</td>
      <td>3.34500</td>
      <td>4.630000</td>
    </tr>
    <tr>
      <th>Brittle</th>
      <td>200.0</td>
      <td>48.161950</td>
      <td>14.129455</td>
      <td>10.940000</td>
      <td>37.755000</td>
      <td>49.510000</td>
      <td>58.26250</td>
      <td>84.330000</td>
    </tr>
    <tr>
      <th>TOC</th>
      <td>200.0</td>
      <td>0.991950</td>
      <td>0.478264</td>
      <td>0.000000</td>
      <td>0.617500</td>
      <td>1.030000</td>
      <td>1.35000</td>
      <td>2.180000</td>
    </tr>
    <tr>
      <th>VR</th>
      <td>200.0</td>
      <td>1.964300</td>
      <td>0.300827</td>
      <td>0.930000</td>
      <td>1.770000</td>
      <td>1.960000</td>
      <td>2.14250</td>
      <td>2.870000</td>
    </tr>
    <tr>
      <th>Prod</th>
      <td>200.0</td>
      <td>3842.630027</td>
      <td>1594.301295</td>
      <td>803.640483</td>
      <td>2551.414599</td>
      <td>3626.229052</td>
      <td>4739.73408</td>
      <td>9021.792491</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>It is good that we checked the summary statistics.</p>
<ul class="simple">
<li><p>there are no obvious issues</p></li>
<li><p>check out the range of values for each feature to set up and adjust plotting limits. See above.</p></li>
</ul>
</section>
<section id="calculate-the-correlation-matrix-and-correlation-with-response-ranking">
<h2>Calculate the Correlation Matrix and Correlation with Response Ranking<a class="headerlink" href="#calculate-the-correlation-matrix-and-correlation-with-response-ranking" title="Permalink to this heading">#</a></h2>
<p>Let’s perform with correlation analysis. We can calculate and view the correlation matrix and correlation to the response features with these previously declared functions.</p>
<ul class="simple">
<li><p>correlation analysis is based on the assumption of linear relationships, but it is a good start</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">correlation</span> <span class="o">=</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plot_corr</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="s1">&#39;Correlation Matrix&#39;</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.5</span><span class="p">)</span>           <span class="c1"># using our correlation matrix visualization function</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Features&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Features&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">feature_rank_plot</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">correlation</span><span class="p">,</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="s1">&#39;Feature Ranking, Correlation with &#39;</span> <span class="o">+</span> <span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="s1">&#39;Correlation&#39;</span><span class="p">,</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/9ccb60421ffa42bec24f02270e0cb19e4ab0827d13308e827a76a7a86b2c0dc6.png" src="_images/9ccb60421ffa42bec24f02270e0cb19e4ab0827d13308e827a76a7a86b2c0dc6.png" />
</div>
</div>
<p>Note the 1.0 diagonal resulting from the correlation of each variable with themselves.</p>
<p>This looks good.  There is a mix of correlation magnitudes. Of course, correlation coefficients are limited to degree of linear correlations.</p>
<ul class="simple">
<li><p>Let’s look at the matrix scatter plot to see the pairwise relationship between the features.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pairgrid</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">PairGrid</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="nb">vars</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Por&#39;</span><span class="p">,</span><span class="s1">&#39;Perm&#39;</span><span class="p">,</span><span class="s1">&#39;AI&#39;</span><span class="p">,</span><span class="s1">&#39;Brittle&#39;</span><span class="p">,</span><span class="s1">&#39;TOC&#39;</span><span class="p">,</span><span class="s1">&#39;Prod&#39;</span><span class="p">])</span> <span class="c1"># matrix scatter plots</span>
<span class="n">pairgrid</span> <span class="o">=</span> <span class="n">pairgrid</span><span class="o">.</span><span class="n">map_upper</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">pairgrid</span> <span class="o">=</span> <span class="n">pairgrid</span><span class="o">.</span><span class="n">map_diag</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;darkorange&#39;</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">)</span><span class="c1"># Map a density plot to the lower triangle</span>
<span class="n">pairgrid</span> <span class="o">=</span> <span class="n">pairgrid</span><span class="o">.</span><span class="n">map_lower</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span><span class="p">,</span> 
                              <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">n_levels</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">pairgrid</span><span class="o">.</span><span class="n">add_legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4c23ae18eda1e533de50c2330dba444a3862043169ebd7569532055f40e72e5f.png" src="_images/4c23ae18eda1e533de50c2330dba444a3862043169ebd7569532055f40e72e5f.png" />
</div>
</div>
</section>
<section id="working-with-only-two-predictor-features">
<h2>Working with Only Two Predictor Features<a class="headerlink" href="#working-with-only-two-predictor-features" title="Permalink to this heading">#</a></h2>
<p>Let’s simplify the problem to 2 predictor features, Porosity and Brittleness to predict Production rate.  By working with only 2 features, it is very easy to visualize the segmentation of the feature space (it is only 2D and can be shown completely on a single plot).</p>
</section>
<section id="standardizing-predictor-features">
<h2>Standardizing Predictor Features<a class="headerlink" href="#standardizing-predictor-features" title="Permalink to this heading">#</a></h2>
<p>The k-nearest neighbour method uses a nearest training sample search in feature space (like k-means clustering). To remove the impact feature range from the approach we standardize the features.</p>
<ul class="simple">
<li><p>we will standardize our predictor features to have a mean of zero and a variance of one.</p></li>
<li><p>we use the scikit-learn preprocessing module to simplify this step and provide a convenient and safe reverse transform.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">if1</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">if2</span> <span class="o">=</span> <span class="mi">3</span>                                              <span class="c1"># selected predictor features</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">();</span>                                 <span class="c1"># instantiate feature standardization method</span>

<span class="n">sel_pred</span> <span class="o">=</span> <span class="p">[</span><span class="n">pred</span><span class="p">[</span><span class="n">if1</span><span class="p">],</span><span class="n">pred</span><span class="p">[</span><span class="n">if2</span><span class="p">]]</span>
<span class="n">sel_features</span> <span class="o">=</span> <span class="n">pred</span> <span class="o">+</span> <span class="p">[</span><span class="n">resp</span><span class="p">]</span>

<span class="n">spredlabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Standardized &#39;</span> <span class="o">+</span> <span class="n">element</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">predlabel</span><span class="p">]</span> <span class="c1"># standardized predictors list</span>

<span class="n">sel_spredlabel</span> <span class="o">=</span> <span class="p">[</span><span class="n">spredlabel</span><span class="p">[</span><span class="n">if1</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[</span><span class="n">spredlabel</span><span class="p">[</span><span class="n">if2</span><span class="p">]]</span> 

<span class="n">sel_spred</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;s&#39;</span> <span class="o">+</span> <span class="n">element</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">sel_pred</span><span class="p">]</span>           <span class="c1"># standardized predictors list</span>

<span class="n">df</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_pred</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)[:,</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># standardize the data features to mean = 0, var = 1.0</span>
<span class="n">df</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_pred</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># standardize the data features to mean = 0, var = 1.0</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Selected Predictor Features: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sel_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Standardized Selected Predictor Features: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sel_spred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Response Feature: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">([</span><span class="n">resp</span><span class="p">]))</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Selected Predictor Features: [&#39;Por&#39;, &#39;Brittle&#39;]
Standardized Selected Predictor Features: [&#39;sPor&#39;, &#39;sBrittle&#39;]
Response Feature: [[&#39;Prod&#39;]]
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
      <th>Prod</th>
      <th>sPor</th>
      <th>sBrittle</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
      <td>1339.165488</td>
      <td>-0.982256</td>
      <td>2.358297</td>
    </tr>
    <tr>
      <th>1</th>
      <td>12.38</td>
      <td>3.53</td>
      <td>3.22</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
      <td>3383.979252</td>
      <td>-0.881032</td>
      <td>-0.141332</td>
    </tr>
    <tr>
      <th>2</th>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
      <td>2509.686720</td>
      <td>-0.327677</td>
      <td>1.748113</td>
    </tr>
    <tr>
      <th>3</th>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
      <td>5514.421023</td>
      <td>0.903875</td>
      <td>-0.592585</td>
    </tr>
    <tr>
      <th>4</th>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
      <td>3532.020478</td>
      <td>0.853263</td>
      <td>-2.640962</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let’s demonstrate the reverse transform from standardized features back to the original features.</p>
<ul class="simple">
<li><p>we won’t need this in our workflow since the we only need to forward transform the predictor features to train the model and make predictions</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Backtransformed: </span><span class="se">\n</span><span class="s1">        Por    Brittle&#39;</span><span class="p">)</span>
<span class="n">transform</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_spred</span><span class="p">])[:</span><span class="mi">5</span><span class="p">,:]</span>        <span class="c1"># check the reverse standardization</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Backtransformed: 
        Por    Brittle
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[12.08, 81.4 ],
       [12.38, 46.17],
       [14.02, 72.8 ],
       [17.67, 39.81],
       [17.52, 10.94]])
</pre></div>
</div>
</div>
</div>
<p>We can compare the output above with the original porosity and brittleness. The reverse transform works!</p>
<ul class="simple">
<li><p>We will use this method to return to original feature units when needed.</p></li>
<li><p>In general, the back transformation is not needed for predictor features, well only forward transform the predictor features to make predictions of the response feature.</p></li>
<li><p>In this example, we don’t need to transform the response feature while building our model. The response feature distribution is well-behaved and there is not theory in k-nearest neighbours that expects a specific range or distribution share for the response feature.</p></li>
</ul>
</section>
<section id="feature-ranges">
<h2>Feature Ranges<a class="headerlink" href="#feature-ranges" title="Permalink to this heading">#</a></h2>
<p>Let’s set some ranges for plotting. Note for the standardized predictor features we will use -3.5 to 3.5 as the limits.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Xmin</span> <span class="o">=</span> <span class="p">[</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">];</span> <span class="n">Xmax</span> <span class="o">=</span> <span class="p">[</span><span class="mf">25.0</span><span class="p">,</span><span class="mf">100.0</span><span class="p">]</span>                        <span class="c1"># selected predictor features min and max</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-and-test-split">
<h2>Train and Test Split<a class="headerlink" href="#train-and-test-split" title="Permalink to this heading">#</a></h2>
<p>For convenience and simplicity we use scikit-learn’s random train and test split.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_spred</span><span class="p">],</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">resp</span><span class="p">],</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">73073</span><span class="p">)</span>
<span class="n">df_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                <span class="c1"># make one train DataFrame with both X and y (remove all other features)</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                   <span class="c1"># make one testin DataFrame with both X and y (remove all other features)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s first check the univariate statistics of Porosity, Brittleness and Production.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nbins</span> <span class="o">=</span> <span class="mi">20</span>                                                    <span class="c1"># number of histogram bins</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;darkorange&#39;</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">nbins</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">nbins</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Test&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">sel_spredlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;darkorange&#39;</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">nbins</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">nbins</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Test&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">sel_spredlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">],</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;darkorange&#39;</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">nbins</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">],</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">nbins</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Test&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">resplabel</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a6e3b01d9e6230c6eb26e1b06c604aa2fc175bb399d25bcd7794d5fb4b1b1e46.png" src="_images/a6e3b01d9e6230c6eb26e1b06c604aa2fc175bb399d25bcd7794d5fb4b1b1e46.png" />
</div>
</div>
<p>The distributions are well behaved,</p>
<ul class="simple">
<li><p>we cannot observe obvious gaps nor truncations.</p></li>
<li><p>check coverage of the train and test data</p></li>
</ul>
<p>Let’s look at a scatter plot of Porosity vs. Brittleness with points colored by Production.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                                              <span class="c1"># train data plot</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">ymin</span><span class="p">,</span> 
                 <span class="n">vmax</span><span class="o">=</span><span class="n">ymax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Train &#39;</span> <span class="o">+</span> <span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39; vs. &#39;</span> <span class="o">+</span> <span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39; and &#39;</span> <span class="o">+</span> <span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">sel_spredlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">sel_spredlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">&#39;vertical&#39;</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="n">resplabel</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">270</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
<span class="n">add_grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                               <span class="c1"># test data plot</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">ymin</span><span class="p">,</span> 
                 <span class="n">vmax</span><span class="o">=</span><span class="n">ymax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Test &#39;</span> <span class="o">+</span> <span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39; vs. &#39;</span> <span class="o">+</span> <span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39; and &#39;</span> <span class="o">+</span> <span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">sel_spredlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">sel_spredlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">&#39;vertical&#39;</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="n">resplabel</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">270</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
<span class="n">add_grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4c88383d908cf65a54e1601379bf0b36cdbfab09eeae0ff5cc37587387fd084c.png" src="_images/4c88383d908cf65a54e1601379bf0b36cdbfab09eeae0ff5cc37587387fd084c.png" />
</div>
</div>
<p>This problem looks nonlinear and could not be modeled with simple linear regression.</p>
<ul class="simple">
<li><p>It appears there is a sweet spot for Brittleness and increasing Porosity is always beneficial for Production.</p></li>
</ul>
</section>
<section id="instantiate-fit-and-predict-with-k-nearest-neighbour">
<h2>Instantiate, Fit and Predict with k-nearest Neighbour<a class="headerlink" href="#instantiate-fit-and-predict-with-k-nearest-neighbour" title="Permalink to this heading">#</a></h2>
<p>Let’s instantiate, fit and predict with a k-nearest neighbour model.</p>
<ul class="simple">
<li><p>instantiate it with the hyperparameters, k-nearest neighbours</p></li>
<li><p>train with the training data, we use the standard fit function from scikit-learn</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_neighbours</span> <span class="o">=</span> <span class="mi">150</span><span class="p">;</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="n">weights</span> <span class="o">=</span> <span class="s1">&#39;uniform&#39;</span>                 <span class="c1"># model hyperparameters</span>
<span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbours</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="p">)</span> <span class="c1"># instantiate the prediction model</span>
</pre></div>
</div>
</div>
</div>
<p>We have set the hyperparameters:</p>
<ul class="simple">
<li><p>weights = averaging weights for the prediction given the nearest neighbours. ‘uniform’ is arithmetic average, while ‘distance’ is inverse distance weighting.</p></li>
<li><p>n_neighbours = maximum number of neighbours. Note, we constrain our prediction by limiting it to 5 nearest neighbours.</p></li>
<li><p>p = distance metric power or Minkowski metric (1 = Manhattan distance, 2 for Euclidian distance) for finding the nearest neighbours.</p></li>
</ul>
<p>Now we are ready to fit our model for prediction of Production given Porosity and Brittleness.</p>
<ul class="simple">
<li><p>We will use our two functions defined above to visualize the k-nearest neighbour prediction over the feature space and the cross plot of actual and estimated production for the training data along with three model metrics from the sklearn.metric module.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">neigh_fit</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>                        <span class="c1"># train the model with the training data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>                                              <span class="c1"># training data vs. the model predictions</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                    <span class="s1">&#39;Training Data and k Nearest Neighbours&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;Hyperparameters&#39;</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;weights: &#39;</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;n neighbours: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;distance norm: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>                                              <span class="c1"># testing data vs. the model predictions</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">&#39;Testing Data and k Nearest Neighbours&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;Hyperparameters&#39;</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;weights: &#39;</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;n neighbours: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;distance norm: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

<span class="c1"># plt.subplot(223)                                              # model accuracy check</span>
<span class="c1"># check_model(neigh_fit,X_train[sel_spred[0]],X_train[sel_spred[1]],X_test[sel_spred[0]],X_test[sel_spred[1]],ymin,ymax,</span>
<span class="c1">#             y_train[resp[0]],y_test[resp[0]],&#39;K Nearest Neighbour Regression Model Accuracy&#39;)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/dd9cfeb47657661a2423dad215c8b8dd2eac3b9b797de000dfff181328be6aff.png" src="_images/dd9cfeb47657661a2423dad215c8b8dd2eac3b9b797de000dfff181328be6aff.png" />
</div>
</div>
<p>The model looks good:</p>
<ul class="simple">
<li><p>the nonparametric approach is quite flexible to fit the nonlinear response patterns in the predictor feature space</p></li>
<li><p>we can see some search artifacts due to limited k nearest data and the use of uniform weighting</p></li>
<li><p>we have dense data for this low dimensional problem (only 2 predictor features)</p></li>
<li><p>the testing and training data are consistent and close to each other in the predictor feature space</p></li>
</ul>
<p>Let’s try to overfit the model by using a very large k hyperparameter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_neighbours</span> <span class="o">=</span> <span class="mi">100</span><span class="p">;</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="n">weights</span> <span class="o">=</span> <span class="s1">&#39;uniform&#39;</span>                <span class="c1"># model hyperparameters</span>
<span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbours</span><span class="p">,</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="p">)</span> <span class="c1"># instantiate the prediction model</span>

<span class="n">neigh_fit</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>                        <span class="c1"># train the model with the training data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>                                              <span class="c1"># training data vs. the model predictions</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                    <span class="s1">&#39;Training Data and k Nearest Neighbours&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;Hyperparameters&#39;</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;weights: &#39;</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;n neighbours: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;distance norm: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>                                              <span class="c1"># testing data vs. the model predictions</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">&#39;Testing Data and k Nearest Neighbours&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;Hyperparameters&#39;</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;weights: &#39;</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;n neighbours: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;distance norm: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>                                              <span class="c1"># model accuracy check</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
            <span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="s1">&#39;K Nearest Neighbour Regression Model Accuracy&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/8d931fb3fa3f3ee1a1ed229fa21395220ef6ac0f45302dd8c455e15d1d795c9d.png" src="_images/8d931fb3fa3f3ee1a1ed229fa21395220ef6ac0f45302dd8c455e15d1d795c9d.png" />
</div>
</div>
<p>Note that this smoothed out the response, and the predictions are approaching the global mean.</p>
<ul class="simple">
<li><p>we have an underfit model.</p></li>
</ul>
<p>Next let’s use a smaller k hyperparameter for our k-nearest neighbours prediction model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_neighbours</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="n">weights</span> <span class="o">=</span> <span class="s1">&#39;uniform&#39;</span>                  <span class="c1"># model hyperparameters</span>
<span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbours</span><span class="p">,</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="p">)</span> <span class="c1"># instantiate the prediction model</span>

<span class="n">neigh_fit</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>                        <span class="c1"># train the model with the training data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>                                              <span class="c1"># training data vs. the model predictions</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                    <span class="s1">&#39;Training Data and k Nearest Neighbours&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;Hyperparameters&#39;</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;weights: &#39;</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;n neighbours: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;distance norm: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>                                              <span class="c1"># testing data vs. the model predictions</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">&#39;Testing Data and k Nearest Neighbours&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;Hyperparameters&#39;</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;weights: &#39;</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;n neighbours: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;distance norm: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>                                              <span class="c1"># model accuracy check</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
            <span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="s1">&#39;K Nearest Neighbour Regression Model Accuracy&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/36151afeb7ee7ec97d8f9695513890616f1d619cbc81c9e9a734492d90c1e86f.png" src="_images/36151afeb7ee7ec97d8f9695513890616f1d619cbc81c9e9a734492d90c1e86f.png" />
</div>
</div>
<p>Now we have an extreme overfit model.</p>
<ul class="simple">
<li><p>The training MSE is 0.0 and the testing error is quite high.</p></li>
<li><p>Note, some of our predictions in our overfit model are outside the plotting min and max response feature values.</p></li>
</ul>
<p>Let’s try to use a L1, Manhattan distance to find the k nearest neighbours.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_neighbours</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">weights</span> <span class="o">=</span> <span class="s1">&#39;uniform&#39;</span>                 <span class="c1"># model hyperparameters</span>
<span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbours</span><span class="p">,</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="p">)</span> <span class="c1"># instantiate the prediction model</span>

<span class="n">neigh_fit</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>                        <span class="c1"># train the model with the training data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>                                              <span class="c1"># training data vs. the model predictions</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                    <span class="s1">&#39;Training Data and k Nearest Neighbours&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;Hyperparameters&#39;</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;weights: &#39;</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;n neighbours: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;distance norm: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>                                              <span class="c1"># testing data vs. the model predictions</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">&#39;Testing Data and k Nearest Neighbours&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;Hyperparameters&#39;</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;weights: &#39;</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;n neighbours: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;distance norm: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>                                              <span class="c1"># model accuracy check</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
            <span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="s1">&#39;K Nearest Neighbour Regression Model Accuracy&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/58118fcb46c0eb738a754ea3e1103828cda85f1f5eea8dc2d12b6e69215213d3.png" src="_images/58118fcb46c0eb738a754ea3e1103828cda85f1f5eea8dc2d12b6e69215213d3.png" />
</div>
</div>
<p>Compare this prediction model to our first model, all we changes is the distance search for the k nearest samples to Manhattan from Euclidean distance.</p>
<ul class="simple">
<li><p>the search artifacts are now aligned on the features (the rays are oriented in the x and y directions)</p></li>
</ul>
</section>
<section id="hyperparameter-tuning-for-k-nearest-neighbours">
<h2>Hyperparameter Tuning for k-Nearest Neighbours<a class="headerlink" href="#hyperparameter-tuning-for-k-nearest-neighbours" title="Permalink to this heading">#</a></h2>
<p>Let’s check this out as we tune the hyper parameters.</p>
<p>So what does the <span class="math notranslate nohighlight">\(k\)</span> do?</p>
<ul class="simple">
<li><p>small <span class="math notranslate nohighlight">\(k\)</span> hyperparameter results in a local specific prediction model over the predictor feature space</p></li>
<li><p>large <span class="math notranslate nohighlight">\(k\)</span> hyperparameter results in a more smooth, globally fit prediction model over the predictor features space</p></li>
</ul>
<p>This is analogous to the low to high complexity we have observed with other models (like decision trees).</p>
<ul class="simple">
<li><p>small <span class="math notranslate nohighlight">\(k\)</span> is complex</p></li>
<li><p>large <span class="math notranslate nohighlight">\(k\)</span> is simple</p></li>
</ul>
<p>We need to tune the complexity to optimize model performance.</p>
</section>
<section id="tuning-the-hyperparameters">
<h2>Tuning the Hyperparameters<a class="headerlink" href="#tuning-the-hyperparameters" title="Permalink to this heading">#</a></h2>
<p>Let’s loop over multiple <span class="math notranslate nohighlight">\(k\)</span> nearest neighbours for average and inverse distance estimates to access the best hyperparameters with respect to accuracy in testing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">k</span> <span class="o">=</span> <span class="mi">1</span>                                                         <span class="c1"># set initial, lowest k hyperparameter</span>
<span class="n">dist_error</span> <span class="o">=</span> <span class="p">[];</span> <span class="n">unif_error</span> <span class="o">=</span> <span class="p">[];</span> <span class="n">k_mat</span> <span class="o">=</span> <span class="p">[]</span>                  <span class="c1"># make lists to store the results</span>
<span class="k">while</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">150</span><span class="p">:</span>                                               <span class="c1"># loop over the k hyperparameter</span>
    <span class="n">neigh_dist</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="s1">&#39;distance&#39;</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># instantiate the model</span>
    <span class="n">neigh_dist_fit</span> <span class="o">=</span> <span class="n">neigh_dist</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>          <span class="c1"># train the model with the training data</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">neigh_dist_fit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>                   <span class="c1"># predict over the testing cases</span>
    <span class="n">MSE</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>           <span class="c1"># calculate the MSE testing</span>
    <span class="n">dist_error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MSE</span><span class="p">)</span>                                    <span class="c1"># add to the list of MSE</span>
    
    <span class="n">neigh_unif</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">neigh_unif_fit</span> <span class="o">=</span> <span class="n">neigh_unif</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>          <span class="c1"># train the model with the training data</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">neigh_unif_fit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>                   <span class="c1"># predict over the testing cases</span>
    <span class="n">MSE</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>           <span class="c1"># calculate the MSE testing</span>
    <span class="n">unif_error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MSE</span><span class="p">)</span>                                    <span class="c1"># add to the list of MSE</span>
    
    <span class="n">k_mat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>                                           <span class="c1"># append k to an array for plotting</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s plot the result.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">k_mat</span><span class="p">,</span><span class="n">dist_error</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;inverse distance weighted&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">k_mat</span><span class="p">,</span><span class="n">unif_error</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;arithmetic average&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Testing Error vs. Number of Nearest Neighbours&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Nearest Neighbours&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Mean Square Error&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">50</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">750000</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/01eac05af310de41e5fc30ed84e0dd7ffbc211efc97eea008ec63bd1c8ef9a09.png" src="_images/01eac05af310de41e5fc30ed84e0dd7ffbc211efc97eea008ec63bd1c8ef9a09.png" />
</div>
</div>
<p>What can we observe from this result?</p>
<ul class="simple">
<li><p>at <span class="math notranslate nohighlight">\(k = 12\)</span> nearest neighbours we minimize the mean square error in testing.</p></li>
<li><p>we have better performance with the inverse distance weighted than the arithmetic average (uniform weighting of k nearest training data in predictor feature space)</p></li>
</ul>
<p>There is an optimum degree of specificity / complexity to our model.</p>
<ul class="simple">
<li><p>1 nearest neighbour is a very locally specific model (overfit)</p></li>
<li><p>many nearest neighbours includes too much information and is too general (underfit)</p></li>
</ul>
<p>We are observing the accuracy vs. complexity trade-off for the <span class="math notranslate nohighlight">\(k\)</span> nearest neighbour model.</p>
</section>
<section id="k-fold-cross-validation">
<h2>k-fold Cross Validation<a class="headerlink" href="#k-fold-cross-validation" title="Permalink to this heading">#</a></h2>
<p>It is useful to evaluate the performance of our model by observing the accuracy vs. complexity trade-off.</p>
<p>Yet, what we really want to do is rigorously test our model performance.  We should perform a more rigorous cross validation that does a better job evaluating over different sets of training and testing data. scikit learn has a built in cross validation method called cross_val_score that we can use to:</p>
<ol class="arabic simple">
<li><p>Apply k-fold approach with iterative separation of training and testing data</p></li>
<li><p>Automate the model construction, looping over folds and averaging the metric of interest</p></li>
</ol>
<p>Let’s try it out on our k nearest neighbour prediction with variable number of <span class="math notranslate nohighlight">\(k\)</span> nearest neighbours.  Note the cross validation is set to use 4 processors, but still will likely take a couple of minutes to run.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">score</span> <span class="o">=</span> <span class="p">[]</span>                                                  <span class="c1"># code modified from StackOverFlow by Dimosthenis</span>
<span class="n">k_mat</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">150</span><span class="p">):</span>
    <span class="n">neigh_dist</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="s1">&#39;distance&#39;</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">neigh_dist</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;sPor&#39;</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;sBrittle&#39;</span><span class="p">]],</span><span class="n">y</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Prod&#39;</span><span class="p">],</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                             <span class="n">scoring</span> <span class="o">=</span> <span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">)</span> <span class="c1"># Perform 7-fold cross validation</span>
    <span class="n">score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
    <span class="n">k_mat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The output is an array of average scores (MSE) over the k-folds for each level of complexity (number of <span class="math notranslate nohighlight">\(k\)</span> nearest neighbours), along with an array with the <span class="math notranslate nohighlight">\(k\)</span>s.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">k_mat</span><span class="p">,</span><span class="n">score</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;k-fold Cross Validation Error (MSE) vs. k Nearest Neighbours&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Nearest Neighbours&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Mean Square Error&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">150</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1400000</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3486b059575a23212d8aafc3a96a97665590c325236271232ebf8b699313ea39.png" src="_images/3486b059575a23212d8aafc3a96a97665590c325236271232ebf8b699313ea39.png" />
</div>
</div>
<p>With the hyperparameter of 10 nearest neighbours we get the greatest accuracy in k-fold cross validation model testing.</p>
</section>
<section id="predictor-feature-standardization">
<h2>Predictor Feature Standardization<a class="headerlink" href="#predictor-feature-standardization" title="Permalink to this heading">#</a></h2>
<p>We have standardized the predictor feature to remove the influence of their ranges.</p>
<ul class="simple">
<li><p>What would happen if we worked with the original predictor features?</p></li>
</ul>
<p>Let’s try it out.</p>
<ul class="simple">
<li><p>we first apply train and test split with the original features, without standardization</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_orig</span><span class="p">,</span> <span class="n">X_test_orig</span><span class="p">,</span> <span class="n">y_train_orig</span><span class="p">,</span> <span class="n">y_test_orig</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_pred</span><span class="p">],</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">resp</span><span class="p">],</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">73073</span><span class="p">)</span>

<span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="s1">&#39;distance&#39;</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">neigh_fit</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_orig</span><span class="p">,</span><span class="n">y_train_orig</span><span class="p">)</span>                <span class="c1"># train the model with the training data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                                              <span class="c1"># training data vs. the model predictions</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X_train_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                    <span class="s1">&#39;Training Data and k Nearest Neighbours&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;Hyperparameters&#39;</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;weights: &#39;</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;n neighbours: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;distance norm: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                              <span class="c1"># testing data vs. the model predictions</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_test_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X_test_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">&#39;Testing Data and k Nearest Neighbours&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;Hyperparameters&#39;</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;weights: &#39;</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;n neighbours: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;distance norm: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/8c3133ce421b3030fdd8a00084845ccd1d24e4e798c75f636c0920eebed4d5c6.png" src="_images/8c3133ce421b3030fdd8a00084845ccd1d24e4e798c75f636c0920eebed4d5c6.png" />
</div>
</div>
<p>Do you see the horizontal banding?  The larger range of magnitudes of brittleness vs. porosity results in this banding.</p>
<ul class="simple">
<li><p>distances in the feature space are more sensitive to the relative changes in brittleness than porosity</p></li>
</ul>
<p>Let’s convert porosity to a fraction and observe the change in our predictor due to the arbitrary decision to work with porosity as a fraction vs. a percentage.</p>
<ul class="simple">
<li><p>by applying a <span class="math notranslate nohighlight">\(\frac{1}{100}\)</span> factor to all the porosity values.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_orig</span><span class="p">,</span> <span class="n">X_test_orig</span><span class="p">,</span> <span class="n">y_train_orig</span><span class="p">,</span> <span class="n">y_test_orig</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_pred</span><span class="p">],</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">resp</span><span class="p">],</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">73073</span><span class="p">)</span>

<span class="n">X_train_orig</span><span class="p">[</span><span class="s1">&#39;Por&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_train_orig</span><span class="p">[</span><span class="s1">&#39;Por&#39;</span><span class="p">]</span><span class="o">/</span><span class="mf">100.0</span>
<span class="n">X_test_orig</span><span class="p">[</span><span class="s1">&#39;Por&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_test_orig</span><span class="p">[</span><span class="s1">&#39;Por&#39;</span><span class="p">]</span><span class="o">/</span><span class="mf">100.0</span>

<span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="s1">&#39;distance&#39;</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">neigh_fit</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_orig</span><span class="p">,</span><span class="n">y_train_orig</span><span class="p">)</span>                <span class="c1"># train the model with the training data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                                              <span class="c1"># training data vs. the model predictions</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">,</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">,</span><span class="n">X_train_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                    <span class="s1">&#39;Training Data and k Nearest Neighbours&#39;</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;Hyperparameters&#39;</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;weights: &#39;</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;n neighbours: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;distance norm: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                              <span class="c1"># testing data vs. the model predictions</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_test_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">,</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">,</span><span class="n">X_test_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">&#39;Testing Data and k Nearest Neighbours&#39;</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;Hyperparameters&#39;</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;weights: &#39;</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;n neighbours: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;distance norm: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e98632fa73beaf85be54462502e9cd2b26c6bc804f11e5ba193bd5a17f99b64d.png" src="_images/e98632fa73beaf85be54462502e9cd2b26c6bc804f11e5ba193bd5a17f99b64d.png" />
</div>
</div>
<ul class="simple">
<li><p>this banding effect gets even more severe as we convert from percentage to fractional porosity, because distances in porosity appear so much closer than in brittleness, just because of the difference in feature ranges.</p></li>
</ul>
<p>Our distance metric for assigning nearest neighbours is quite sensitive to the feature units.  We should always standardize all predictor features (put them on equal footing) before we use them to build our <span class="math notranslate nohighlight">\(k\)</span>-nearest neighbour regression model!</p>
</section>
<section id="k-nearest-neighbour-regression-in-scikit-learn-with-pipelines">
<h2>k Nearest Neighbour Regression in scikit-learn with Pipelines<a class="headerlink" href="#k-nearest-neighbour-regression-in-scikit-learn-with-pipelines" title="Permalink to this heading">#</a></h2>
<p>The need to standardize features, train, tune and retrain the tuned model with all the data may seem to be a lot of work!</p>
<ul class="simple">
<li><p>one solution is to use the Pipeline object from scikit-learn.</p></li>
</ul>
<p>Here’s some highlights on Pipelines.</p>
<section id="machine-learning-modeling-pipelines-basics">
<h3>Machine Learning Modeling Pipelines Basics<a class="headerlink" href="#machine-learning-modeling-pipelines-basics" title="Permalink to this heading">#</a></h3>
<p>Machine learning workflows can be complicated, with various steps:</p>
<ul class="simple">
<li><p>data preparation, feature engineering transformations</p></li>
<li><p>model parameter fitting</p></li>
<li><p>model hyperparameter tuning</p></li>
<li><p>modeling method selection</p></li>
<li><p>searching over a large combinatorial of hyperparameters</p></li>
<li><p>training and testing model runs</p></li>
</ul>
<p>Pipelines are a scikit-learn class that allows for the encapsulation of a sequence of data preparation and modeling steps</p>
<ul class="simple">
<li><p>then we can treat the pipeline as an object in our much condensed workflow</p></li>
</ul>
<p>The pipeline class allows us to:</p>
<ul class="simple">
<li><p>improve code readability and to keep everything straight</p></li>
<li><p>avoid common workflow problems like data leakage, testing data informing model parameter training</p></li>
<li><p>abstract common machine learning modeling and focus on building the best model possible</p></li>
</ul>
<p>The fundamental philosophy is to treat machine learning as a combinatorial search to automate the determination of the best model (AutoML)</p>
</section>
<section id="k-nearest-neighbours-with-pipelines">
<h3>k-Nearest Neighbours with Pipelines<a class="headerlink" href="#k-nearest-neighbours-with-pipelines" title="Permalink to this heading">#</a></h3>
<p>Here’s compact, safe code for the entire model training and tuning process with scikit-learn pipelines</p>
<ul class="simple">
<li><p>the GridSearchCV object actually becomes the prediction model, with tuned hyperparameters retrained on all of the data!</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>                                                     <span class="c1"># to set current working directory </span>

<span class="n">folds</span> <span class="o">=</span> <span class="mi">4</span>                                                   <span class="c1"># number of k folds</span>
<span class="n">k_min</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">k_max</span> <span class="o">=</span> <span class="mi">150</span>                                       <span class="c1"># range of k hyperparameter to consider</span>

<span class="n">X_pipe</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_pred</span><span class="p">]</span>                                 <span class="c1"># all the samples for the original features</span>
<span class="n">y_pipe</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>                             <span class="c1"># warning this becomes a series, 1D ndarray with label</span>

<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>                                           <span class="c1"># the machine learning workflow as a pipeline object</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;knear&#39;</span><span class="p">,</span> <span class="n">KNeighborsRegressor</span><span class="p">())</span>
<span class="p">])</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>                                                  <span class="c1"># the machine learning workflow method&#39;s parameters</span>
    <span class="s1">&#39;scaler&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">StandardScaler</span><span class="p">()],</span>
    <span class="s1">&#39;knear__n_neighbors&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">k_min</span><span class="p">,</span><span class="n">k_max</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">dtype</span> <span class="o">=</span> <span class="nb">int</span><span class="p">),</span>
    <span class="s1">&#39;knear__metric&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;euclidean&#39;</span><span class="p">],</span>
    <span class="s1">&#39;knear__p&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span>
    <span class="s1">&#39;knear__weights&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;distance&#39;</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">grid_cv_tuned</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;neg_mean_squared_error&#39;</span><span class="p">,</span> <span class="c1"># grid search cross validation </span>
                             <span class="n">cv</span><span class="o">=</span><span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">folds</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                             <span class="n">refit</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">grid_cv_tuned</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_pipe</span><span class="p">,</span><span class="n">y_pipe</span><span class="p">)</span>                                      <span class="c1"># fit model with tuned hyperparameters</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">visualize_tuned_model</span><span class="p">(</span><span class="n">grid_cv_tuned</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;knear__n_neighbors&#39;</span><span class="p">],</span> <span class="c1"># visualize the error vs. k </span>
                      <span class="n">grid_cv_tuned</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;param_knear__n_neighbors&#39;</span><span class="p">],</span>
                      <span class="nb">abs</span><span class="p">(</span><span class="n">grid_cv_tuned</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]))</span>              

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                            <span class="c1"># visualize the tuned model</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">grid_cv_tuned</span><span class="p">,</span><span class="n">X</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">&#39;All Data and Tuned and Retrained k-Nearest Neighbours&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/83fd2c84c5d45efc2ab0262137bbbdafd882df6ec6ab4098a5b6e277724e7c05.png" src="_images/83fd2c84c5d45efc2ab0262137bbbdafd882df6ec6ab4098a5b6e277724e7c05.png" />
</div>
</div>
</section>
<section id="check-the-tuned-hyperparameters">
<h3>Check the Tuned Hyperparameters<a class="headerlink" href="#check-the-tuned-hyperparameters" title="Permalink to this heading">#</a></h3>
<p>In the GridSearchCV model object, there is a built in dictionary called best_params_ that includes all the tuned hyperparameters.</p>
<ul class="simple">
<li><p>note, over the range of k’s the selected k, n_neighbors</p></li>
<li><p>also, the other hyperparameters were specified, but we could have provided a range and scenarios for each to explore with the grid search method</p></li>
</ul>
<p>When tuning more than 1 hyperparameter, the runtime will increase with the combinatorial of hyperparameters and the resulting model loss function, e.g., cv_results_[‘mean_test_score’], is sorted over all the hyperparameter cases</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_cv_tuned</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;knear__metric&#39;: &#39;euclidean&#39;,
 &#39;knear__n_neighbors&#39;: 11,
 &#39;knear__p&#39;: 2,
 &#39;knear__weights&#39;: &#39;distance&#39;,
 &#39;scaler&#39;: StandardScaler()}
</pre></div>
</div>
</div>
</div>
<p>It is also useful to look at the entire model object for more information. Including:</p>
<ul class="simple">
<li><p>the pipeline and all cases considered for the hyperparameter tuning.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_cv_tuned</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=KFold(n_splits=4, random_state=None, shuffle=False),
             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),
                                       (&#x27;knear&#x27;, KNeighborsRegressor())]),
             param_grid={&#x27;knear__metric&#x27;: [&#x27;euclidean&#x27;],
                         &#x27;knear__n_neighbors&#x27;: array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,
        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,
        40,  41,  42,  43,  44,  45,...
        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,
        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,
       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,
       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,
       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149]),
                         &#x27;knear__p&#x27;: [2], &#x27;knear__weights&#x27;: [&#x27;distance&#x27;],
                         &#x27;scaler&#x27;: [StandardScaler()]},
             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" ><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">GridSearchCV</label><div class="sk-toggleable__content"><pre>GridSearchCV(cv=KFold(n_splits=4, random_state=None, shuffle=False),
             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),
                                       (&#x27;knear&#x27;, KNeighborsRegressor())]),
             param_grid={&#x27;knear__metric&#x27;: [&#x27;euclidean&#x27;],
                         &#x27;knear__n_neighbors&#x27;: array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,
        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,
        40,  41,  42,  43,  44,  45,...
        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,
        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,
       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,
       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,
       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149]),
                         &#x27;knear__p&#x27;: [2], &#x27;knear__weights&#x27;: [&#x27;distance&#x27;],
                         &#x27;scaler&#x27;: [StandardScaler()]},
             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" ><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">estimator: Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;knear&#x27;, KNeighborsRegressor())])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" ><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler()</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox" ><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">KNeighborsRegressor</label><div class="sk-toggleable__content"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
</section>
</section>
<section id="comments">
<h2>Comments<a class="headerlink" href="#comments" title="Permalink to this heading">#</a></h2>
<p>This was a basic treatment of k-nearest neighbours. Much more could be done and discussed, I have many more resources. Check out my <a class="reference external" href="https://michaelpyrcz.com/my-resources">shared resource inventory</a> and the YouTube lecture links at the start of this chapter with resource links in the videos’ descriptions.</p>
<p>I hope this is helpful,</p>
<p><em>Michael</em></p>
</section>
<section id="about-the-author">
<h2>About the Author<a class="headerlink" href="#about-the-author" title="Permalink to this heading">#</a></h2>
<figure style="text-align: center;">
  <img src="_static/intro/michael_pyrcz_officeshot_jacket.jpg" style="display: block; margin: 0 auto; width: 70%;">
  <figcaption style="text-align: center;"> Professor Michael Pyrcz in his office on the 40 acres, campus of The University of Texas at Austin.
</figcaption>
</figure>
<p>Michael Pyrcz is a professor in the <a class="reference external" href="https://cockrell.utexas.edu/faculty-directory/alphabetical/p">Cockrell School of Engineering</a>, and the <a class="reference external" href="https://www.jsg.utexas.edu/researcher/michael_pyrcz/">Jackson School of Geosciences</a>, at <a class="reference external" href="https://www.utexas.edu/">The University of Texas at Austin</a>, where he researches and teaches subsurface, spatial data analytics, geostatistics, and machine learning. Michael is also,</p>
<ul class="simple">
<li><p>the principal investigator of the <a class="reference external" href="https://fri.cns.utexas.edu/energy-analytics">Energy Analytics</a> freshmen research initiative and a core faculty in the Machine Learn Laboratory in the College of Natural Sciences, The University of Texas at Austin</p></li>
<li><p>an associate editor for <a class="reference external" href="https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board">Computers and Geosciences</a>, and a board member for <a class="reference external" href="https://link.springer.com/journal/11004/editorial-board">Mathematical Geosciences</a>, the International Association for Mathematical Geosciences.</p></li>
</ul>
<p>Michael has written over 70 <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en">peer-reviewed publications</a>, a <a class="reference external" href="https://pypi.org/project/geostatspy/">Python package</a> for spatial data analytics, co-authored a textbook on spatial data analytics, <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistical Reservoir Modeling</a> and author of two recently released e-books, <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostatistics in Python: a Hands-on Guide with GeostatsPy</a> and <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html">Applied Machine Learning in Python: a Hands-on Guide with Code</a>.</p>
<p>All of Michael’s university lectures are available on his <a class="reference external" href="https://www.youtube.com/&#64;GeostatsGuyLectures">YouTube Channel</a> with links to 100s of Python interactive dashboards and well-documented workflows in over 40 repositories on his <a class="reference external" href="https://github.com/GeostatsGuy">GitHub account</a>, to support any interested students and working professionals with evergreen content. To find out more about Michael’s work and shared educational resources visit his <span class="xref myst">Website</span>.</p>
</section>
<section id="want-to-work-together">
<h2>Want to Work Together?<a class="headerlink" href="#want-to-work-together" title="Permalink to this heading">#</a></h2>
<p>I hope this content is helpful to those that want to learn more about subsurface modeling, data analytics and machine learning. Students and working professionals are welcome to participate.</p>
<ul class="simple">
<li><p>Want to invite me to visit your company for training, mentoring, project review, workflow design and / or consulting? I’d be happy to drop by and work with you!</p></li>
<li><p>Interested in partnering, supporting my graduate student research or my Subsurface Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)? My research combines data analytics, stochastic modeling and machine learning theory with practice to develop novel methods and workflows to add value. We are solving challenging subsurface problems!</p></li>
<li><p>I can be reached at <a class="reference external" href="mailto:mpyrcz&#37;&#52;&#48;austin&#46;utexas&#46;edu">mpyrcz<span>&#64;</span>austin<span>&#46;</span>utexas<span>&#46;</span>edu</a>.</p></li>
</ul>
<p>I’m always happy to discuss,</p>
<p><em>Michael</em></p>
<p>Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The Jackson School of Geosciences, The University of Texas at Austin</p>
</section>
<section id="more-resources-available-at-twitter-github-website-googlescholar-book-youtube-applied-geostats-in-python-e-book-linkedin">
<h2>More Resources Available at: <a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a><a class="headerlink" href="#more-resources-available-at-twitter-github-website-googlescholar-book-youtube-applied-geostats-in-python-e-book-linkedin" title="Permalink to this heading">#</a></h2>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="MachineLearning_polynomial_regression.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Polynomial Regression</p>
      </div>
    </a>
    <a class="right-next"
       href="MachineLearning_decision_tree.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Decision Tree</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivations-for-k-nearest-neighbours-regression">Motivations for k-nearest Neighbours Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convolution">Convolution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#k-nearest-neighbours-hyperparameters">k-nearest Neighbours Hyperparameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-the-required-libraries">Load the Required Libraries</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#declare-functions">Declare Functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#set-the-working-directory">Set the Working Directory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-tabular-data">Loading Tabular Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-add-random-noise-to-the-response-feature">Optional: Add Random Noise to the Response Feature</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-the-dataframe">Visualize the DataFrame</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-statistics-for-tabular-data">Summary Statistics for Tabular Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculate-the-correlation-matrix-and-correlation-with-response-ranking">Calculate the Correlation Matrix and Correlation with Response Ranking</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#working-with-only-two-predictor-features">Working with Only Two Predictor Features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#standardizing-predictor-features">Standardizing Predictor Features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-ranges">Feature Ranges</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-and-test-split">Train and Test Split</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#instantiate-fit-and-predict-with-k-nearest-neighbour">Instantiate, Fit and Predict with k-nearest Neighbour</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-tuning-for-k-nearest-neighbours">Hyperparameter Tuning for k-Nearest Neighbours</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tuning-the-hyperparameters">Tuning the Hyperparameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#k-fold-cross-validation">k-fold Cross Validation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#predictor-feature-standardization">Predictor Feature Standardization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#k-nearest-neighbour-regression-in-scikit-learn-with-pipelines">k Nearest Neighbour Regression in scikit-learn with Pipelines</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-learning-modeling-pipelines-basics">Machine Learning Modeling Pipelines Basics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#k-nearest-neighbours-with-pipelines">k-Nearest Neighbours with Pipelines</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#check-the-tuned-hyperparameters">Check the Tuned Hyperparameters</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comments">Comments</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#about-the-author">About the Author</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#want-to-work-together">Want to Work Together?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#more-resources-available-at-twitter-github-website-googlescholar-book-youtube-applied-geostats-in-python-e-book-linkedin">More Resources Available at: Twitter | GitHub | Website | GoogleScholar | Book | YouTube  | Applied Geostats in Python e-book | LinkedIn</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Michael J. Pyrcz
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024 CC-BY-SA 4.0.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>