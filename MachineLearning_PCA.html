

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Principal Component Analysis &#8212; Applied Machine Learning in Python</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/myfile.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'MachineLearning_PCA';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Multidimensional Scaling" href="MachineLearning_multidimensional_scaling.html" />
    <link rel="prev" title="Spectral Clustering" href="MachineLearning_spectral_clustering.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/AppliedMachineLearning.jpg" class="logo__image only-light" alt="Applied Machine Learning in Python - Home"/>
    <script>document.write(`<img src="_static/AppliedMachineLearning.jpg" class="logo__image only-dark" alt="Applied Machine Learning in Python - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_concepts.html">Machine Learning Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_training_tuning.html">Training and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_workflow_construction.html">Workflow Construction and Coding</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_probability.html">Probability Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_plotting_data_models.html">Loading and Plotting Data and Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_univariate_analysis.html">Univariate Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_multivariate_analysis.html">Multivariate Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_feature_transformations.html">Feature Transformations</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_feature_ranking.html">Feature Ranking</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_feature_imputation.html">Feature Imputation</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_clustering.html">Cluster Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_density-based_clustering.html">Density-based Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_spectral_clustering.html">Spectral Clustering</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Principal Components Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_multidimensional_scaling.html">Multidimensional Scaling</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_random_projection.html">Random Projection</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_linear_regression.html">Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_ridge_regression.html">Ridge Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_LASSO_regression.html">LASSO Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_Bayesian_linear_regression.html">Bayesian Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_naive_Bayes.html">Naive Bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_polynomial_regression.html">Polynomial Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_knearest_neighbours.html">k-Nearest Neighbours</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_decision_tree.html">Decision Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_ensemble_trees.html">Bagging Tree and Random Forest</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_gradient_boosting.html">Gradient Boosting</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_support_vector_machines.html">Support Vector Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_time_series.html">Time Series Analysis and Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="conclusions.html">Conclusions</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning_glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/GeostatsPyDemos_Book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/GeostatsPyDemos_Book/issues/new?title=Issue%20on%20page%20%2FMachineLearning_PCA.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/MachineLearning_PCA.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Principal Component Analysis</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation-for-principal-component-analysis">Motivation for Principal Component Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#curse-of-dimensionality">Curse of Dimensionality</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inferential-machine-learning">Inferential Machine Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Principal Component Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#orthogonal-transformation">Orthogonal Transformation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#best-fitting-interpretation">Best Fitting Interpretation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rotation-based-intepretation">Rotation-based Intepretation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#eigenvalues-eigenvectors-interpretation">Eigenvalues / Eigenvectors Interpretation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-principal-components-analysis-workflow">The Principal Components Analysis Workflow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-the-required-libraries">Load the Required Libraries</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#declare-functions">Declare Functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#set-the-working-directory">Set the Working Directory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-tabular-data">Loading Tabular Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-the-dataframe">Visualize the DataFrame</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-statistics-for-tabular-data">Summary Statistics for Tabular Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculate-the-correlation-matrix">Calculate the Correlation Matrix</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#check-matrix-scatter-plots">Check Matrix Scatter Plots</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-bivariate-example">Simple Bivariate Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculation-of-principal-components">Calculation of Principal Components</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#standardize-the-features">Standardize the Features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#principal-component-analysis-pca">Principal Component Analysis (PCA)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#component-loadings">Component Loadings</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#proportion-of-variance-explained-with-principal-components">Proportion of Variance Explained with Principal Components</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#principal-component-scores-forward-and-reverse-projections">Principal Component Scores, Forward and Reverse Projections</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conservation-of-variance">Conservation of Variance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#independence-of-principal-component-scores">Independence of Principal Component Scores</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#principal-component-analysis-by-hand-with-eigenvalue-and-eigen-vector-calculator">Principal Component Analysis By-hand with Eigenvalue and Eigen Vector Calculator</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstration-of-dimensional-reduction">Demonstration of Dimensional Reduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#all-predictor-features">All Predictor Features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scree-plots">Scree Plots</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Independence of Principal Component Scores</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reduced-dimensionality-impact-on-a-2-feature-relationship">Reduced Dimensionality Impact on a 2 Feature Relationship</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reduced-dimensionality-impact-on-matrix-scatter-plots-of-all-features">Reduced Dimensionality Impact on Matrix Scatter Plots of All Features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#principal-components-analysis-on-uncorrelated-data">Principal Components Analysis on Uncorrelated Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comments">Comments</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#about-the-author">About the Author</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#want-to-work-together">Want to Work Together?</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <figure style="text-align: center;">
  <img src="_static/intro/title_page.png" style="display: block; margin: 0 auto; width: 100%;">
</figure>
<section id="principal-component-analysis">
<h1>Principal Component Analysis<a class="headerlink" href="#principal-component-analysis" title="Permalink to this heading">#</a></h1>
<p>Michael J. Pyrcz, Professor, The University of Texas at Austin</p>
<p><a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></p>
<p>Chapter of e-book “Applied Machine Learning in Python: a Hands-on Guide with Code”.</p>
<div class="remove-from-content-only admonition">
<p class="admonition-title">Cite this e-Book as:</p>
<p>Pyrcz, M.J., 2024, <em>Applied Machine Learning in Python: A Hands-on Guide with Code</em> [e-book]. Zenodo. doi:10.5281/zenodo.15169138 <a class="reference external" href="https://doi.org/10.5281/zenodo.15169138"><img alt="DOI" src="https://zenodo.org/badge/863274676.svg" /></a></p>
</div>
<p>The workflows in this book and more are available here:</p>
<div class="remove-from-content-only admonition">
<p class="admonition-title">Cite the MachineLearningDemos GitHub Repository as:</p>
<p>Pyrcz, M.J., 2024, <em>MachineLearningDemos: Python Machine Learning Demonstration Workflows Repository</em> (0.0.3) [Software]. Zenodo. DOI: 10.5281/zenodo.13835312. GitHub repository: <a class="github reference external" href="https://github.com/GeostatsGuy/MachineLearningDemos">GeostatsGuy/MachineLearningDemos</a> <a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.13835312"><img alt="DOI" src="https://zenodo.org/badge/862519860.svg" /></a></p>
</div>
<p>By Michael J. Pyrcz <br />
© Copyright 2024.</p>
<p>This chapter is a tutorial for / demonstration of <strong>Principal Component Analysis</strong>.</p>
<p><strong>YouTube Lecture</strong>: check out my lectures on:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://youtu.be/zOUM_AnI1DQ?si=wzWdJ35qJ9n8O6Bl">Introduction to Machine Learning</a></p></li>
<li><p><a class="reference external" href="https://youtu.be/-to3JXiae9Y?si=W1j2CwR9t0t8hxIB">Curse of Dimensionality, Dimensionality Reduction, Principal Component Analysis</a></p></li>
<li><p><a class="reference external" href="https://youtu.be/Yt0o8ukIOKU?si=_ri1NPwKVdhYzgO3">Multidimensional Scaling and Random Projection</a></p></li>
</ul>
<p>These lectures are all part of my <a class="reference external" href="https://youtube.com/playlist?list=PLG19vXLQHvSC2ZKFIkgVpI9fCjkN38kwf&amp;si=XonjO2wHdXffMpeI">Machine Learning Course</a> on YouTube with linked well-documented Python workflows and interactive dashboards. My goal is to share accessible, actionable, and repeatable educational content. If you want to know about my motivation, check out <a class="reference external" href="https://michaelpyrcz.com/my-story">Michael’s Story</a>.</p>
<section id="motivation-for-principal-component-analysis">
<h2>Motivation for Principal Component Analysis<a class="headerlink" href="#motivation-for-principal-component-analysis" title="Permalink to this heading">#</a></h2>
<p>Working with more features / variables is harder!</p>
<ol class="arabic simple">
<li><p>More difficult to visualize data and model</p></li>
<li><p>More data are required to infer the joint probabilities</p></li>
<li><p>Less data coverage of feature space</p></li>
<li><p>More difficult to interrogate / check the model</p></li>
<li><p>More likely redundant features, e.g., multicollinearity, resulting in model instability</p></li>
<li><p>More computational effort, more computational resources and longer run times</p></li>
<li><p>More complicated model is more likely overfit</p></li>
<li><p>More professional time for model construction</p></li>
</ol>
<p>We get a better model with fewer, informative features than throwing all our features into the model! A big part of this motivation is driven by the curse of dimensionality.</p>
</section>
<section id="curse-of-dimensionality">
<h2>Curse of Dimensionality<a class="headerlink" href="#curse-of-dimensionality" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Data and Model Visualization</strong> - we cannot visualize beyond 3D, i.e., access the model fit to data, evaluate interpolation vs. extrapolation.</p></li>
</ol>
<ul class="simple">
<li><p>consider a 5D example shown as a matrix scatter plot, even in this case there is an extreme marginalization to 2D for each plot,</p></li>
</ul>
<figure style="text-align: center;">
  <img src="_static\feature_ranking\matrix_scatterplot.png" style="display: block; margin: 0 auto; width: 100%;">
  <figcaption style="text-align: center;">Example 5D data as a matrix scatter plot.</figcaption>
</figure>
<ol class="arabic simple" start="2">
<li><p><strong>Sampling</strong> - the number of samples sufficient to infer statistics like the joint probability, <span class="math notranslate nohighlight">\(P(x_1,\ldots,x_m)\)</span>.</p></li>
</ol>
<ul class="simple">
<li><p>recall the calculation of a histogram or normalized histogram: we establish bins and calculate frequencies or probabilities in each bin.</p></li>
<li><p>we require a nominal number of data samples for each bin, so we require <span class="math notranslate nohighlight">\(𝑛=𝑛_{𝑠/𝑏𝑖𝑛} \cdot 𝑛_{𝑏𝑖𝑛𝑠}\)</span> samples in 1D</p></li>
<li><p>but in mD we required <span class="math notranslate nohighlight">\(n\)</span> samples to calculate the discretized joint probability,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
𝑛=𝑛_{𝑠/𝑏𝑖𝑛} \cdot 𝑛_{𝑏𝑖𝑛𝑠}^m$
\]</div>
<ul class="simple">
<li><p>for example, 10 samples per bin with 35 bins requires 12,250 samples in 2D, and 428,750 samples in 3D</p></li>
</ul>
<figure style="text-align: center;">
  <img src="_static/feature_ranking/bivariate_example.png" style="display: block; margin: 0 auto; width: 70%;">
  <figcaption style="text-align: center;">Example 2D data with 35 bins for each feature.</figcaption>
</figure>
<ol class="arabic simple" start="3">
<li><p><strong>Sample Coverage</strong> - the range of the sample values cover the predictor feature space.</p></li>
</ol>
<ul class="simple">
<li><p>fraction of the possible solution space that is sampled, for 1 feature we assume 80% coverage</p></li>
<li><p>remember, we usually, directly sample only <span class="math notranslate nohighlight">\(\frac{1}{10^7}\)</span> of the volume of the subsurface</p></li>
<li><p>yes, the concept of coverage is subjective, how much data to cover? What about gaps? etc.</p></li>
</ul>
<figure style="text-align: center;">
  <img src="_static/feature_ranking/coverage1D.png" style="display: block; margin: 0 auto; width: 80%;">
  <figcaption style="text-align: center;">Example 2D data with 35 bins for each feature.</figcaption>
</figure>
<ul class="simple">
<li><p>now if there is 80% coverage for 2 features the 2D coverage is 64%</p></li>
</ul>
<figure style="text-align: center;">
  <img src="_static/feature_ranking/coverage2D.png" style="display: block; margin: 0 auto; width: 80%;">
  <figcaption style="text-align: center;">Example 2D data with 35 bins for each feature.</figcaption>
</figure>
<ul class="simple">
<li><p>coverage is,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
c =  c_1^m
\]</div>
<ol class="arabic simple" start="4">
<li><p><strong>Distorted Space</strong> - high dimensional space is distorted.</p></li>
</ol>
<ul class="simple">
<li><p>take the ratio of the volume of an inscribed hypersphere in a hypercube,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\frac{\pi^{\frac{m}{2}}}{m 2^{m-1} \Gamma\left(\frac{m}{2}\right)} \to 0 \quad \text{as} \quad m \to \infty
\]</div>
<ul class="simple">
<li><p>recall, <span class="math notranslate nohighlight">\(\Gamma(𝑛)=(𝑛−1)!\)</span>.</p></li>
<li><p>high dimensional space is all corners and no middle and most of high dimensional space is far from the middle (all corners!).</p></li>
<li><p>as a result distances in high dimensional space lose sensitivity, i.e., for any random points in the space the expected pairwise distances all become the same,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\lim_{m \to \infty} \left( \mathbb{E}\left[\text{dist}_{\text{max}}(m) - \text{dist}_{\text{min}}(m)\right] \right) \to 0
\]</div>
<ul class="simple">
<li><p>the limit of the expectation of the range of pairwise distances over random points in hyper-dimensional space tends to zero. If distances are almost all the same, Euclidian distance is no longer meaningful!</p></li>
</ul>
<figure style="text-align: center;">
  <img src="_static/feature_ranking/distortion_chart.png" style="display: block; margin: 0 auto; width: 60%;">
  <figcaption style="text-align: center;">The ratio of the volume of a hypersphere within a hypercube.</figcaption>
</figure>
<ul class="simple">
<li><p>here’s the severity of the distortion for various dimensionalities,</p></li>
</ul>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>m</p></th>
<th class="head"><p>nD / 2D</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>2</p></td>
<td><p>1.0</p></td>
</tr>
<tr class="row-odd"><td><p>5</p></td>
<td><p>0.28</p></td>
</tr>
<tr class="row-even"><td><p>10</p></td>
<td><p>0.003</p></td>
</tr>
<tr class="row-odd"><td><p>20</p></td>
<td><p>0.00000003</p></td>
</tr>
</tbody>
</table>
<ol class="arabic simple" start="5">
<li><p><strong>Multicollinearity</strong> - higher dimensional datasets are more likely to have collinearity or multicollinearity.</p></li>
</ol>
<ul class="simple">
<li><p>Feature linearly described by other features resulting in high model variance.</p></li>
</ul>
</section>
<section id="inferential-machine-learning">
<h2>Inferential Machine Learning<a class="headerlink" href="#inferential-machine-learning" title="Permalink to this heading">#</a></h2>
<p>Princpal conponent analysis is an inferential, unsupervised machine learnng method.</p>
<ul class="simple">
<li><p>there are no response features, <span class="math notranslate nohighlight">\(y\)</span>, just predictor features,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
𝑋_1,\ldots,𝑋_𝑚
\]</div>
<ul class="simple">
<li><p>Machine learns by mimicry a compact representation of the data</p></li>
<li><p>Captures patterns as feature projections, group assignments, neural network latent features, etc.</p></li>
<li><p>We focus on inference of the population, the natural system, instead of prediction of response features.</p></li>
</ul>
</section>
<section id="id1">
<h2>Principal Component Analysis<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<p>Principal Component Analysis one of a variety of methods for dimensional reduction:</p>
<p>Dimensional reduction transforms the data to a lower dimension</p>
<ul class="simple">
<li><p>Given features, <span class="math notranslate nohighlight">\(𝑋_1,\dots,𝑋_𝑚\)</span> we would require <span class="math notranslate nohighlight">\({m \choose 2}=\frac{𝑚 \cdot (𝑚−1)}{2}\)</span> scatter plots to visualize just the two-dimensional scatter plots.</p></li>
<li><p>Once we have 4 or more variables understanding our data gets very hard.</p></li>
<li><p>Recall the curse of dimensionality, impact inference, modeling and visualization.</p></li>
</ul>
<p>One solution, is to find a good lower dimensional, <span class="math notranslate nohighlight">\(𝑝\)</span>,  representation of the original dimensions <span class="math notranslate nohighlight">\(𝑚\)</span></p>
<p>Benefits of Working in a Reduced Dimensional Representation:</p>
<ol class="arabic simple">
<li><p>Data storage / Computational Time</p></li>
<li><p>Easier visualization</p></li>
<li><p>Also takes care of multicollinearity</p></li>
</ol>
</section>
<section id="orthogonal-transformation">
<h2>Orthogonal Transformation<a class="headerlink" href="#orthogonal-transformation" title="Permalink to this heading">#</a></h2>
<p>Convert a set of observations into a set of linearly uncorrelated variables known as principal components</p>
<ul class="simple">
<li><p>The number of principal components (<span class="math notranslate nohighlight">\(k\)</span>) available are min⁡(<span class="math notranslate nohighlight">\(𝑛−1,𝑚\)</span>)</p></li>
<li><p>Limited by the variables/features, <span class="math notranslate nohighlight">\(𝑚\)</span>, and the number of data</p></li>
</ul>
<p>Components are ordered,</p>
<ul class="simple">
<li><p>First component describes the larges possible variance / accounts for as much variability as possible</p></li>
<li><p>Next component describes the largest possible remaining variance</p></li>
<li><p>Up to the maximum number of principal components</p></li>
</ul>
<p>There are mutliple ways to interpret principal components analysis,</p>
</section>
<section id="best-fitting-interpretation">
<h2>Best Fitting Interpretation<a class="headerlink" href="#best-fitting-interpretation" title="Permalink to this heading">#</a></h2>
<p>Minimizes the orthogonal projection error between the data and the principal components,</p>
<div class="math notranslate nohighlight">
\[ 
\min \sum_{i=1}^{n} \left( \left( X_i - \bar{X} \right) - \left( X_i - \bar{X} \right) V_p V_p^T \right)^2 
\]</div>
<p>where <span class="math notranslate nohighlight">\(𝑽_𝒑\)</span> is a matrix of our first <span class="math notranslate nohighlight">\(𝒑\)</span> vectors, and <span class="math notranslate nohighlight">\(𝑿_𝒊\)</span> is a vector for sample <span class="math notranslate nohighlight">\(𝑖\)</span> over all <span class="math notranslate nohighlight">\(𝑝\)</span> features and <span class="math notranslate nohighlight">\(\overline{X}\)</span> is a vector of the means,</p>
<figure style="text-align: center;">
  <img src="_static/PCA/error.png" style="display: block; margin: 0 auto; width: 70%;">
  <figcaption style="text-align: center;"> Orthogonal error when projecting 2D data to 1D (left) and 3D data to 2D (right)(citation to be added).
</figcaption>
</figure>
<p>where the princpal components describe a vector in 1D and a plane in 2D, and where the principal component scores in the projected space are,</p>
<div class="math notranslate nohighlight">
\[
(𝑿_𝒊−\overline{𝑿})𝑽_𝒑
\]</div>
<p>and the back transformation in the original space with reduced dimensionality is,</p>
<div class="math notranslate nohighlight">
\[
(𝑿_𝒊−\overline{X})𝑽_𝒑 𝑽_𝒑^𝑻
\]</div>
<p>note, given the <span class="math notranslate nohighlight">\(V_p\)</span> matrix is orthogonal,</p>
<div class="math notranslate nohighlight">
\[
V_p^T = V_p^{-1}
\]</div>
</section>
<section id="rotation-based-intepretation">
<h2>Rotation-based Intepretation<a class="headerlink" href="#rotation-based-intepretation" title="Permalink to this heading">#</a></h2>
<p>Orthogonal transformation is a rotation that maximizes the variance explained on the first principal component, maximizes the remaining variance on the second principal component, etc.</p>
<p>If you would like to see PCA as a rotation in action, check out my <a class="reference external" href="https://github.com/GeostatsGuy/DataScienceInteractivePython/blob/main/Interactive_PCA_Rotation.ipynb">PCA Rotation interactive Python dashboard</a>,</p>
<figure style="text-align: center;">
  <img src="_static/PCA/rotation.png" style="display: block; margin: 0 auto; width: 100%;">
  <figcaption style="text-align: center;"> My interactive dashboard demonstrating PCA as rotation of the data.
</figcaption>
</figure>
<p>from this dashboard it is clear that there is a rotation that maixmizes the variance explained by the first principal component while removing the correlation between the first and second principal component.</p>
</section>
<section id="eigenvalues-eigenvectors-interpretation">
<h2>Eigenvalues / Eigenvectors Interpretation<a class="headerlink" href="#eigenvalues-eigenvectors-interpretation" title="Permalink to this heading">#</a></h2>
<p>For principal components analysis we calculate the data covariance matrix, the pairwise covariance for the combinatorial of features.</p>
<ul class="simple">
<li><p>The we calculate the eigenvectors and eigenvalues from the covariance matrix.</p></li>
<li><p>The eigenvalues are the variance explained for each component.</p></li>
<li><p>The eigenvectors of the data covariance matrix are the principal components.</p></li>
</ul>
</section>
<section id="the-principal-components-analysis-workflow">
<h2>The Principal Components Analysis Workflow<a class="headerlink" href="#the-principal-components-analysis-workflow" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Standardize the Features</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
𝑋^𝑠=\frac{𝑋−\overline{X}}{\sigma_𝑋} 
\]</div>
<div class="math notranslate nohighlight">
\[
𝑋_1,\ldots,𝑋_𝑚 \quad \rightarrow 𝑋_1^𝑠,\ldots,𝑋_𝑚^𝑠
\]</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>where $X_i$ are original features and $X^s_i$ are transformed features.
</pre></div>
</div>
<ul class="simple">
<li><p>standardization is required to prevent features with larger variance dominating the solution, i.e., first principal component aligned with feature with greatest variance</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Calculate the standardized feature covariance matrix</p></li>
</ol>
<div class="math notranslate nohighlight">
\[ 
C_{(X_{m_1}, X_{m_2})} = \frac{\sum_{i=1}^{n} \left( (x_{m_1} - \bar{x}_{m_1})(x_{m_2} - \bar{x}_{m_2}) \right)}{n - 1} 
\]</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>given the features are standardized the matrix is a correlation matrix
</pre></div>
</div>
<div class="math notranslate nohighlight">
\[\begin{split} 
C = \begin{bmatrix}
C(X_1, X_1) &amp; \cdots &amp; C(X_1, X_m) \\
\vdots &amp; \ddots &amp; \vdots \\
C(X_m, X_1) &amp; \cdots &amp; C(X_m, X_m)
\end{bmatrix} 
\end{split}\]</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>given the features are standardized the matrix is a correlation matrix,
</pre></div>
</div>
<div class="math notranslate nohighlight">
\[\begin{split} 
C = \begin{bmatrix}
\rho(X_1, X_1) &amp; \cdots &amp; \rho(X_1, X_m) \\
\vdots &amp; \ddots &amp; \vdots \\
\rho(X_m, X_1) &amp; \cdots &amp; \rho(X_m, X_m)
\end{bmatrix} 
\end{split}\]</div>
<ol class="arabic" start="3">
<li><p>Calculate the eigenvalues and eigenvectors of covariance matrix, <span class="math notranslate nohighlight">\(𝑪\)</span>,</p>
<p>given 𝐶 is a square matrix <span class="math notranslate nohighlight">\((𝑚 \times 𝑚)\)</span>, <span class="math notranslate nohighlight">\(𝑣 (𝑚 \times 1)\)</span> is a vector and <span class="math notranslate nohighlight">\(\lambda\)</span> is a scaler (<span class="math notranslate nohighlight">\(1\)</span>),</p>
</li>
</ol>
<div class="math notranslate nohighlight">
\[
𝐶𝑣=\lambda 𝑣
\]</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>we can reorder to,
</pre></div>
</div>
<div class="math notranslate nohighlight">
\[
(𝐶− \lambda \cdot 𝐼)∙𝑣=0
\]</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>where $I$ is an identity matrix. By Cramer’s rule, we have a solution if the determinant is 0,
</pre></div>
</div>
<div class="math notranslate nohighlight">
\[
|𝐶− \lambda \cdot 𝐼|=0
\]</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>find the possible Eigenvalues, $\lambda_𝛼$, and solve for eigenvectors, $𝒗_𝜶, \quad \alpha=𝟏,\ldots,𝒎$
</pre></div>
</div>
<ul class="simple">
<li><p>the resulting <span class="math notranslate nohighlight">\(\text{𝒎𝒊𝒏}⁡(𝒎,𝒏−𝟏)\)</span> eigenvectors in a matrix, <span class="math notranslate nohighlight">\(𝑽_𝒎\)</span></p></li>
</ul>
<figure style="text-align: center;">
  <img src="_static/PCA/components.png" style="display: block; margin: 0 auto; width: 70%;">
  <figcaption style="text-align: center;"> Eigen vectors as principal components.
</figcaption>
</figure>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>that form a basis on which the data are projected for dimensionality reduction,
</pre></div>
</div>
<figure style="text-align: center;">
  <img src="_static/PCA/components_basis.png" style="display: block; margin: 0 auto; width: 100%;">
  <figcaption style="text-align: center;"> Eigen vectors as principal components defining the new rotated basis.
</figcaption>
</figure>
<p>If you would like to see the principal components loadings and the variance partitioning between components, check out my <a class="reference external" href="https://github.com/GeostatsGuy/DataScienceInteractivePython/blob/main/Interactive_PCA_Eigen.ipynb">PCA loadings interactive Python dashboard</a>,</p>
<figure style="text-align: center;">
  <img src="_static/PCA/interactive_loadings.png" style="display: block; margin: 0 auto; width: 100%;">
  <figcaption style="text-align: center;"> My interactive dashboard demonstrating PCA loadings and variance explained for eacch principal component as correlation is changes between features 1, 2 and 3.
</figcaption>
</figure>
</section>
<section id="load-the-required-libraries">
<h2>Load the Required Libraries<a class="headerlink" href="#load-the-required-libraries" title="Permalink to this heading">#</a></h2>
<p>The following code loads the required libraries. These should have been installed with Anaconda 3.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ignore_warnings</span> <span class="o">=</span> <span class="kc">True</span>                                        <span class="c1"># ignore warnings?</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>                         <span class="c1"># PCA program from scikit learn (package for machine learning)</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>              <span class="c1"># standardize variables to mean of 0.0 and variance of 1.0</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>                                            <span class="c1"># ndarrays for gridded data</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>                                           <span class="c1"># DataFrames for tabular data</span>
<span class="kn">import</span> <span class="nn">pandas.plotting</span> <span class="k">as</span> <span class="nn">pd_plot</span>                             <span class="c1"># pandas plotting functions</span>
<span class="kn">import</span> <span class="nn">copy</span>                                                   <span class="c1"># for deep copies</span>
<span class="kn">import</span> <span class="nn">os</span>                                                     <span class="c1"># set working directory, run executables</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>                               <span class="c1"># for plotting</span>
<span class="kn">from</span> <span class="nn">matplotlib.ticker</span> <span class="kn">import</span> <span class="p">(</span><span class="n">MultipleLocator</span><span class="p">,</span> <span class="n">AutoMinorLocator</span><span class="p">)</span> <span class="c1"># control of axes ticks</span>
<span class="kn">import</span> <span class="nn">matplotlib.ticker</span> <span class="k">as</span> <span class="nn">mtick</span>                             <span class="c1"># control tick label formatting</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>                                         <span class="c1"># advanced plotting</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;axes&#39;</span><span class="p">,</span> <span class="n">axisbelow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                                <span class="c1"># plot all grids below the plot elements</span>
<span class="k">if</span> <span class="n">ignore_warnings</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>                                   
    <span class="kn">import</span> <span class="nn">warnings</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span>                                         <span class="c1"># color map</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span>                                                     <span class="c1"># random number seed</span>
</pre></div>
</div>
</div>
</div>
<p>If you get a package import error, you may have to first install some of these packages. This can usually be accomplished by opening up a command window on Windows and then typing ‘python -m pip install [package-name]’. More assistance is available with the respective package docs.</p>
</section>
<section id="declare-functions">
<h2>Declare Functions<a class="headerlink" href="#declare-functions" title="Permalink to this heading">#</a></h2>
<p>Let’s define a single function to streamline plotting correlation matrices. I also added a convenience function to add major and minor gridlines to improve plot interpretability.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_corr</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>                                    <span class="c1"># plots a graphical correlation matrix </span>
    <span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>              <span class="c1"># make a custom colormap</span>
    <span class="n">my_colormap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">&#39;RdBu_r&#39;</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>          
    <span class="n">newcolors</span> <span class="o">=</span> <span class="n">my_colormap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>
    <span class="n">white</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">newcolors</span><span class="p">[</span><span class="mi">65</span><span class="p">:</span><span class="mi">191</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">white</span>                              <span class="c1"># mask all correlations less than abs(0.8)</span>
    <span class="n">newcmp</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">(</span><span class="n">newcolors</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">corr</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">))</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">corr</span><span class="p">,</span><span class="n">vmin</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span><span class="n">cmap</span> <span class="o">=</span> <span class="n">newcmp</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr</span><span class="o">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">corr</span><span class="o">.</span><span class="n">columns</span><span class="p">);</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr</span><span class="o">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">corr</span><span class="o">.</span><span class="n">columns</span><span class="p">);</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">&#39;vertical&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Correlation Matrix&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">m</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],[</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">add_grid</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="c1"># add y grids</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="mi">7</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">());</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">())</span> <span class="c1"># turn on minor ticks </span>

<span class="k">def</span> <span class="nf">add_grid2</span><span class="p">(</span><span class="n">sub_plot</span><span class="p">):</span>
    <span class="n">sub_plot</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">);</span> <span class="n">sub_plot</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="c1"># add y grids</span>
    <span class="n">sub_plot</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="mi">7</span><span class="p">);</span> <span class="n">sub_plot</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">sub_plot</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">());</span> <span class="n">sub_plot</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">())</span> <span class="c1"># turn on minor ticks   </span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="set-the-working-directory">
<h2>Set the Working Directory<a class="headerlink" href="#set-the-working-directory" title="Permalink to this heading">#</a></h2>
<p>I always like to do this so I don’t lose files and to simplify subsequent read and writes (avoid including the full address each time).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#os.chdir(&quot;c:/PGE383&quot;)                                 # set the working directory</span>
</pre></div>
</div>
</div>
</div>
<p>You will have to update the part in quotes with your own working directory and the format is different on a Mac (e.g. “~/PGE”).</p>
</section>
<section id="loading-tabular-data">
<h2>Loading Tabular Data<a class="headerlink" href="#loading-tabular-data" title="Permalink to this heading">#</a></h2>
<p>Here’s the command to load our comma delimited data file in to a Pandas’ DataFrame object.</p>
<p>Let’s load the provided multivariate, spatial dataset ‘unconv_MV.csv’. This dataset has variables from 1,000 unconventional wells including:</p>
<ul class="simple">
<li><p>well average porosity</p></li>
<li><p>log transform of permeability (to linearize the relationships with other variables)</p></li>
<li><p>acoustic impedance (kg/m^3 x m/s x 10^6)</p></li>
<li><p>brittleness ratio (%)</p></li>
<li><p>total organic carbon (%)</p></li>
<li><p>vitrinite reflectance (%)</p></li>
<li><p>initial production 90 day average (MCFPD).</p></li>
</ul>
<p>Note, the dataset is synthetic.</p>
<p>We load it with the pandas ‘read_csv’ function into a DataFrame we called ‘my_data’ and then preview it to make sure it loaded correctly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#my_data = pd.read_csv(&quot;unconv_MV.csv&quot;)  </span>
<span class="n">my_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV.csv&quot;</span><span class="p">)</span> <span class="c1"># load the comma delimited data file</span>
<span class="n">my_data</span> <span class="o">=</span> <span class="n">my_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span>                              <span class="c1"># remove the well index</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualize-the-dataframe">
<h2>Visualize the DataFrame<a class="headerlink" href="#visualize-the-dataframe" title="Permalink to this heading">#</a></h2>
<p>Visualizing the DataFrame is a useful first check.</p>
<p>We can preview by slicing the DataFrame.</p>
<ul class="simple">
<li><p>we are showing all records from 0 up to and not including 7</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">my_data</span><span class="p">[:</span><span class="mi">7</span><span class="p">]</span>                                               <span class="c1"># preview the first 7 rows of the dataframe</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Por</th>
      <th>LogPerm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
      <th>Production</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>15.91</td>
      <td>1.67</td>
      <td>3.06</td>
      <td>14.05</td>
      <td>1.36</td>
      <td>1.85</td>
      <td>177.381958</td>
    </tr>
    <tr>
      <th>1</th>
      <td>15.34</td>
      <td>1.65</td>
      <td>2.60</td>
      <td>31.88</td>
      <td>1.37</td>
      <td>1.79</td>
      <td>1479.767778</td>
    </tr>
    <tr>
      <th>2</th>
      <td>20.45</td>
      <td>2.02</td>
      <td>3.13</td>
      <td>63.67</td>
      <td>1.79</td>
      <td>2.53</td>
      <td>4421.221583</td>
    </tr>
    <tr>
      <th>3</th>
      <td>11.95</td>
      <td>1.14</td>
      <td>3.90</td>
      <td>58.81</td>
      <td>0.40</td>
      <td>2.03</td>
      <td>1488.317629</td>
    </tr>
    <tr>
      <th>4</th>
      <td>19.53</td>
      <td>1.83</td>
      <td>2.57</td>
      <td>43.75</td>
      <td>1.40</td>
      <td>2.11</td>
      <td>5261.094919</td>
    </tr>
    <tr>
      <th>5</th>
      <td>19.47</td>
      <td>2.04</td>
      <td>2.73</td>
      <td>54.37</td>
      <td>1.42</td>
      <td>2.12</td>
      <td>5497.005506</td>
    </tr>
    <tr>
      <th>6</th>
      <td>12.70</td>
      <td>1.30</td>
      <td>3.70</td>
      <td>43.03</td>
      <td>0.45</td>
      <td>1.95</td>
      <td>1784.266285</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="summary-statistics-for-tabular-data">
<h2>Summary Statistics for Tabular Data<a class="headerlink" href="#summary-statistics-for-tabular-data" title="Permalink to this heading">#</a></h2>
<p>There are a lot of efficient methods to calculate summary statistics from tabular data in DataFrames. The describe command provides count, mean, minimum, maximum, and quartiles all in a nice data table.</p>
<ul class="simple">
<li><p>We use transpose just to flip the table so that features are on the rows and the statistics are on the columns.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">my_data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>                            <span class="c1"># calculate summary statistics for the data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Por</th>
      <td>1000.0</td>
      <td>14.950460</td>
      <td>3.029634</td>
      <td>5.400000</td>
      <td>12.85750</td>
      <td>14.98500</td>
      <td>17.080000</td>
      <td>24.65000</td>
    </tr>
    <tr>
      <th>LogPerm</th>
      <td>1000.0</td>
      <td>1.398880</td>
      <td>0.405966</td>
      <td>0.120000</td>
      <td>1.13000</td>
      <td>1.39000</td>
      <td>1.680000</td>
      <td>2.58000</td>
    </tr>
    <tr>
      <th>AI</th>
      <td>1000.0</td>
      <td>2.982610</td>
      <td>0.577629</td>
      <td>0.960000</td>
      <td>2.57750</td>
      <td>3.01000</td>
      <td>3.360000</td>
      <td>4.70000</td>
    </tr>
    <tr>
      <th>Brittle</th>
      <td>1000.0</td>
      <td>49.719480</td>
      <td>15.077006</td>
      <td>-10.500000</td>
      <td>39.72250</td>
      <td>49.68000</td>
      <td>59.170000</td>
      <td>93.47000</td>
    </tr>
    <tr>
      <th>TOC</th>
      <td>1000.0</td>
      <td>1.003810</td>
      <td>0.504978</td>
      <td>-0.260000</td>
      <td>0.64000</td>
      <td>0.99500</td>
      <td>1.360000</td>
      <td>2.71000</td>
    </tr>
    <tr>
      <th>VR</th>
      <td>1000.0</td>
      <td>1.991170</td>
      <td>0.308194</td>
      <td>0.900000</td>
      <td>1.81000</td>
      <td>2.00000</td>
      <td>2.172500</td>
      <td>2.90000</td>
    </tr>
    <tr>
      <th>Production</th>
      <td>1000.0</td>
      <td>2247.295809</td>
      <td>1464.256312</td>
      <td>2.713535</td>
      <td>1191.36956</td>
      <td>1976.48782</td>
      <td>3023.594214</td>
      <td>12568.64413</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Good that we checked the summary statistics, we have some negative values for brittleness and total organic carbon. This is physically impossible.</p>
<ul class="simple">
<li><p>The values must be in error. We know the lowest possible values are 0.0, so we will truncate on 0.0.</p></li>
</ul>
<p>We use the:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">get_numerical_data</span><span class="p">()</span>
</pre></div>
</div>
<p>DataFrame member function to get a shallow copy of the data from the DataFrame.</p>
<p>Since it is a shallow copy, any changes we make to the copy are made to the data in the original DataFrame.</p>
<ul class="simple">
<li><p>This allows us to apply this simple conditional statement to all the data values in the DataFrame all at once.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num</span> <span class="o">=</span> <span class="n">my_data</span><span class="o">.</span><span class="n">_get_numeric_data</span><span class="p">()</span>                         <span class="c1"># get the numerical values</span>
<span class="n">num</span><span class="p">[</span><span class="n">num</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>                                          <span class="c1"># truncate negative values to 0.0</span>
<span class="n">my_data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>                            <span class="c1"># calculate summary statistics for the data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Por</th>
      <td>1000.0</td>
      <td>14.950460</td>
      <td>3.029634</td>
      <td>5.400000</td>
      <td>12.85750</td>
      <td>14.98500</td>
      <td>17.080000</td>
      <td>24.65000</td>
    </tr>
    <tr>
      <th>LogPerm</th>
      <td>1000.0</td>
      <td>1.398880</td>
      <td>0.405966</td>
      <td>0.120000</td>
      <td>1.13000</td>
      <td>1.39000</td>
      <td>1.680000</td>
      <td>2.58000</td>
    </tr>
    <tr>
      <th>AI</th>
      <td>1000.0</td>
      <td>2.982610</td>
      <td>0.577629</td>
      <td>0.960000</td>
      <td>2.57750</td>
      <td>3.01000</td>
      <td>3.360000</td>
      <td>4.70000</td>
    </tr>
    <tr>
      <th>Brittle</th>
      <td>1000.0</td>
      <td>49.731480</td>
      <td>15.033593</td>
      <td>0.000000</td>
      <td>39.72250</td>
      <td>49.68000</td>
      <td>59.170000</td>
      <td>93.47000</td>
    </tr>
    <tr>
      <th>TOC</th>
      <td>1000.0</td>
      <td>1.006170</td>
      <td>0.499838</td>
      <td>0.000000</td>
      <td>0.64000</td>
      <td>0.99500</td>
      <td>1.360000</td>
      <td>2.71000</td>
    </tr>
    <tr>
      <th>VR</th>
      <td>1000.0</td>
      <td>1.991170</td>
      <td>0.308194</td>
      <td>0.900000</td>
      <td>1.81000</td>
      <td>2.00000</td>
      <td>2.172500</td>
      <td>2.90000</td>
    </tr>
    <tr>
      <th>Production</th>
      <td>1000.0</td>
      <td>2247.295809</td>
      <td>1464.256312</td>
      <td>2.713535</td>
      <td>1191.36956</td>
      <td>1976.48782</td>
      <td>3023.594214</td>
      <td>12568.64413</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="calculate-the-correlation-matrix">
<h2>Calculate the Correlation Matrix<a class="headerlink" href="#calculate-the-correlation-matrix" title="Permalink to this heading">#</a></h2>
<p>For dimensional reduction, a good first step is data visualization.</p>
<p>Let’s start with the correlation matrix.</p>
<p>We can calculate it and view it in the console with these commands.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">my_data</span><span class="p">,</span> <span class="n">rowvar</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>the input data is a 2D ndarray and <span class="math notranslate nohighlight">\(rowvar\)</span> specifies if the variables are in the rows instead of columns.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">my_data</span><span class="p">,</span> <span class="n">rowvar</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">around</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>                           <span class="c1"># print the correlation matrix to 2 decimals</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 1.    0.81 -0.51 -0.25  0.71  0.08  0.69]
 [ 0.81  1.   -0.32 -0.15  0.51  0.05  0.57]
 [-0.51 -0.32  1.    0.17 -0.55  0.49 -0.33]
 [-0.25 -0.15  0.17  1.   -0.24  0.3  -0.07]
 [ 0.71  0.51 -0.55 -0.24  1.    0.31  0.5 ]
 [ 0.08  0.05  0.49  0.3   0.31  1.    0.14]
 [ 0.69  0.57 -0.33 -0.07  0.5   0.14  1.  ]]
</pre></div>
</div>
</div>
</div>
<p>Note the 1.0 diagonal resulting from the correlation of each variable with themselves.</p>
<p>Let’s use our function declared above to make a graphical correlation matrix visualization.</p>
<ul class="simple">
<li><p>This may improve our ability to spot features. It relies on the built in correlation matrix method with Numpy DataFrames and MatPlotLib for plotting.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_corr</span><span class="p">(</span><span class="n">my_data</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span>                                      <span class="c1"># using our correlation matrix visualization function</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/779b947412ca0f360bb3a9f517fdd22d7c6ad98015e0cf1a6bd4a8f8fb0162da.png" src="_images/779b947412ca0f360bb3a9f517fdd22d7c6ad98015e0cf1a6bd4a8f8fb0162da.png" />
</div>
</div>
<p>This looks good. There is a mix of bivariate, linear correlation magnitudes. Of course, correlation coefficients are limited to degree of linear correlations.</p>
</section>
<section id="check-matrix-scatter-plots">
<h2>Check Matrix Scatter Plots<a class="headerlink" href="#check-matrix-scatter-plots" title="Permalink to this heading">#</a></h2>
<p>For more complete information, let’s look at the matrix scatter plot from the Pandas package.</p>
<ul class="simple">
<li><p>covariance and correlation are sensitive to outliers and nonlinearity</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pd_plot</span><span class="o">.</span><span class="n">scatter_matrix</span><span class="p">(</span><span class="n">my_data</span><span class="p">)</span>
</pre></div>
</div>
<p>the <span class="math notranslate nohighlight">\(alpha\)</span> allows us to use semitransparent points for easier visualization with dense scatter plots.</p>
<p>the <span class="math notranslate nohighlight">\(hist_kwds\)</span> is a set of parameters for the histograms on the diagonal elements.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd_plot</span><span class="o">.</span><span class="n">scatter_matrix</span><span class="p">(</span><span class="n">my_data</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>              <span class="c1"># pandas matrix scatter plot</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">hist_kwds</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;color&#39;</span><span class="p">:[</span><span class="s1">&#39;grey&#39;</span><span class="p">]})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ad5210bc0e50b9cd1f9e82e2101cd6a8e22b7b46827929b73884539038ea060c.png" src="_images/ad5210bc0e50b9cd1f9e82e2101cd6a8e22b7b46827929b73884539038ea060c.png" />
</div>
</div>
</section>
<section id="simple-bivariate-example">
<h2>Simple Bivariate Example<a class="headerlink" href="#simple-bivariate-example" title="Permalink to this heading">#</a></h2>
<p>Let’s simplify the problem to bivariate (2 features), porosity and the log transform of permeability and reduce the number of wells from 1,000 to 100.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">my_data_por_perm</span> <span class="o">=</span> <span class="n">my_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>                <span class="c1"># extract just por and logperm, 100 samples</span>
<span class="n">my_data_por_perm</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>                   <span class="c1"># calculate summary statistics for the data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Por</th>
      <td>100.0</td>
      <td>14.9856</td>
      <td>2.823016</td>
      <td>9.23</td>
      <td>12.9275</td>
      <td>14.720</td>
      <td>16.705</td>
      <td>21.00</td>
    </tr>
    <tr>
      <th>LogPerm</th>
      <td>100.0</td>
      <td>1.3947</td>
      <td>0.390947</td>
      <td>0.36</td>
      <td>1.1475</td>
      <td>1.365</td>
      <td>1.650</td>
      <td>2.48</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let’s first check the univariate statistics of Por and LogPerm.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">my_data_por_perm</span><span class="p">[</span><span class="s2">&quot;Por&quot;</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Porosity&#39;</span><span class="p">);</span> <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Porosity (%)&#39;</span><span class="p">);</span> <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">);</span> <span class="n">add_grid2</span><span class="p">(</span><span class="n">ax1</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">my_data_por_perm</span><span class="p">[</span><span class="s2">&quot;LogPerm&quot;</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Log Transformed Permeability&#39;</span><span class="p">);</span> <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Log[Permeability] (log(mD)&#39;</span><span class="p">);</span> <span class="n">add_grid2</span><span class="p">(</span><span class="n">ax2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/06c2be261b8ed9903e1e372588a28bcd52cf56d411cbd6376aa5fdec5bbda07e.png" src="_images/06c2be261b8ed9903e1e372588a28bcd52cf56d411cbd6376aa5fdec5bbda07e.png" />
</div>
</div>
<p>The distributions may actually be Gaussian distributed, regardless they are well behaved, we cannot observe obvious gaps nor truncations.</p>
<p>Let’s look at a scatter plot of porosity vs. log permeability.</p>
<p>This would be the basic command from <em>matplotlib</em> to make a scatter plot.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">my_data_por_perm</span><span class="p">[</span><span class="s2">&quot;Por&quot;</span><span class="p">],</span><span class="n">my_data_por_perm</span><span class="p">[</span><span class="s2">&quot;LogPerm&quot;</span><span class="p">]</span>
</pre></div>
</div>
<ul class="simple">
<li><p>the additional parameters are for formatting and labels</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">my_data_por_perm</span><span class="p">[</span><span class="s2">&quot;Por&quot;</span><span class="p">],</span><span class="n">my_data_por_perm</span><span class="p">[</span><span class="s2">&quot;LogPerm&quot;</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Log Transformed Permeability vs. Porosity&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Porosity (%)&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Log(Permeability (Log(mD))&#39;</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/6db1439ec376e70dfe82d70d9dfae50de99df77b9c2bbc25f29d89f082850b57.png" src="_images/6db1439ec376e70dfe82d70d9dfae50de99df77b9c2bbc25f29d89f082850b57.png" />
</div>
</div>
</section>
<section id="calculation-of-principal-components">
<h2>Calculation of Principal Components<a class="headerlink" href="#calculation-of-principal-components" title="Permalink to this heading">#</a></h2>
<p>With the log transform of permeability we have a very nice linear relationship with porosity, PCA should work well on this data.</p>
<ul class="simple">
<li><p>We are ready to perform PCA with porosity and log of permeability.</p></li>
</ul>
</section>
<section id="standardize-the-features">
<h2>Standardize the Features<a class="headerlink" href="#standardize-the-features" title="Permalink to this heading">#</a></h2>
<p>We must standardize our variables to have a mean equal to zero, <span class="math notranslate nohighlight">\(\bar{x} = 0.0\)</span>, and the variance equal to one, <span class="math notranslate nohighlight">\(\sigma^{2}_{x} = 1.0\)</span>.</p>
<ul class="simple">
<li><p>Otherwise the difference between the scale of porosity and permeability would have a significant impact. Note, given the impact of choice of units on variance, e.g., darcies (D) vs. millidarcies (mD) for permeability or fraction instead of a percentage for porosity. This is quite arbitrary!</p></li>
</ul>
<p>To remove this effect, we should always standardize unless the two variables have the same units and then the range, variance between them is meaningful and standardization could remove important information.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Por&#39;</span><span class="p">,</span><span class="s1">&#39;LogPerm&#39;</span><span class="p">]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">my_data_por_perm</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">features</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">sd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>                     <span class="c1"># standardize the data features to mean = 0, var = 1.0</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original Mean Por&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mu</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;, Original Mean LogPerm = &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mu</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="mi">2</span><span class="p">))</span> 
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original StDev Por&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">sd</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;, Original StDev LogPerm = &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">sd</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="mi">2</span><span class="p">))</span> 
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean Transformed Por =&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]),</span><span class="mi">2</span><span class="p">),</span><span class="s1">&#39;, Mean Transformed LogPerm =&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]),</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Variance Transformed Por =&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]),</span><span class="s1">&#39;, Variance Transformed LogPerm =&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Original Mean Por 14.99 , Original Mean LogPerm =  1.39
Original StDev Por 2.81 , Original StDev LogPerm =  0.39
Mean Transformed Por = 0.0 , Mean Transformed LogPerm = -0.0
Variance Transformed Por = 1.0000000000000002 , Variance Transformed LogPerm = 1.0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">rowvar</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">cov</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[1.01010101, 0.80087707],
       [0.80087707, 1.01010101]])
</pre></div>
</div>
</div>
</div>
<p>“x” is a 2D ndarray from Numpy package with the features in columns and the samples in rows.</p>
<ul class="simple">
<li><p>Above we confirm that the features in the “x” 2D array are standardized.</p></li>
</ul>
<p>It is not a bad idea to check the univariate and bivariate distributions of our standardized variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dfS</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;sPor&#39;</span><span class="p">:</span> <span class="n">x</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;sLogPerm&#39;</span><span class="p">:</span> <span class="n">x</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]})</span>
<span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">dfS</span><span class="p">,</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;sPor&#39;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s1">&#39;sLogPerm&#39;</span><span class="p">,</span><span class="n">marginal_kws</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">),</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/294c5353a5f381ec9771db8cfa867a24ca2c07c3089527accf291ed36b79524d.png" src="_images/294c5353a5f381ec9771db8cfa867a24ca2c07c3089527accf291ed36b79524d.png" />
</div>
</div>
<p>Everything looks fine and we are ready to apply principal components analysis.</p>
</section>
<section id="principal-component-analysis-pca">
<h2>Principal Component Analysis (PCA)<a class="headerlink" href="#principal-component-analysis-pca" title="Permalink to this heading">#</a></h2>
<p>To run PCA with the SciKitLearn machine learning package in Python, we first make a PCA model with a specified number of components and then we ‘fit’ it to our data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">n_components</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">)</span>
<span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>As you will see later with dimensional reduction, we can use matrix math with this model and reduce our data to any dimensionality from 1 to the number of features, m. Let’s run the model with number of components equal to number of features, m.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_components</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="component-loadings">
<h2>Component Loadings<a class="headerlink" href="#component-loadings" title="Permalink to this heading">#</a></h2>
<p>The first thing we should do is look at the component loadings. Let’s view them and interpret our result.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;First Principal Component = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span><span class="mi">3</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Second Principal Component = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="p">[</span><span class="mi">1</span><span class="p">,:],</span><span class="mi">3</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 0.707  0.707]
 [ 0.707 -0.707]]
First Principal Component = [0.707 0.707]
Second Principal Component = [ 0.707 -0.707]
</pre></div>
</div>
</div>
</div>
<p>The components are listed as a 2D array (ndarray) with:</p>
<ul class="simple">
<li><p>principal components on the rows</p></li>
<li><p>features on the columns</p></li>
<li><p>the rows are sorted so that the first principal component is the top row and the last principal component is the last row.</p></li>
</ul>
</section>
<section id="proportion-of-variance-explained-with-principal-components">
<h2>Proportion of Variance Explained with Principal Components<a class="headerlink" href="#proportion-of-variance-explained-with-principal-components" title="Permalink to this heading">#</a></h2>
<p>It is also important to look at the proportion of the variance described by each principal component.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Variance explained by PC1 and PC2 =&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;First Principal Component explains &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">3</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39; of the total variance.&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Second Principal Component explains &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="mi">3</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39; of the total variance.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Variance explained by PC1 and PC2 = [0.896 0.104]
First Principal Component explains 0.896 of the total variance.
Second Principal Component explains 0.104 of the total variance.
</pre></div>
</div>
</div>
</div>
</section>
<section id="principal-component-scores-forward-and-reverse-projections">
<h2>Principal Component Scores, Forward and Reverse Projections<a class="headerlink" href="#principal-component-scores-forward-and-reverse-projections" title="Permalink to this heading">#</a></h2>
<p>We can calculate the principle component scores of the original data.</p>
<ul class="simple">
<li><p>This is effectively a rotation of the data, aligned with PC1 for the direction of greatest variance.</p></li>
<li><p>We will calculate the principal component scores with the “transform” function built into PCA and then visualize as a scatter plot.</p></li>
<li><p>Then to “close the loop” and check what we have done (and our knowledge) we will reverse the PCA, go from the principal component scores back to the standardized features.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax101</span><span class="p">,</span> <span class="n">ax102</span><span class="p">,</span> <span class="n">ax103</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">f</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

<span class="n">ax101</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">x</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax101</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Standardized LogPerm vs. Por&#39;</span><span class="p">);</span> <span class="n">ax101</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Standardized Por&#39;</span><span class="p">);</span> <span class="n">ax101</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Standardized LogPerm&#39;</span><span class="p">)</span>
<span class="n">ax101</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]);</span> <span class="n">ax101</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]);</span> <span class="n">add_grid2</span><span class="p">(</span><span class="n">ax101</span><span class="p">)</span>

<span class="n">x_trans</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>                                <span class="c1"># calculate the principal component scores</span>
<span class="n">ax102</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_trans</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">x_trans</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax102</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Principal Component Scores&#39;</span><span class="p">);</span> <span class="n">ax102</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;PC1&#39;</span><span class="p">);</span> <span class="n">ax102</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;PC2&#39;</span><span class="p">)</span>
<span class="n">ax102</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]);</span> <span class="n">ax102</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]);</span> <span class="n">add_grid2</span><span class="p">(</span><span class="n">ax102</span><span class="p">)</span>

<span class="n">x_reverse</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">x_trans</span><span class="p">)</span>                        <span class="c1"># reverse the principal component scores to standardized values</span>
<span class="n">ax103</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_reverse</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">x_reverse</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax103</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Reverse PCA&#39;</span><span class="p">);</span> <span class="n">ax103</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Standardized Por&#39;</span><span class="p">);</span> <span class="n">ax103</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Standardized LogPerm&#39;</span><span class="p">)</span>
<span class="n">ax103</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]);</span> <span class="n">ax103</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]);</span> <span class="n">add_grid2</span><span class="p">(</span><span class="n">ax103</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/040728685fd4737dba466d509bb325eece330659c69d1efa7a1d9c67735a74ae.png" src="_images/040728685fd4737dba466d509bb325eece330659c69d1efa7a1d9c67735a74ae.png" />
</div>
</div>
<p>The standardized original and reverse PCA cross plots should look exactly the same. If so, the method is working.</p>
</section>
<section id="conservation-of-variance">
<h2>Conservation of Variance<a class="headerlink" href="#conservation-of-variance" title="Permalink to this heading">#</a></h2>
<p>Let’s check the variances of the principle component scores, since we have calculated them now.</p>
<ul class="simple">
<li><p>we calculate the variance for each of the original features</p></li>
<li><p>then sum to get the original total variance</p></li>
<li><p>we calculate the variance for each of the transformed, principal component scores</p></li>
<li><p>then we sum to get the transformed total variance</p></li>
</ul>
<p>We note the:</p>
<ul class="simple">
<li><p>the first principal component score has larger variance than the second component scores</p></li>
<li><p>total variance is preserved over the transformation, the sum of variance is the same for original features and m principal component scores</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Variance of the 2 features:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Total Variance from Original Features:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Variance of the 2 principle components:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x_trans</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">),</span><span class="mi">2</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Total Variance from Original Features:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x_trans</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)),</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Variance of the 2 features:
[1. 1.]

Total Variance from Original Features:
2.0

Variance of the 2 principle components:
[1.79 0.21]

Total Variance from Original Features:
2.0
</pre></div>
</div>
</div>
</div>
</section>
<section id="independence-of-principal-component-scores">
<h2>Independence of Principal Component Scores<a class="headerlink" href="#independence-of-principal-component-scores" title="Permalink to this heading">#</a></h2>
<p>Let’s check the correlations for the original features vs. our projected features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Correlation Matrix of the 2 original features components:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">rowvar</span> <span class="o">=</span> <span class="kc">False</span><span class="p">),</span><span class="mi">2</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Correlation Matrix of the 2 principle components</span><span class="se">\&#39;</span><span class="s1"> scores:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">x_trans</span><span class="p">,</span> <span class="n">rowvar</span> <span class="o">=</span> <span class="kc">False</span><span class="p">),</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Correlation Matrix of the 2 original features components:
[[1.   0.79]
 [0.79 1.  ]]

Correlation Matrix of the 2 principle components&#39; scores:
[[ 1. -0.]
 [-0.  1.]]
</pre></div>
</div>
</div>
</div>
<p>We have projected our original features with high correlation to 2 new features without correlation between the new features.</p>
</section>
<section id="principal-component-analysis-by-hand-with-eigenvalue-and-eigen-vector-calculator">
<h2>Principal Component Analysis By-hand with Eigenvalue and Eigen Vector Calculator<a class="headerlink" href="#principal-component-analysis-by-hand-with-eigenvalue-and-eigen-vector-calculator" title="Permalink to this heading">#</a></h2>
<p>Let’s show PCA by-hand with the standardized features and the eigen calculation and compare to the scikit-learn results from above.</p>
<ul class="simple">
<li><p>we confirm that the results match.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="kn">import</span> <span class="n">eig</span>
<span class="n">eigen_values</span><span class="p">,</span><span class="n">eigen_vectors</span> <span class="o">=</span> <span class="n">eig</span><span class="p">(</span><span class="n">cov</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Eigen Vectors:</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span>  <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">eigen_vectors</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;First Eigen Vector: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">eigen_vectors</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Second Eigen Vector: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">eigen_vectors</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Eigen Values:</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span>  <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">eigen_values</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
<span class="n">PC</span> <span class="o">=</span> <span class="n">eigen_vectors</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">PC</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span><span class="n">PC</span><span class="p">[</span><span class="mi">1</span><span class="p">,:],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Principal Component Scores By-hand with numpy.linalg Eig Function&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;PC1&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;PC2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_trans</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">x_trans</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Principal Component Scores with scikit-learn PCA&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;PC1&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;PC2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Eigen Vectors:
[[ 0.71 -0.71]
 [ 0.71  0.71]]
First Eigen Vector: [0.70710678 0.70710678]
Second Eigen Vector: [-0.70710678  0.70710678]
Eigen Values:
[1.81 0.21]
</pre></div>
</div>
<img alt="_images/792323ef0c7e641c08fbe33eefb6dc67e05dfacaee639375589ba3f7f4689f07.png" src="_images/792323ef0c7e641c08fbe33eefb6dc67e05dfacaee639375589ba3f7f4689f07.png" />
</div>
</div>
</section>
<section id="demonstration-of-dimensional-reduction">
<h2>Demonstration of Dimensional Reduction<a class="headerlink" href="#demonstration-of-dimensional-reduction" title="Permalink to this heading">#</a></h2>
<p>Now let’s attempt <strong>dimensional reduction</strong> by only retaining the first principle component. We will go from original values to predictions of original values.</p>
<ul class="simple">
<li><p>Recall we were able to explain about 90% of the variance with the first principal component so the result should look ‘pretty good’, right?</p></li>
</ul>
<p>We will do the whole thing by hand to make it as simple/understandable as possible for this first time through.  Later we will be much more compact.  The steps:</p>
<ol class="arabic simple">
<li><p>start with the original porosity and permeability data</p></li>
<li><p>standardize such that Por and LogPerm have a mean of 0.0 and a variance of 1.0</p></li>
<li><p>calculate the 2 principal component model, visualize the principal component scores</p></li>
<li><p>remove the 2nd principal component by setting the associated component scores to 0.0</p></li>
<li><p>reverse the principal component by matrix multiplication of the scores with the component loadings</p></li>
<li><p>apply matrix math to restore the original mean and variance</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nComp</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">f</span><span class="p">,</span> <span class="p">((</span><span class="n">ax201</span><span class="p">,</span> <span class="n">ax202</span><span class="p">,</span> <span class="n">ax203</span><span class="p">),</span> <span class="p">(</span><span class="n">ax206</span><span class="p">,</span> <span class="n">ax205</span><span class="p">,</span> <span class="n">ax204</span><span class="p">))</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="c1">#f, ((ax201, ax202), (ax203, ax204), (ax205, ax206)) = plt.subplots(3, 2,figsize=(10,15))</span>
<span class="n">f</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">hspace</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>

<span class="n">ax201</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">my_data_por_perm</span><span class="p">[</span><span class="s2">&quot;Por&quot;</span><span class="p">],</span><span class="n">my_data_por_perm</span><span class="p">[</span><span class="s2">&quot;LogPerm&quot;</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax201</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;1. LogPerm vs. Por&#39;</span><span class="p">);</span> <span class="n">ax201</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Por&#39;</span><span class="p">);</span> <span class="n">ax201</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;LogPerm&#39;</span><span class="p">)</span>
<span class="n">ax201</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span><span class="mi">22</span><span class="p">]);</span> <span class="n">ax201</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">2.5</span><span class="p">]);</span> <span class="n">add_grid2</span><span class="p">(</span><span class="n">ax201</span><span class="p">)</span>

<span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">my_data_por_perm</span><span class="p">[</span><span class="s2">&quot;Por&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span><span class="n">my_data_por_perm</span><span class="p">[</span><span class="s2">&quot;LogPerm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">sd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">my_data_por_perm</span><span class="p">[</span><span class="s2">&quot;Por&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span><span class="n">my_data_por_perm</span><span class="p">[</span><span class="s2">&quot;LogPerm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>                     <span class="c1"># standardize the data features to mean = 0, var = 1.0</span>

<span class="n">ax202</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">x</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax202</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;2. Standardized LogPerm vs. Por&#39;</span><span class="p">);</span> <span class="n">ax202</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Standardized Por&#39;</span><span class="p">);</span> <span class="n">ax202</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Standardized LogPerm&#39;</span><span class="p">)</span>
<span class="n">ax202</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">]);</span> <span class="n">ax202</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">]);</span> <span class="n">add_grid2</span><span class="p">(</span><span class="n">ax202</span><span class="p">)</span>

<span class="n">n_components</span> <span class="o">=</span> <span class="mi">2</span>                                          <span class="c1"># build principal component model with 2 components</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">)</span>
<span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">x_trans</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>                                <span class="c1"># calculate principal component scores</span>
<span class="n">ax203</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_trans</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">x_trans</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax203</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;3. Principal Component Scores&#39;</span><span class="p">);</span> <span class="n">ax203</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;PC1&#39;</span><span class="p">);</span> <span class="n">ax203</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;PC2&#39;</span><span class="p">)</span>
<span class="n">ax203</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">]);</span> <span class="n">ax203</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">]);</span> <span class="n">add_grid2</span><span class="p">(</span><span class="n">ax203</span><span class="p">)</span>

<span class="n">x_trans</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>                                         <span class="c1"># zero / remove the 2nd principal component </span>

<span class="n">ax204</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_trans</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">x_trans</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax204</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;4. Only 1st Principal Component Scores&#39;</span><span class="p">);</span> <span class="n">ax204</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;PC1&#39;</span><span class="p">);</span> <span class="n">ax204</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;PC2&#39;</span><span class="p">)</span>
<span class="n">ax204</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">]);</span> <span class="n">ax204</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">]);</span> <span class="n">add_grid2</span><span class="p">(</span><span class="n">ax204</span><span class="p">)</span>

<span class="n">xhat</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">x_trans</span><span class="p">)</span>                             <span class="c1"># reverse the principal component scores to standardized values</span>
<span class="n">ax205</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xhat</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">xhat</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax205</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;5. Reverse PCA&#39;</span><span class="p">);</span> <span class="n">ax205</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Standardized Por&#39;</span><span class="p">);</span> <span class="n">ax205</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Standardized LogPerm&#39;</span><span class="p">)</span>
<span class="n">ax205</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">]);</span> <span class="n">ax205</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">]);</span> <span class="n">add_grid2</span><span class="p">(</span><span class="n">ax205</span><span class="p">)</span>

<span class="n">xhat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)[:,:</span><span class="n">nComp</span><span class="p">],</span> <span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="p">[:</span><span class="n">nComp</span><span class="p">,:])</span>
<span class="n">xhat</span> <span class="o">=</span> <span class="n">sd</span><span class="o">*</span><span class="n">xhat</span> <span class="o">+</span> <span class="n">mu</span>                                       <span class="c1"># remove the standardization</span>

<span class="n">ax206</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">my_data_por_perm</span><span class="p">[</span><span class="s2">&quot;Por&quot;</span><span class="p">],</span><span class="n">my_data_por_perm</span><span class="p">[</span><span class="s2">&quot;LogPerm&quot;</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax206</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xhat</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">xhat</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax206</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;6. De-standardized Reverse PCA&#39;</span><span class="p">);</span> <span class="n">ax206</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Por&#39;</span><span class="p">);</span> <span class="n">ax206</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;LogPerm&#39;</span><span class="p">)</span>
<span class="n">ax206</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span><span class="mi">22</span><span class="p">]);</span> <span class="n">ax206</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">2.5</span><span class="p">]);</span> <span class="n">add_grid2</span><span class="p">(</span><span class="n">ax206</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/99fce5c8ff4962b84e1d76599a56e25a485eb8a4462b4fa608f8d5a9af64a8dd.png" src="_images/99fce5c8ff4962b84e1d76599a56e25a485eb8a4462b4fa608f8d5a9af64a8dd.png" />
</div>
</div>
<p>Let’s put the original data and the resulting lower dimensional model side-by-side and check the resulting variances.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax201</span><span class="p">,</span> <span class="n">ax206</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">f</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">hspace</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>

<span class="n">ax201</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">my_data_por_perm</span><span class="p">[</span><span class="s2">&quot;Por&quot;</span><span class="p">],</span><span class="n">my_data_por_perm</span><span class="p">[</span><span class="s2">&quot;LogPerm&quot;</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax201</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;1. LogPerm vs. Por&#39;</span><span class="p">);</span> <span class="n">ax201</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Por&#39;</span><span class="p">);</span> <span class="n">ax201</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;LogPerm&#39;</span><span class="p">)</span>
<span class="n">ax201</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span><span class="mi">22</span><span class="p">]);</span> <span class="n">ax201</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">2.5</span><span class="p">]);</span> <span class="n">add_grid2</span><span class="p">(</span><span class="n">ax201</span><span class="p">)</span>

<span class="n">ax206</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xhat</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">xhat</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax206</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;6. De-standardized Reverse PCA&#39;</span><span class="p">);</span> <span class="n">ax206</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Por&#39;</span><span class="p">);</span> <span class="n">ax206</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;LogPerm&#39;</span><span class="p">)</span>
<span class="n">ax206</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span><span class="mi">22</span><span class="p">]);</span> <span class="n">ax206</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">2.5</span><span class="p">]);</span> <span class="n">add_grid2</span><span class="p">(</span><span class="n">ax206</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">var_por</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">my_data_por_perm</span><span class="p">[</span><span class="s2">&quot;Por&quot;</span><span class="p">]);</span> <span class="n">var_por_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">xhat</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]);</span>
<span class="n">var_logperm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">my_data_por_perm</span><span class="p">[</span><span class="s2">&quot;LogPerm&quot;</span><span class="p">]);</span> <span class="n">var_logperm_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">xhat</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]);</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Variance Por =&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">var_por</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span><span class="s1">&#39;, Variance Reduced Dimensional Por =&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">var_por_hat</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span><span class="s1">&#39;Fraction = &#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">var_por_hat</span><span class="o">/</span><span class="n">var_por</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Variance LogPerm =&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">var_logperm</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span><span class="s1">&#39;, Variance Reduced Dimensional LogPerm =&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">var_logperm_hat</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span><span class="s1">&#39;Fraction = &#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">var_logperm_hat</span><span class="o">/</span><span class="n">var_logperm</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Total Variance =&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">var_por</span> <span class="o">+</span> <span class="n">var_logperm</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="s1">&#39;, Total Variance Reduced Dimension =&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">var_por_hat</span><span class="o">+</span><span class="n">var_logperm_hat</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span><span class="s1">&#39;Fraction = &#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">((</span><span class="n">var_por_hat</span><span class="o">+</span><span class="n">var_logperm_hat</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">var_por</span><span class="o">+</span><span class="n">var_logperm</span><span class="p">),</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/dd23216e8863e8d206d5ad4311ffe9586147d99dbb5d2ad0581d859f68582c1d.png" src="_images/dd23216e8863e8d206d5ad4311ffe9586147d99dbb5d2ad0581d859f68582c1d.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Variance Por = 7.89 , Variance Reduced Dimensional Por = 7.073 Fraction =  0.896
Variance LogPerm = 0.151 , Variance Reduced Dimensional LogPerm = 0.136 Fraction =  0.896
Total Variance = 8.041 , Total Variance Reduced Dimension = 7.208 Fraction =  0.896
</pre></div>
</div>
</div>
</div>
</section>
<section id="all-predictor-features">
<h2>All Predictor Features<a class="headerlink" href="#all-predictor-features" title="Permalink to this heading">#</a></h2>
<p>We will go back to the original data file and this time extract all 6 predictor variables and the first 500 samples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">my_data_f6</span> <span class="o">=</span> <span class="n">my_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">500</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">6</span><span class="p">]</span>                      <span class="c1"># extract the 6 predictors, 500 samples</span>
</pre></div>
</div>
</div>
</div>
<p>It is a good idea to start with the summary statistics for our data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">my_data_f6</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>                         <span class="c1"># calculate summary statistics for the data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Por</th>
      <td>500.0</td>
      <td>14.89936</td>
      <td>2.985967</td>
      <td>5.40</td>
      <td>12.8500</td>
      <td>14.900</td>
      <td>17.0125</td>
      <td>23.85</td>
    </tr>
    <tr>
      <th>LogPerm</th>
      <td>500.0</td>
      <td>1.40010</td>
      <td>0.409616</td>
      <td>0.18</td>
      <td>1.1475</td>
      <td>1.380</td>
      <td>1.6700</td>
      <td>2.58</td>
    </tr>
    <tr>
      <th>AI</th>
      <td>500.0</td>
      <td>2.99244</td>
      <td>0.563674</td>
      <td>1.21</td>
      <td>2.5900</td>
      <td>3.035</td>
      <td>3.3725</td>
      <td>4.70</td>
    </tr>
    <tr>
      <th>Brittle</th>
      <td>500.0</td>
      <td>49.74682</td>
      <td>15.212123</td>
      <td>0.00</td>
      <td>39.3125</td>
      <td>49.595</td>
      <td>59.2075</td>
      <td>93.47</td>
    </tr>
    <tr>
      <th>TOC</th>
      <td>500.0</td>
      <td>0.99800</td>
      <td>0.503635</td>
      <td>0.00</td>
      <td>0.6400</td>
      <td>0.960</td>
      <td>1.3500</td>
      <td>2.71</td>
    </tr>
    <tr>
      <th>VR</th>
      <td>500.0</td>
      <td>1.99260</td>
      <td>0.307434</td>
      <td>0.90</td>
      <td>1.8200</td>
      <td>2.010</td>
      <td>2.1725</td>
      <td>2.84</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let’s also calculate a correlation matrix and view it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">my_data_f6</span><span class="p">,</span> <span class="n">rowvar</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">around</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>                           <span class="c1"># print the correlation matrix to 2 decimals</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 1.    0.79 -0.49 -0.25  0.71  0.12]
 [ 0.79  1.   -0.32 -0.13  0.48  0.04]
 [-0.49 -0.32  1.    0.14 -0.53  0.47]
 [-0.25 -0.13  0.14  1.   -0.24  0.24]
 [ 0.71  0.48 -0.53 -0.24  1.    0.35]
 [ 0.12  0.04  0.47  0.24  0.35  1.  ]]
</pre></div>
</div>
</div>
</div>
<p>We will need to standardize each variable to have a mean of zero and a variance of one.  Let’s do that and check the results. In the console below we print all the initial and standardized means and variances for all 6 predictors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Por&#39;</span><span class="p">,</span><span class="s1">&#39;LogPerm&#39;</span><span class="p">,</span><span class="s1">&#39;AI&#39;</span><span class="p">,</span><span class="s1">&#39;Brittle&#39;</span><span class="p">,</span><span class="s1">&#39;TOC&#39;</span><span class="p">,</span><span class="s1">&#39;VR&#39;</span><span class="p">]</span>
<span class="n">x_f6</span> <span class="o">=</span> <span class="n">my_data_f6</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">features</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">mu_f6</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x_f6</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">sd_f6</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x_f6</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x_f6</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_f6</span><span class="p">)</span>
 
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original Means&quot;</span><span class="p">,</span> <span class="n">features</span><span class="p">[:],</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mu_f6</span><span class="p">[:],</span><span class="mi">2</span><span class="p">))</span> 
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original StDevs&quot;</span><span class="p">,</span> <span class="n">features</span><span class="p">[:],</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">sd_f6</span><span class="p">[:],</span><span class="mi">2</span><span class="p">))</span> 
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean Transformed =&#39;</span><span class="p">,</span><span class="n">features</span><span class="p">[:],</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Variance Transformed Por =&#39;</span><span class="p">,</span><span class="n">features</span><span class="p">[:],</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Original Means [&#39;Por&#39;, &#39;LogPerm&#39;, &#39;AI&#39;, &#39;Brittle&#39;, &#39;TOC&#39;, &#39;VR&#39;] [14.9   1.4   2.99 49.75  1.    1.99]
Original StDevs [&#39;Por&#39;, &#39;LogPerm&#39;, &#39;AI&#39;, &#39;Brittle&#39;, &#39;TOC&#39;, &#39;VR&#39;] [ 2.98  0.41  0.56 15.2   0.5   0.31]
Mean Transformed = [&#39;Por&#39;, &#39;LogPerm&#39;, &#39;AI&#39;, &#39;Brittle&#39;, &#39;TOC&#39;, &#39;VR&#39;] [0. 0.]
Variance Transformed Por = [&#39;Por&#39;, &#39;LogPerm&#39;, &#39;AI&#39;, &#39;Brittle&#39;, &#39;TOC&#39;, &#39;VR&#39;] [1. 1.]
</pre></div>
</div>
</div>
</div>
<p>We should also check the univariate distributions for each variable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax6</span><span class="p">,</span><span class="n">ax7</span><span class="p">,</span><span class="n">ax8</span><span class="p">,</span><span class="n">ax9</span><span class="p">,</span><span class="n">ax10</span><span class="p">,</span><span class="n">ax11</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">ax6</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x_f6</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span> <span class="n">ax6</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Std. Porosity&#39;</span><span class="p">);</span> <span class="n">ax6</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">ax7</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x_f6</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span> <span class="n">ax7</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Std. Log[Perm.]&#39;</span><span class="p">);</span> <span class="n">ax7</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">ax8</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x_f6</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span> <span class="n">ax8</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Std. Acoustic Imped.&#39;</span><span class="p">);</span> <span class="n">ax8</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">ax9</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x_f6</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span> <span class="n">ax9</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Std. Brittleness&#39;</span><span class="p">);</span> <span class="n">ax9</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">ax10</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x_f6</span><span class="p">[:,</span><span class="mi">4</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span> <span class="n">ax10</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Std. Total Organic C&#39;</span><span class="p">);</span> <span class="n">ax10</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">ax11</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x_f6</span><span class="p">[:,</span><span class="mi">5</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span> <span class="n">ax11</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Std. Vit. Reflectance&#39;</span><span class="p">);</span> <span class="n">ax11</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/cb70ebc58a6161c91e168f37c51faf16ad0c7a73cb23c7741794ee731d2470a4.png" src="_images/cb70ebc58a6161c91e168f37c51faf16ad0c7a73cb23c7741794ee731d2470a4.png" />
</div>
</div>
<p>The summary statistics and distributions look good.  No obvious missing data, gaps, significant truncations, spikes or outliers.  We are ready to perform principal component analysis on our 6 features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_components</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">pca_f6</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">)</span>
<span class="n">pca_f6</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_f6</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">pca_f6</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>                     <span class="c1"># visualize the component loadings</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 0.558  0.476 -0.405 -0.211  0.504  0.01 ]
 [-0.117 -0.114 -0.432 -0.323 -0.229 -0.794]
 [-0.019 -0.124  0.384 -0.898  0.07   0.157]
 [-0.214 -0.674 -0.424 -0.006  0.526  0.21 ]
 [-0.784  0.522 -0.031 -0.046  0.331 -0.019]
 [ 0.12  -0.138  0.566  0.206  0.55  -0.549]]
</pre></div>
</div>
</div>
</div>
<p>Let’s look at the component loadings first.  Each row is a component, top row is the first principal component (PC1), next row is the second principal component (PC2) up to the last row the sixth principal component (PC6).  The columns are the features ordered from ‘Por’, ‘LogPerm’, ‘AI’, ‘Brittle’, ‘TOC’, to ‘VR’.</p>
<p>First principal component is mainly composed of porosity, log permeability, acoustic impedance and total organic carbon, suggesting that the way they vary together is responsible for much of the variance.  The next principle component is mainly composed of vitrinite reflectance.  The third principal coordinate is mainly composed of brittleness and so on.</p>
</section>
<section id="scree-plots">
<h2>Scree Plots<a class="headerlink" href="#scree-plots" title="Permalink to this heading">#</a></h2>
<p>To assist in this interpretation we should consider the variance contributions from each principal component.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Variance explained by PC1 thru PC6 =&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">pca_f6</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>

<span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax10</span><span class="p">,</span> <span class="n">ax11</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">f</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">hspace</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>

<span class="n">ax10</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">pca_f6</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">ax10</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">pca_f6</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">ax10</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Principal Component&#39;</span><span class="p">);</span> <span class="n">ax10</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Variance Explained&#39;</span><span class="p">);</span> <span class="n">ax10</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Variance Explained by Principal Component&#39;</span><span class="p">)</span>
<span class="n">fmt</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">%.0f%%</span><span class="s1">&#39;</span> <span class="c1"># Format you want the ticks, e.g. &#39;40%&#39;</span>
<span class="n">yticks</span> <span class="o">=</span> <span class="n">mtick</span><span class="o">.</span><span class="n">FormatStrFormatter</span><span class="p">(</span><span class="n">fmt</span><span class="p">);</span> <span class="n">ax10</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">);</span> <span class="n">ax10</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">100.0</span><span class="p">)</span>
<span class="n">ax10</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">yticks</span><span class="p">);</span> <span class="n">add_grid2</span><span class="p">(</span><span class="n">ax10</span><span class="p">)</span>

<span class="n">ax11</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">pca_f6</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="o">*</span><span class="mi">100</span><span class="p">),</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">ax11</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">pca_f6</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="o">*</span><span class="mi">100</span><span class="p">),</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">ax11</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">],[</span><span class="mi">95</span><span class="p">,</span><span class="mi">95</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">)</span>
<span class="n">ax11</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Principal Component&#39;</span><span class="p">);</span> <span class="n">ax11</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Cumulative Variance Explained&#39;</span><span class="p">);</span> <span class="n">ax11</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Cumulative Variance Explained by Principal Component&#39;</span><span class="p">)</span>
<span class="n">fmt</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">%.0f%%</span><span class="s1">&#39;</span> <span class="c1"># Format you want the ticks, e.g. &#39;40%&#39;</span>
<span class="n">yticks</span> <span class="o">=</span> <span class="n">mtick</span><span class="o">.</span><span class="n">FormatStrFormatter</span><span class="p">(</span><span class="n">fmt</span><span class="p">);</span> <span class="n">ax11</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">);</span> <span class="n">ax11</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">100.0</span><span class="p">);</span> <span class="n">ax11</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;95% variance explained&#39;</span><span class="p">,[</span><span class="mf">4.05</span><span class="p">,</span><span class="mi">90</span><span class="p">])</span>
<span class="n">ax11</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">yticks</span><span class="p">);</span> <span class="n">add_grid2</span><span class="p">(</span><span class="n">ax11</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Variance explained by PC1 thru PC6 = [0.462 0.246 0.149 0.11  0.024 0.009]
</pre></div>
</div>
<img alt="_images/f13a2759a5a3a9ba079c2c90976c1d01b7e4e03c073aeb9780c2e4db83e7bbbf.png" src="_images/f13a2759a5a3a9ba079c2c90976c1d01b7e4e03c073aeb9780c2e4db83e7bbbf.png" />
</div>
</div>
<p>We can see that about 46% of the variance is described by the 1st principal component and then about 25% is described by the 2nd principal component etc.</p>
</section>
<section id="id2">
<h2>Independence of Principal Component Scores<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<p>Let’s check the pairwise feature correlations before and after the projection.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Correlation Matrix of the 6 original features components:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">x_f6</span><span class="p">,</span> <span class="n">rowvar</span> <span class="o">=</span> <span class="kc">False</span><span class="p">),</span><span class="mi">2</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Correlation Matrix of the 6 principle components</span><span class="se">\&#39;</span><span class="s1"> scores:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">pca_f6</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_f6</span><span class="p">),</span> <span class="n">rowvar</span> <span class="o">=</span> <span class="kc">False</span><span class="p">),</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Correlation Matrix of the 6 original features components:
[[ 1.    0.79 -0.49 -0.25  0.71  0.12]
 [ 0.79  1.   -0.32 -0.13  0.48  0.04]
 [-0.49 -0.32  1.    0.14 -0.53  0.47]
 [-0.25 -0.13  0.14  1.   -0.24  0.24]
 [ 0.71  0.48 -0.53 -0.24  1.    0.35]
 [ 0.12  0.04  0.47  0.24  0.35  1.  ]]

Correlation Matrix of the 6 principle components&#39; scores:
[[ 1. -0.  0. -0.  0. -0.]
 [-0.  1. -0. -0.  0. -0.]
 [ 0. -0.  1. -0.  0.  0.]
 [-0. -0. -0.  1.  0. -0.]
 [ 0.  0.  0.  0.  1.  0.]
 [-0. -0.  0. -0.  0.  1.]]
</pre></div>
</div>
</div>
</div>
<p>The new projected features (even without dimensionality reduction, <span class="math notranslate nohighlight">\(p=m\)</span>) all have pairwise correlations of 0.0!</p>
<ul class="simple">
<li><p>all the projected features are linearly independent of each other</p></li>
</ul>
</section>
<section id="reduced-dimensionality-impact-on-a-2-feature-relationship">
<h2>Reduced Dimensionality Impact on a 2 Feature Relationship<a class="headerlink" href="#reduced-dimensionality-impact-on-a-2-feature-relationship" title="Permalink to this heading">#</a></h2>
<p>It would be interesting to look just at the porosity vs. log permeability bivariate relationship when we retain <span class="math notranslate nohighlight">\(1,\ldots,6\)</span> principal components.</p>
<ul class="simple">
<li><p>to do this we use matrix math to reverse with PCA and the standardization with various number of principal component and then plot the scatter plots of log permeability vs. porosity.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nComp</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">xhat_6d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">pca_f6</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_f6</span><span class="p">)[:,:</span><span class="n">nComp</span><span class="p">],</span> <span class="n">pca_f6</span><span class="o">.</span><span class="n">components_</span><span class="p">[:</span><span class="n">nComp</span><span class="p">,:])</span>
<span class="n">xhat_6d</span> <span class="o">=</span> <span class="n">sd_f6</span><span class="o">*</span><span class="n">xhat_6d</span> <span class="o">+</span> <span class="n">mu_f6</span>

<span class="n">nComp</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">xhat_5d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">pca_f6</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_f6</span><span class="p">)[:,:</span><span class="n">nComp</span><span class="p">],</span> <span class="n">pca_f6</span><span class="o">.</span><span class="n">components_</span><span class="p">[:</span><span class="n">nComp</span><span class="p">,:])</span>
<span class="n">xhat_5d</span> <span class="o">=</span> <span class="n">sd_f6</span><span class="o">*</span><span class="n">xhat_5d</span> <span class="o">+</span> <span class="n">mu_f6</span>

<span class="n">nComp</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">xhat_4d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">pca_f6</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_f6</span><span class="p">)[:,:</span><span class="n">nComp</span><span class="p">],</span> <span class="n">pca_f6</span><span class="o">.</span><span class="n">components_</span><span class="p">[:</span><span class="n">nComp</span><span class="p">,:])</span>
<span class="n">xhat_4d</span> <span class="o">=</span> <span class="n">sd_f6</span><span class="o">*</span><span class="n">xhat_4d</span> <span class="o">+</span> <span class="n">mu_f6</span>

<span class="n">nComp</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">xhat_3d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">pca_f6</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_f6</span><span class="p">)[:,:</span><span class="n">nComp</span><span class="p">],</span> <span class="n">pca_f6</span><span class="o">.</span><span class="n">components_</span><span class="p">[:</span><span class="n">nComp</span><span class="p">,:])</span>
<span class="n">xhat_3d</span> <span class="o">=</span> <span class="n">sd_f6</span><span class="o">*</span><span class="n">xhat_3d</span> <span class="o">+</span> <span class="n">mu_f6</span>

<span class="n">nComp</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">xhat_2d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">pca_f6</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_f6</span><span class="p">)[:,:</span><span class="n">nComp</span><span class="p">],</span> <span class="n">pca_f6</span><span class="o">.</span><span class="n">components_</span><span class="p">[:</span><span class="n">nComp</span><span class="p">,:])</span>
<span class="n">xhat_2d</span> <span class="o">=</span> <span class="n">sd_f6</span><span class="o">*</span><span class="n">xhat_2d</span> <span class="o">+</span> <span class="n">mu_f6</span>

<span class="n">nComp</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">xhat_1d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">pca_f6</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_f6</span><span class="p">)[:,:</span><span class="n">nComp</span><span class="p">],</span> <span class="n">pca_f6</span><span class="o">.</span><span class="n">components_</span><span class="p">[:</span><span class="n">nComp</span><span class="p">,:])</span>
<span class="n">xhat_1d</span> <span class="o">=</span> <span class="n">sd_f6</span><span class="o">*</span><span class="n">xhat_1d</span> <span class="o">+</span> <span class="n">mu_f6</span>

<span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax12</span><span class="p">,</span> <span class="n">ax13</span><span class="p">,</span> <span class="n">ax14</span><span class="p">,</span> <span class="n">ax15</span><span class="p">,</span> <span class="n">ax16</span><span class="p">,</span> <span class="n">ax17</span><span class="p">,</span> <span class="n">ax18</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
<span class="n">f</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

<span class="n">ax12</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">my_data_f6</span><span class="p">[</span><span class="s2">&quot;Por&quot;</span><span class="p">],</span><span class="n">my_data_f6</span><span class="p">[</span><span class="s2">&quot;LogPerm&quot;</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax12</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Original Data&#39;</span><span class="p">);</span> <span class="n">ax12</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Por&#39;</span><span class="p">);</span> <span class="n">ax12</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;LogPerm&#39;</span><span class="p">)</span>
<span class="n">ax12</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">);</span> <span class="n">ax12</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">22</span><span class="p">);</span> <span class="n">ax12</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mf">4.0</span><span class="p">);</span> 

<span class="n">ax13</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xhat_1d</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">xhat_1d</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax13</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;1 Principal Component&#39;</span><span class="p">);</span> <span class="n">ax13</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Por&#39;</span><span class="p">);</span> <span class="n">ax13</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;LogPerm&#39;</span><span class="p">)</span>
<span class="n">ax13</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">);</span> <span class="n">ax13</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">22</span><span class="p">);</span> <span class="n">ax13</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mf">4.0</span><span class="p">)</span>

<span class="n">ax14</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xhat_2d</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">xhat_2d</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax14</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;2 Principal Components&#39;</span><span class="p">);</span> <span class="n">ax14</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Por&#39;</span><span class="p">);</span> <span class="n">ax14</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;LogPerm&#39;</span><span class="p">)</span>
<span class="n">ax14</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">);</span> <span class="n">ax14</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">22</span><span class="p">);</span> <span class="n">ax14</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mf">4.0</span><span class="p">)</span>

<span class="n">ax15</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xhat_3d</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">xhat_3d</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax15</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;3 Principal Components&#39;</span><span class="p">);</span> <span class="n">ax15</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Por&#39;</span><span class="p">);</span> <span class="n">ax15</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;LogPerm&#39;</span><span class="p">)</span>
<span class="n">ax15</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">);</span> <span class="n">ax15</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">22</span><span class="p">);</span> <span class="n">ax15</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mf">4.0</span><span class="p">)</span>

<span class="n">ax16</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xhat_4d</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">xhat_4d</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax16</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;4 Principal Components&#39;</span><span class="p">);</span> <span class="n">ax16</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Por&#39;</span><span class="p">);</span> <span class="n">ax16</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;LogPerm&#39;</span><span class="p">)</span>
<span class="n">ax16</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">);</span> <span class="n">ax16</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">22</span><span class="p">);</span> <span class="n">ax16</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mf">4.0</span><span class="p">)</span>

<span class="n">ax17</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xhat_5d</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">xhat_5d</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax17</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;5 Principal Components&#39;</span><span class="p">);</span> <span class="n">ax17</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Por&#39;</span><span class="p">);</span> <span class="n">ax17</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;LogPerm&#39;</span><span class="p">)</span>
<span class="n">ax17</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">);</span> <span class="n">ax17</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">22</span><span class="p">);</span> <span class="n">ax17</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mf">4.0</span><span class="p">)</span>

<span class="n">ax18</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xhat_6d</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">xhat_6d</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;darkorange&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax18</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;6 Principal Components&#39;</span><span class="p">);</span> <span class="n">ax18</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Por&#39;</span><span class="p">);</span> <span class="n">ax18</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;LogPerm&#39;</span><span class="p">)</span>
<span class="n">ax18</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">);</span> <span class="n">ax18</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">22</span><span class="p">);</span> <span class="n">ax18</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mf">4.0</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/2c07008ca4c1cad616bfb73f5ffed082b67c565a0bbab5e216624e59e8c949ff.png" src="_images/2c07008ca4c1cad616bfb73f5ffed082b67c565a0bbab5e216624e59e8c949ff.png" />
</div>
</div>
<p>Very interesting to watch the accuracy of the bivariate relationship between log permeability and porosity improve as we include more components.  Let’s check the variances.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;1 Principal Component : Variance Por =&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">xhat_1d</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span><span class="mi">2</span><span class="p">),</span><span class="s1">&#39; Variance Log Perm = &#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">xhat_1d</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span><span class="mi">2</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;2 Principal Components: Variance Por =&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">xhat_2d</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span><span class="mi">2</span><span class="p">),</span><span class="s1">&#39; Variance Log Perm = &#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">xhat_2d</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span><span class="mi">2</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;3 Principal Components: Variance Por =&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">xhat_3d</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span><span class="mi">2</span><span class="p">),</span><span class="s1">&#39; Variance Log Perm = &#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">xhat_3d</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span><span class="mi">2</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;4 Principal Components: Variance Por =&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">xhat_4d</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span><span class="mi">2</span><span class="p">),</span><span class="s1">&#39; Variance Log Perm = &#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">xhat_4d</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span><span class="mi">2</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;5 Principal Components: Variance Por =&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">xhat_5d</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span><span class="mi">2</span><span class="p">),</span><span class="s1">&#39;  Variance Log Perm = &#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">xhat_5d</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span><span class="mi">2</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;6 Principal Components: Variance Por =&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">xhat_6d</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span><span class="mi">2</span><span class="p">),</span><span class="s1">&#39;  Variance Log Perm = &#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">xhat_6d</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">sd_f6</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1 Principal Component : Variance Por = 0.86  Variance Log Perm =  0.63
2 Principal Components: Variance Por = 0.88  Variance Log Perm =  0.65
3 Principal Components: Variance Por = 0.88  Variance Log Perm =  0.66
4 Principal Components: Variance Por = 0.91  Variance Log Perm =  0.96
5 Principal Components: Variance Por = 1.0   Variance Log Perm =  1.0
6 Principal Components: Variance Por = 1.0   Variance Log Perm =  1.0
</pre></div>
</div>
</div>
</div>
<p>This is interesting.  With the first principal component we describe 86% of the porosity variance. The next two principal components do not provide much assistance. Then there is a jump with the 4th and 5th principal components.</p>
<ul class="simple">
<li><p>of course, the problem is 6 dimensional, not just porosity vs. log permeability, but is it interesting to see the relationship between number of principal components and variance retained each of these 2 original features</p></li>
<li><p>principal components do not uniformly described each feature</p></li>
</ul>
</section>
<section id="reduced-dimensionality-impact-on-matrix-scatter-plots-of-all-features">
<h2>Reduced Dimensionality Impact on Matrix Scatter Plots of All Features<a class="headerlink" href="#reduced-dimensionality-impact-on-matrix-scatter-plots-of-all-features" title="Permalink to this heading">#</a></h2>
<p>Let’s look at the matrix scatter plots for see all of the bivariate combinations.</p>
<ul class="simple">
<li><p>first some book keeping, we have to put the 6D reduced dimensionality models in DataFrames (there are currently Numpy ndarrays.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_1d</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">xhat_1d</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="n">features</span><span class="p">)</span>   
<span class="n">df_2d</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">xhat_2d</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="n">features</span><span class="p">)</span>
<span class="n">df_3d</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">xhat_3d</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="n">features</span><span class="p">)</span>
<span class="n">df_4d</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">xhat_4d</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="n">features</span><span class="p">)</span>
<span class="n">df_5d</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">xhat_5d</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="n">features</span><span class="p">)</span>
<span class="n">df_6d</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">xhat_6d</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="n">features</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can go ahead and produce the matrix scatter plots with these DataFrames. It is very interesting to see the accuracy of the bivariate plots improve as we add principal components.  Also, with only two principal components we capture some of the bivariate relationships quite well for some of the variable pairs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

<span class="n">pd_plot</span><span class="o">.</span><span class="n">scatter_matrix</span><span class="p">(</span><span class="n">my_data_f6</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>           <span class="c1"># pandas matrix scatter plot</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">hist_kwds</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;color&#39;</span><span class="p">:[</span><span class="s1">&#39;grey&#39;</span><span class="p">]})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Original Data&#39;</span><span class="p">)</span>

<span class="n">pd_plot</span><span class="o">.</span><span class="n">scatter_matrix</span><span class="p">(</span><span class="n">df_1d</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>                <span class="c1"># pandas matrix scatter plot</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">hist_kwds</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;color&#39;</span><span class="p">:[</span><span class="s1">&#39;grey&#39;</span><span class="p">]})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;1 Principal Component&#39;</span><span class="p">)</span>

<span class="n">pd_plot</span><span class="o">.</span><span class="n">scatter_matrix</span><span class="p">(</span><span class="n">df_2d</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>                <span class="c1"># pandas matrix scatter plot</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">hist_kwds</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;color&#39;</span><span class="p">:[</span><span class="s1">&#39;grey&#39;</span><span class="p">]})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;2 Principal Components&#39;</span><span class="p">)</span>

<span class="n">pd_plot</span><span class="o">.</span><span class="n">scatter_matrix</span><span class="p">(</span><span class="n">df_3d</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>                <span class="c1"># pandas matrix scatter plot</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">hist_kwds</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;color&#39;</span><span class="p">:[</span><span class="s1">&#39;grey&#39;</span><span class="p">]})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;3 Principal Components&#39;</span><span class="p">)</span>

<span class="n">pd_plot</span><span class="o">.</span><span class="n">scatter_matrix</span><span class="p">(</span><span class="n">df_4d</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>                <span class="c1"># pandas matrix scatter plot</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">hist_kwds</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;color&#39;</span><span class="p">:[</span><span class="s1">&#39;grey&#39;</span><span class="p">]})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;4 Principal Components&#39;</span><span class="p">)</span>

<span class="n">pd_plot</span><span class="o">.</span><span class="n">scatter_matrix</span><span class="p">(</span><span class="n">df_5d</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>                <span class="c1"># pandas matrix scatter plot</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">hist_kwds</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;color&#39;</span><span class="p">:[</span><span class="s1">&#39;grey&#39;</span><span class="p">]})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;5 Principal Components&#39;</span><span class="p">)</span>

<span class="n">pd_plot</span><span class="o">.</span><span class="n">scatter_matrix</span><span class="p">(</span><span class="n">df_6d</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>                <span class="c1"># pandas matrix scatter plot</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">hist_kwds</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;color&#39;</span><span class="p">:[</span><span class="s1">&#39;grey&#39;</span><span class="p">]})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;6 Principal Components&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Figure size 640x480 with 0 Axes&gt;
</pre></div>
</div>
<img alt="_images/7e0fd0b08b519dd15fc7c0b2a9ccd5a2b5754140ab93346fc7115546b8d3e809.png" src="_images/7e0fd0b08b519dd15fc7c0b2a9ccd5a2b5754140ab93346fc7115546b8d3e809.png" />
<img alt="_images/f27b9d55ef99f92c08c7cb21de0a0d689254e6fc3a83a54a3e8eb85f5c95c0d0.png" src="_images/f27b9d55ef99f92c08c7cb21de0a0d689254e6fc3a83a54a3e8eb85f5c95c0d0.png" />
<img alt="_images/aed8d060779415617db82a0fcf6fe64f0807b6bd8859de1bf769095e5a16edf8.png" src="_images/aed8d060779415617db82a0fcf6fe64f0807b6bd8859de1bf769095e5a16edf8.png" />
<img alt="_images/fe7783f010bac449b06713e8507ed1212dae68d11fe79bf77c977cfda4ec2a47.png" src="_images/fe7783f010bac449b06713e8507ed1212dae68d11fe79bf77c977cfda4ec2a47.png" />
<img alt="_images/258d2ca47aaa2f729024d1eb1517e1e69073d620c641c8c2a8663cf88c072056.png" src="_images/258d2ca47aaa2f729024d1eb1517e1e69073d620c641c8c2a8663cf88c072056.png" />
<img alt="_images/c8dbfa1e504c7c4ee4572bd05c6736e244f886478e03ac2b6eba2326d41cf45f.png" src="_images/c8dbfa1e504c7c4ee4572bd05c6736e244f886478e03ac2b6eba2326d41cf45f.png" />
<img alt="_images/ea4343603b3fdf5cb42d2edb405f36462556c343aa0a8d5a79a90a367b4c45e2.png" src="_images/ea4343603b3fdf5cb42d2edb405f36462556c343aa0a8d5a79a90a367b4c45e2.png" />
</div>
</div>
</section>
<section id="principal-components-analysis-on-uncorrelated-data">
<h2>Principal Components Analysis on Uncorrelated Data<a class="headerlink" href="#principal-components-analysis-on-uncorrelated-data" title="Permalink to this heading">#</a></h2>
<p>Let’s try one more test, principal components analysis on uncorrelated data.</p>
<ul class="simple">
<li><p>we generate a large number of random samples (n is large) for 5 feature.</p></li>
<li><p>we will assume a uniform distribution</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_rand</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span><span class="mi">5</span><span class="p">);</span> <span class="n">df_x_rand</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">x_rand</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Variance of original features: &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x_rand</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">),</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Proportion of variance of original features: &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x_rand</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x_rand</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)),</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Correlation Matrix of original features:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">x_rand</span><span class="p">,</span> <span class="n">rowvar</span> <span class="o">=</span> <span class="kc">False</span><span class="p">),</span><span class="mi">2</span><span class="p">));</span> <span class="nb">print</span><span class="p">()</span>

<span class="n">pd_plot</span><span class="o">.</span><span class="n">scatter_matrix</span><span class="p">(</span><span class="n">df_x_rand</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>                <span class="c1"># pandas matrix scatter plot</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">hist_kwds</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;color&#39;</span><span class="p">:[</span><span class="s1">&#39;grey&#39;</span><span class="p">]})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Original Features&#39;</span><span class="p">)</span>

<span class="n">pca_rand</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">pca_rand</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_rand</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;PCA Variance Explained &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">pca_rand</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>  

<span class="n">scores_x_rand</span> <span class="o">=</span> <span class="n">pca_rand</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_rand</span><span class="p">);</span> <span class="n">df_scores_x_rand</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores_x_rand</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Correlation Matrix of scores:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">scores_x_rand</span><span class="p">,</span> <span class="n">rowvar</span> <span class="o">=</span> <span class="kc">False</span><span class="p">),</span><span class="mi">2</span><span class="p">));</span> <span class="nb">print</span><span class="p">()</span>

<span class="n">pd_plot</span><span class="o">.</span><span class="n">scatter_matrix</span><span class="p">(</span><span class="n">df_scores_x_rand</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>                <span class="c1"># pandas matrix scatter plot</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">hist_kwds</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;color&#39;</span><span class="p">:[</span><span class="s1">&#39;grey&#39;</span><span class="p">]})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Principal Component Scores&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Variance of original features:  [0.08 0.08 0.08 0.08 0.08]
Proportion of variance of original features:  [0.2 0.2 0.2 0.2 0.2]
Correlation Matrix of original features:

[[ 0.08  0.   -0.    0.    0.  ]
 [ 0.    0.08 -0.    0.   -0.  ]
 [-0.   -0.    0.08  0.   -0.  ]
 [ 0.    0.    0.    0.08  0.  ]
 [ 0.   -0.   -0.    0.    0.08]]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>PCA Variance Explained  [0.21 0.2  0.2  0.2  0.19]

Correlation Matrix of scores:

[[ 0.09 -0.    0.   -0.    0.  ]
 [-0.    0.08 -0.   -0.    0.  ]
 [ 0.   -0.    0.08  0.   -0.  ]
 [-0.   -0.    0.    0.08  0.  ]
 [ 0.    0.   -0.    0.    0.08]]
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 0.98, &#39;Principal Component Scores&#39;)
</pre></div>
</div>
<img alt="_images/dfc6a90a6b3319f7de9441450ae74dd55f7a4fb9dd57a9220cd5f4ba2c599696.png" src="_images/dfc6a90a6b3319f7de9441450ae74dd55f7a4fb9dd57a9220cd5f4ba2c599696.png" />
<img alt="_images/bdff06b567c473071603024d2034d58a7ca626a63dc727145ea73cf5c1348d29.png" src="_images/bdff06b567c473071603024d2034d58a7ca626a63dc727145ea73cf5c1348d29.png" />
</div>
</div>
<p>What happens when principal component analysis is applied to uncorrelated, uniformly distributed features?</p>
<ul class="simple">
<li><p>all the principal components describe the same amount of variance</p></li>
<li><p>there is no opportunity for dimensionality reduction through feature projection</p></li>
<li><p>the linear combination of independent random variables invokes the central limit theorem, the principle component scores tend to a Gaussian distribution (see the rounding of the points in the matrix scatter plots above)</p></li>
</ul>
</section>
<section id="comments">
<h2>Comments<a class="headerlink" href="#comments" title="Permalink to this heading">#</a></h2>
<p>This was a basic treatment of dimensionality reduction by principal component analysis (PCA). Much more could be done and discussed, I have many more resources. Check out my <a class="reference external" href="https://michaelpyrcz.com/my-resources">shared resource inventory</a> and the YouTube lecture links at the start of this chapter with resource links in the videos’ descriptions.</p>
<p>I hope this is helpful,</p>
<p><em>Michael</em></p>
</section>
<section id="about-the-author">
<h2>About the Author<a class="headerlink" href="#about-the-author" title="Permalink to this heading">#</a></h2>
<figure style="text-align: center;">
  <img src="_static/intro/michael_pyrcz_officeshot_jacket.jpg" style="display: block; margin: 0 auto; width: 70%;">
  <figcaption style="text-align: center;"> Professor Michael Pyrcz in his office on the 40 acres, campus of The University of Texas at Austin.
</figcaption>
</figure>
<p>Michael Pyrcz is a professor in the <a class="reference external" href="https://cockrell.utexas.edu/faculty-directory/alphabetical/p">Cockrell School of Engineering</a>, and the <a class="reference external" href="https://www.jsg.utexas.edu/researcher/michael_pyrcz/">Jackson School of Geosciences</a>, at <a class="reference external" href="https://www.utexas.edu/">The University of Texas at Austin</a>, where he researches and teaches subsurface, spatial data analytics, geostatistics, and machine learning. Michael is also,</p>
<ul class="simple">
<li><p>the principal investigator of the <a class="reference external" href="https://fri.cns.utexas.edu/energy-analytics">Energy Analytics</a> freshmen research initiative and a core faculty in the Machine Learn Laboratory in the College of Natural Sciences, The University of Texas at Austin</p></li>
<li><p>an associate editor for <a class="reference external" href="https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board">Computers and Geosciences</a>, and a board member for <a class="reference external" href="https://link.springer.com/journal/11004/editorial-board">Mathematical Geosciences</a>, the International Association for Mathematical Geosciences.</p></li>
</ul>
<p>Michael has written over 70 <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en">peer-reviewed publications</a>, a <a class="reference external" href="https://pypi.org/project/geostatspy/">Python package</a> for spatial data analytics, co-authored a textbook on spatial data analytics, <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistical Reservoir Modeling</a> and author of two recently released e-books, <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostatistics in Python: a Hands-on Guide with GeostatsPy</a> and <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html">Applied Machine Learning in Python: a Hands-on Guide with Code</a>.</p>
<p>All of Michael’s university lectures are available on his <a class="reference external" href="https://www.youtube.com/&#64;GeostatsGuyLectures">YouTube Channel</a> with links to 100s of Python interactive dashboards and well-documented workflows in over 40 repositories on his <a class="reference external" href="https://github.com/GeostatsGuy">GitHub account</a>, to support any interested students and working professionals with evergreen content. To find out more about Michael’s work and shared educational resources visit his <span class="xref myst">Website</span>.</p>
</section>
<section id="want-to-work-together">
<h2>Want to Work Together?<a class="headerlink" href="#want-to-work-together" title="Permalink to this heading">#</a></h2>
<p>I hope this content is helpful to those that want to learn more about subsurface modeling, data analytics and machine learning. Students and working professionals are welcome to participate.</p>
<ul class="simple">
<li><p>Want to invite me to visit your company for training, mentoring, project review, workflow design and / or consulting? I’d be happy to drop by and work with you!</p></li>
<li><p>Interested in partnering, supporting my graduate student research or my Subsurface Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)? My research combines data analytics, stochastic modeling and machine learning theory with practice to develop novel methods and workflows to add value. We are solving challenging subsurface problems!</p></li>
<li><p>I can be reached at <a class="reference external" href="mailto:mpyrcz&#37;&#52;&#48;austin&#46;utexas&#46;edu">mpyrcz<span>&#64;</span>austin<span>&#46;</span>utexas<span>&#46;</span>edu</a>.</p></li>
</ul>
<p>I’m always happy to discuss,</p>
<p><em>Michael</em></p>
<p>Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The Jackson School of Geosciences, The University of Texas at Austin</p>
<p>More Resources Available at: <a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="MachineLearning_spectral_clustering.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Spectral Clustering</p>
      </div>
    </a>
    <a class="right-next"
       href="MachineLearning_multidimensional_scaling.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Multidimensional Scaling</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation-for-principal-component-analysis">Motivation for Principal Component Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#curse-of-dimensionality">Curse of Dimensionality</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inferential-machine-learning">Inferential Machine Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Principal Component Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#orthogonal-transformation">Orthogonal Transformation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#best-fitting-interpretation">Best Fitting Interpretation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rotation-based-intepretation">Rotation-based Intepretation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#eigenvalues-eigenvectors-interpretation">Eigenvalues / Eigenvectors Interpretation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-principal-components-analysis-workflow">The Principal Components Analysis Workflow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-the-required-libraries">Load the Required Libraries</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#declare-functions">Declare Functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#set-the-working-directory">Set the Working Directory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-tabular-data">Loading Tabular Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-the-dataframe">Visualize the DataFrame</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-statistics-for-tabular-data">Summary Statistics for Tabular Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculate-the-correlation-matrix">Calculate the Correlation Matrix</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#check-matrix-scatter-plots">Check Matrix Scatter Plots</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-bivariate-example">Simple Bivariate Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculation-of-principal-components">Calculation of Principal Components</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#standardize-the-features">Standardize the Features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#principal-component-analysis-pca">Principal Component Analysis (PCA)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#component-loadings">Component Loadings</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#proportion-of-variance-explained-with-principal-components">Proportion of Variance Explained with Principal Components</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#principal-component-scores-forward-and-reverse-projections">Principal Component Scores, Forward and Reverse Projections</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conservation-of-variance">Conservation of Variance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#independence-of-principal-component-scores">Independence of Principal Component Scores</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#principal-component-analysis-by-hand-with-eigenvalue-and-eigen-vector-calculator">Principal Component Analysis By-hand with Eigenvalue and Eigen Vector Calculator</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstration-of-dimensional-reduction">Demonstration of Dimensional Reduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#all-predictor-features">All Predictor Features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scree-plots">Scree Plots</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Independence of Principal Component Scores</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reduced-dimensionality-impact-on-a-2-feature-relationship">Reduced Dimensionality Impact on a 2 Feature Relationship</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reduced-dimensionality-impact-on-matrix-scatter-plots-of-all-features">Reduced Dimensionality Impact on Matrix Scatter Plots of All Features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#principal-components-analysis-on-uncorrelated-data">Principal Components Analysis on Uncorrelated Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comments">Comments</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#about-the-author">About the Author</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#want-to-work-together">Want to Work Together?</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Michael J. Pyrcz
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024 CC-BY-SA 4.0.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>